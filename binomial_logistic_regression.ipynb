{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./data.npy')\n",
    "label = np.load('./label.npy')\n",
    "print(label.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(label):\n",
    "    width = int(np.max(label))\n",
    "    y = np.zeros([len(label), width])\n",
    "    for i in range(len(y)):\n",
    "        y[i][int(label[i])-1] = 1\n",
    "    return y\n",
    "# y = to_onehot(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42642077  0.83405872]\n",
      " [ 1.65636139 -0.67727351]\n",
      " [-0.81060602  1.22225334]\n",
      " [ 0.03314629  1.23479683]\n",
      " [-0.49780507  1.60400856]]\n",
      "[[ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, label,\n",
    "                                                  test_size = 0.3, random_state = 1)\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.astype(np.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = len(x_train[0])\n",
    "sample_num = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.randn(feature_num, 1)\n",
    "w = tf.Variable(w, dtype=tf.float32)\n",
    "b = tf.Variable(0.5, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.sigmoid(tf.matmul(x, w) + b)\n",
    "# y_pred = tf.sigmoid(tf.matmul(x, tf.reshape(w, [-1, 1])) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_pred, y_true):\n",
    "    return tf.reduce_mean(-(y_true*tf.log(y_pred) + (1-y_true)*tf.log(1-y_pred)), axis=[0,1])\n",
    "loss = cross_entropy(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "fit = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "# sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1, loss: 0.306137, val_loss: 0.295512 ---\n",
      "--- epoch: 2, loss: 0.304881, val_loss: 0.294289 ---\n",
      "--- epoch: 3, loss: 0.303636, val_loss: 0.293078 ---\n",
      "--- epoch: 4, loss: 0.302402, val_loss: 0.291877 ---\n",
      "--- epoch: 5, loss: 0.301179, val_loss: 0.290687 ---\n",
      "--- epoch: 6, loss: 0.299967, val_loss: 0.289507 ---\n",
      "--- epoch: 7, loss: 0.298765, val_loss: 0.288337 ---\n",
      "--- epoch: 8, loss: 0.297574, val_loss: 0.287178 ---\n",
      "--- epoch: 9, loss: 0.296394, val_loss: 0.286028 ---\n",
      "--- epoch: 10, loss: 0.295223, val_loss: 0.284889 ---\n",
      "--- epoch: 11, loss: 0.294063, val_loss: 0.283759 ---\n",
      "--- epoch: 12, loss: 0.292913, val_loss: 0.282639 ---\n",
      "--- epoch: 13, loss: 0.291773, val_loss: 0.281528 ---\n",
      "--- epoch: 14, loss: 0.290642, val_loss: 0.280427 ---\n",
      "--- epoch: 15, loss: 0.289521, val_loss: 0.279336 ---\n",
      "--- epoch: 16, loss: 0.288410, val_loss: 0.278253 ---\n",
      "--- epoch: 17, loss: 0.287308, val_loss: 0.277180 ---\n",
      "--- epoch: 18, loss: 0.286215, val_loss: 0.276116 ---\n",
      "--- epoch: 19, loss: 0.285132, val_loss: 0.275060 ---\n",
      "--- epoch: 20, loss: 0.284058, val_loss: 0.274014 ---\n",
      "--- epoch: 21, loss: 0.282993, val_loss: 0.272976 ---\n",
      "--- epoch: 22, loss: 0.281937, val_loss: 0.271947 ---\n",
      "--- epoch: 23, loss: 0.280889, val_loss: 0.270926 ---\n",
      "--- epoch: 24, loss: 0.279850, val_loss: 0.269914 ---\n",
      "--- epoch: 25, loss: 0.278820, val_loss: 0.268910 ---\n",
      "--- epoch: 26, loss: 0.277799, val_loss: 0.267914 ---\n",
      "--- epoch: 27, loss: 0.276785, val_loss: 0.266926 ---\n",
      "--- epoch: 28, loss: 0.275780, val_loss: 0.265947 ---\n",
      "--- epoch: 29, loss: 0.274784, val_loss: 0.264975 ---\n",
      "--- epoch: 30, loss: 0.273795, val_loss: 0.264011 ---\n",
      "--- epoch: 31, loss: 0.272815, val_loss: 0.263055 ---\n",
      "--- epoch: 32, loss: 0.271842, val_loss: 0.262107 ---\n",
      "--- epoch: 33, loss: 0.270877, val_loss: 0.261166 ---\n",
      "--- epoch: 34, loss: 0.269920, val_loss: 0.260233 ---\n",
      "--- epoch: 35, loss: 0.268971, val_loss: 0.259307 ---\n",
      "--- epoch: 36, loss: 0.268029, val_loss: 0.258389 ---\n",
      "--- epoch: 37, loss: 0.267095, val_loss: 0.257478 ---\n",
      "--- epoch: 38, loss: 0.266168, val_loss: 0.256574 ---\n",
      "--- epoch: 39, loss: 0.265249, val_loss: 0.255677 ---\n",
      "--- epoch: 40, loss: 0.264337, val_loss: 0.254787 ---\n",
      "--- epoch: 41, loss: 0.263432, val_loss: 0.253904 ---\n",
      "--- epoch: 42, loss: 0.262534, val_loss: 0.253028 ---\n",
      "--- epoch: 43, loss: 0.261643, val_loss: 0.252158 ---\n",
      "--- epoch: 44, loss: 0.260760, val_loss: 0.251296 ---\n",
      "--- epoch: 45, loss: 0.259883, val_loss: 0.250440 ---\n",
      "--- epoch: 46, loss: 0.259012, val_loss: 0.249591 ---\n",
      "--- epoch: 47, loss: 0.258149, val_loss: 0.248748 ---\n",
      "--- epoch: 48, loss: 0.257292, val_loss: 0.247912 ---\n",
      "--- epoch: 49, loss: 0.256442, val_loss: 0.247082 ---\n",
      "--- epoch: 50, loss: 0.255599, val_loss: 0.246258 ---\n",
      "--- epoch: 51, loss: 0.254761, val_loss: 0.245441 ---\n",
      "--- epoch: 52, loss: 0.253931, val_loss: 0.244629 ---\n",
      "--- epoch: 53, loss: 0.253106, val_loss: 0.243824 ---\n",
      "--- epoch: 54, loss: 0.252288, val_loss: 0.243025 ---\n",
      "--- epoch: 55, loss: 0.251476, val_loss: 0.242232 ---\n",
      "--- epoch: 56, loss: 0.250670, val_loss: 0.241445 ---\n",
      "--- epoch: 57, loss: 0.249870, val_loss: 0.240663 ---\n",
      "--- epoch: 58, loss: 0.249076, val_loss: 0.239888 ---\n",
      "--- epoch: 59, loss: 0.248288, val_loss: 0.239118 ---\n",
      "--- epoch: 60, loss: 0.247506, val_loss: 0.238354 ---\n",
      "--- epoch: 61, loss: 0.246730, val_loss: 0.237595 ---\n",
      "--- epoch: 62, loss: 0.245959, val_loss: 0.236842 ---\n",
      "--- epoch: 63, loss: 0.245195, val_loss: 0.236095 ---\n",
      "--- epoch: 64, loss: 0.244435, val_loss: 0.235353 ---\n",
      "--- epoch: 65, loss: 0.243682, val_loss: 0.234616 ---\n",
      "--- epoch: 66, loss: 0.242934, val_loss: 0.233885 ---\n",
      "--- epoch: 67, loss: 0.242191, val_loss: 0.233159 ---\n",
      "--- epoch: 68, loss: 0.241454, val_loss: 0.232438 ---\n",
      "--- epoch: 69, loss: 0.240722, val_loss: 0.231722 ---\n",
      "--- epoch: 70, loss: 0.239995, val_loss: 0.231012 ---\n",
      "--- epoch: 71, loss: 0.239274, val_loss: 0.230306 ---\n",
      "--- epoch: 72, loss: 0.238558, val_loss: 0.229606 ---\n",
      "--- epoch: 73, loss: 0.237847, val_loss: 0.228911 ---\n",
      "--- epoch: 74, loss: 0.237141, val_loss: 0.228220 ---\n",
      "--- epoch: 75, loss: 0.236440, val_loss: 0.227534 ---\n",
      "--- epoch: 76, loss: 0.235744, val_loss: 0.226853 ---\n",
      "--- epoch: 77, loss: 0.235053, val_loss: 0.226177 ---\n",
      "--- epoch: 78, loss: 0.234367, val_loss: 0.225506 ---\n",
      "--- epoch: 79, loss: 0.233686, val_loss: 0.224839 ---\n",
      "--- epoch: 80, loss: 0.233009, val_loss: 0.224177 ---\n",
      "--- epoch: 81, loss: 0.232337, val_loss: 0.223520 ---\n",
      "--- epoch: 82, loss: 0.231670, val_loss: 0.222867 ---\n",
      "--- epoch: 83, loss: 0.231008, val_loss: 0.222218 ---\n",
      "--- epoch: 84, loss: 0.230350, val_loss: 0.221574 ---\n",
      "--- epoch: 85, loss: 0.229697, val_loss: 0.220935 ---\n",
      "--- epoch: 86, loss: 0.229048, val_loss: 0.220300 ---\n",
      "--- epoch: 87, loss: 0.228404, val_loss: 0.219669 ---\n",
      "--- epoch: 88, loss: 0.227764, val_loss: 0.219042 ---\n",
      "--- epoch: 89, loss: 0.227129, val_loss: 0.218420 ---\n",
      "--- epoch: 90, loss: 0.226498, val_loss: 0.217802 ---\n",
      "--- epoch: 91, loss: 0.225871, val_loss: 0.217188 ---\n",
      "--- epoch: 92, loss: 0.225249, val_loss: 0.216578 ---\n",
      "--- epoch: 93, loss: 0.224630, val_loss: 0.215972 ---\n",
      "--- epoch: 94, loss: 0.224016, val_loss: 0.215370 ---\n",
      "--- epoch: 95, loss: 0.223406, val_loss: 0.214773 ---\n",
      "--- epoch: 96, loss: 0.222800, val_loss: 0.214179 ---\n",
      "--- epoch: 97, loss: 0.222199, val_loss: 0.213589 ---\n",
      "--- epoch: 98, loss: 0.221601, val_loss: 0.213003 ---\n",
      "--- epoch: 99, loss: 0.221007, val_loss: 0.212421 ---\n",
      "--- epoch: 100, loss: 0.220417, val_loss: 0.211843 ---\n",
      "--- epoch: 101, loss: 0.219831, val_loss: 0.211268 ---\n",
      "--- epoch: 102, loss: 0.219249, val_loss: 0.210698 ---\n",
      "--- epoch: 103, loss: 0.218671, val_loss: 0.210130 ---\n",
      "--- epoch: 104, loss: 0.218097, val_loss: 0.209567 ---\n",
      "--- epoch: 105, loss: 0.217526, val_loss: 0.209007 ---\n",
      "--- epoch: 106, loss: 0.216959, val_loss: 0.208451 ---\n",
      "--- epoch: 107, loss: 0.216396, val_loss: 0.207899 ---\n",
      "--- epoch: 108, loss: 0.215837, val_loss: 0.207350 ---\n",
      "--- epoch: 109, loss: 0.215281, val_loss: 0.206805 ---\n",
      "--- epoch: 110, loss: 0.214729, val_loss: 0.206263 ---\n",
      "--- epoch: 111, loss: 0.214180, val_loss: 0.205724 ---\n",
      "--- epoch: 112, loss: 0.213635, val_loss: 0.205189 ---\n",
      "--- epoch: 113, loss: 0.213093, val_loss: 0.204657 ---\n",
      "--- epoch: 114, loss: 0.212555, val_loss: 0.204129 ---\n",
      "--- epoch: 115, loss: 0.212020, val_loss: 0.203604 ---\n",
      "--- epoch: 116, loss: 0.211489, val_loss: 0.203082 ---\n",
      "--- epoch: 117, loss: 0.210961, val_loss: 0.202564 ---\n",
      "--- epoch: 118, loss: 0.210437, val_loss: 0.202049 ---\n",
      "--- epoch: 119, loss: 0.209915, val_loss: 0.201537 ---\n",
      "--- epoch: 120, loss: 0.209397, val_loss: 0.201028 ---\n",
      "--- epoch: 121, loss: 0.208883, val_loss: 0.200522 ---\n",
      "--- epoch: 122, loss: 0.208371, val_loss: 0.200020 ---\n",
      "--- epoch: 123, loss: 0.207863, val_loss: 0.199520 ---\n",
      "--- epoch: 124, loss: 0.207358, val_loss: 0.199024 ---\n",
      "--- epoch: 125, loss: 0.206856, val_loss: 0.198531 ---\n",
      "--- epoch: 126, loss: 0.206357, val_loss: 0.198041 ---\n",
      "--- epoch: 127, loss: 0.205861, val_loss: 0.197553 ---\n",
      "--- epoch: 128, loss: 0.205369, val_loss: 0.197069 ---\n",
      "--- epoch: 129, loss: 0.204879, val_loss: 0.196588 ---\n",
      "--- epoch: 130, loss: 0.204393, val_loss: 0.196109 ---\n",
      "--- epoch: 131, loss: 0.203909, val_loss: 0.195633 ---\n",
      "--- epoch: 132, loss: 0.203428, val_loss: 0.195161 ---\n",
      "--- epoch: 133, loss: 0.202951, val_loss: 0.194691 ---\n",
      "--- epoch: 134, loss: 0.202476, val_loss: 0.194224 ---\n",
      "--- epoch: 135, loss: 0.202004, val_loss: 0.193760 ---\n",
      "--- epoch: 136, loss: 0.201535, val_loss: 0.193298 ---\n",
      "--- epoch: 137, loss: 0.201069, val_loss: 0.192839 ---\n",
      "--- epoch: 138, loss: 0.200605, val_loss: 0.192383 ---\n",
      "--- epoch: 139, loss: 0.200145, val_loss: 0.191930 ---\n",
      "--- epoch: 140, loss: 0.199687, val_loss: 0.191479 ---\n",
      "--- epoch: 141, loss: 0.199232, val_loss: 0.191031 ---\n",
      "--- epoch: 142, loss: 0.198779, val_loss: 0.190586 ---\n",
      "--- epoch: 143, loss: 0.198329, val_loss: 0.190143 ---\n",
      "--- epoch: 144, loss: 0.197882, val_loss: 0.189703 ---\n",
      "--- epoch: 145, loss: 0.197438, val_loss: 0.189265 ---\n",
      "--- epoch: 146, loss: 0.196996, val_loss: 0.188830 ---\n",
      "--- epoch: 147, loss: 0.196557, val_loss: 0.188397 ---\n",
      "--- epoch: 148, loss: 0.196121, val_loss: 0.187967 ---\n",
      "--- epoch: 149, loss: 0.195687, val_loss: 0.187540 ---\n",
      "--- epoch: 150, loss: 0.195255, val_loss: 0.187115 ---\n",
      "--- epoch: 151, loss: 0.194826, val_loss: 0.186692 ---\n",
      "--- epoch: 152, loss: 0.194400, val_loss: 0.186272 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 153, loss: 0.193976, val_loss: 0.185854 ---\n",
      "--- epoch: 154, loss: 0.193554, val_loss: 0.185438 ---\n",
      "--- epoch: 155, loss: 0.193135, val_loss: 0.185025 ---\n",
      "--- epoch: 156, loss: 0.192718, val_loss: 0.184614 ---\n",
      "--- epoch: 157, loss: 0.192304, val_loss: 0.184206 ---\n",
      "--- epoch: 158, loss: 0.191892, val_loss: 0.183800 ---\n",
      "--- epoch: 159, loss: 0.191483, val_loss: 0.183396 ---\n",
      "--- epoch: 160, loss: 0.191076, val_loss: 0.182994 ---\n",
      "--- epoch: 161, loss: 0.190671, val_loss: 0.182595 ---\n",
      "--- epoch: 162, loss: 0.190268, val_loss: 0.182197 ---\n",
      "--- epoch: 163, loss: 0.189868, val_loss: 0.181803 ---\n",
      "--- epoch: 164, loss: 0.189470, val_loss: 0.181410 ---\n",
      "--- epoch: 165, loss: 0.189074, val_loss: 0.181019 ---\n",
      "--- epoch: 166, loss: 0.188681, val_loss: 0.180631 ---\n",
      "--- epoch: 167, loss: 0.188289, val_loss: 0.180244 ---\n",
      "--- epoch: 168, loss: 0.187900, val_loss: 0.179860 ---\n",
      "--- epoch: 169, loss: 0.187513, val_loss: 0.179478 ---\n",
      "--- epoch: 170, loss: 0.187128, val_loss: 0.179098 ---\n",
      "--- epoch: 171, loss: 0.186746, val_loss: 0.178720 ---\n",
      "--- epoch: 172, loss: 0.186365, val_loss: 0.178344 ---\n",
      "--- epoch: 173, loss: 0.185987, val_loss: 0.177971 ---\n",
      "--- epoch: 174, loss: 0.185610, val_loss: 0.177599 ---\n",
      "--- epoch: 175, loss: 0.185236, val_loss: 0.177229 ---\n",
      "--- epoch: 176, loss: 0.184864, val_loss: 0.176861 ---\n",
      "--- epoch: 177, loss: 0.184494, val_loss: 0.176495 ---\n",
      "--- epoch: 178, loss: 0.184126, val_loss: 0.176132 ---\n",
      "--- epoch: 179, loss: 0.183760, val_loss: 0.175770 ---\n",
      "--- epoch: 180, loss: 0.183396, val_loss: 0.175410 ---\n",
      "--- epoch: 181, loss: 0.183033, val_loss: 0.175052 ---\n",
      "--- epoch: 182, loss: 0.182673, val_loss: 0.174695 ---\n",
      "--- epoch: 183, loss: 0.182315, val_loss: 0.174341 ---\n",
      "--- epoch: 184, loss: 0.181959, val_loss: 0.173989 ---\n",
      "--- epoch: 185, loss: 0.181604, val_loss: 0.173638 ---\n",
      "--- epoch: 186, loss: 0.181252, val_loss: 0.173290 ---\n",
      "--- epoch: 187, loss: 0.180901, val_loss: 0.172943 ---\n",
      "--- epoch: 188, loss: 0.180553, val_loss: 0.172598 ---\n",
      "--- epoch: 189, loss: 0.180206, val_loss: 0.172254 ---\n",
      "--- epoch: 190, loss: 0.179861, val_loss: 0.171913 ---\n",
      "--- epoch: 191, loss: 0.179518, val_loss: 0.171573 ---\n",
      "--- epoch: 192, loss: 0.179176, val_loss: 0.171235 ---\n",
      "--- epoch: 193, loss: 0.178837, val_loss: 0.170899 ---\n",
      "--- epoch: 194, loss: 0.178499, val_loss: 0.170565 ---\n",
      "--- epoch: 195, loss: 0.178163, val_loss: 0.170232 ---\n",
      "--- epoch: 196, loss: 0.177829, val_loss: 0.169901 ---\n",
      "--- epoch: 197, loss: 0.177496, val_loss: 0.169572 ---\n",
      "--- epoch: 198, loss: 0.177166, val_loss: 0.169244 ---\n",
      "--- epoch: 199, loss: 0.176837, val_loss: 0.168918 ---\n",
      "--- epoch: 200, loss: 0.176509, val_loss: 0.168594 ---\n",
      "--- epoch: 201, loss: 0.176184, val_loss: 0.168271 ---\n",
      "--- epoch: 202, loss: 0.175860, val_loss: 0.167950 ---\n",
      "--- epoch: 203, loss: 0.175538, val_loss: 0.167631 ---\n",
      "--- epoch: 204, loss: 0.175217, val_loss: 0.167313 ---\n",
      "--- epoch: 205, loss: 0.174898, val_loss: 0.166997 ---\n",
      "--- epoch: 206, loss: 0.174581, val_loss: 0.166682 ---\n",
      "--- epoch: 207, loss: 0.174265, val_loss: 0.166369 ---\n",
      "--- epoch: 208, loss: 0.173951, val_loss: 0.166057 ---\n",
      "--- epoch: 209, loss: 0.173639, val_loss: 0.165748 ---\n",
      "--- epoch: 210, loss: 0.173328, val_loss: 0.165439 ---\n",
      "--- epoch: 211, loss: 0.173019, val_loss: 0.165132 ---\n",
      "--- epoch: 212, loss: 0.172711, val_loss: 0.164827 ---\n",
      "--- epoch: 213, loss: 0.172405, val_loss: 0.164523 ---\n",
      "--- epoch: 214, loss: 0.172100, val_loss: 0.164221 ---\n",
      "--- epoch: 215, loss: 0.171797, val_loss: 0.163920 ---\n",
      "--- epoch: 216, loss: 0.171496, val_loss: 0.163621 ---\n",
      "--- epoch: 217, loss: 0.171196, val_loss: 0.163323 ---\n",
      "--- epoch: 218, loss: 0.170897, val_loss: 0.163026 ---\n",
      "--- epoch: 219, loss: 0.170600, val_loss: 0.162731 ---\n",
      "--- epoch: 220, loss: 0.170305, val_loss: 0.162438 ---\n",
      "--- epoch: 221, loss: 0.170011, val_loss: 0.162146 ---\n",
      "--- epoch: 222, loss: 0.169718, val_loss: 0.161855 ---\n",
      "--- epoch: 223, loss: 0.169427, val_loss: 0.161566 ---\n",
      "--- epoch: 224, loss: 0.169137, val_loss: 0.161278 ---\n",
      "--- epoch: 225, loss: 0.168849, val_loss: 0.160991 ---\n",
      "--- epoch: 226, loss: 0.168562, val_loss: 0.160706 ---\n",
      "--- epoch: 227, loss: 0.168277, val_loss: 0.160422 ---\n",
      "--- epoch: 228, loss: 0.167992, val_loss: 0.160140 ---\n",
      "--- epoch: 229, loss: 0.167710, val_loss: 0.159859 ---\n",
      "--- epoch: 230, loss: 0.167429, val_loss: 0.159579 ---\n",
      "--- epoch: 231, loss: 0.167149, val_loss: 0.159301 ---\n",
      "--- epoch: 232, loss: 0.166870, val_loss: 0.159023 ---\n",
      "--- epoch: 233, loss: 0.166593, val_loss: 0.158748 ---\n",
      "--- epoch: 234, loss: 0.166317, val_loss: 0.158473 ---\n",
      "--- epoch: 235, loss: 0.166042, val_loss: 0.158200 ---\n",
      "--- epoch: 236, loss: 0.165769, val_loss: 0.157928 ---\n",
      "--- epoch: 237, loss: 0.165497, val_loss: 0.157657 ---\n",
      "--- epoch: 238, loss: 0.165227, val_loss: 0.157388 ---\n",
      "--- epoch: 239, loss: 0.164957, val_loss: 0.157120 ---\n",
      "--- epoch: 240, loss: 0.164689, val_loss: 0.156853 ---\n",
      "--- epoch: 241, loss: 0.164422, val_loss: 0.156587 ---\n",
      "--- epoch: 242, loss: 0.164157, val_loss: 0.156323 ---\n",
      "--- epoch: 243, loss: 0.163893, val_loss: 0.156060 ---\n",
      "--- epoch: 244, loss: 0.163630, val_loss: 0.155798 ---\n",
      "--- epoch: 245, loss: 0.163368, val_loss: 0.155537 ---\n",
      "--- epoch: 246, loss: 0.163107, val_loss: 0.155277 ---\n",
      "--- epoch: 247, loss: 0.162848, val_loss: 0.155019 ---\n",
      "--- epoch: 248, loss: 0.162590, val_loss: 0.154762 ---\n",
      "--- epoch: 249, loss: 0.162333, val_loss: 0.154505 ---\n",
      "--- epoch: 250, loss: 0.162078, val_loss: 0.154251 ---\n",
      "--- epoch: 251, loss: 0.161823, val_loss: 0.153997 ---\n",
      "--- epoch: 252, loss: 0.161570, val_loss: 0.153744 ---\n",
      "--- epoch: 253, loss: 0.161318, val_loss: 0.153493 ---\n",
      "--- epoch: 254, loss: 0.161067, val_loss: 0.153243 ---\n",
      "--- epoch: 255, loss: 0.160817, val_loss: 0.152993 ---\n",
      "--- epoch: 256, loss: 0.160568, val_loss: 0.152745 ---\n",
      "--- epoch: 257, loss: 0.160321, val_loss: 0.152498 ---\n",
      "--- epoch: 258, loss: 0.160074, val_loss: 0.152252 ---\n",
      "--- epoch: 259, loss: 0.159829, val_loss: 0.152008 ---\n",
      "--- epoch: 260, loss: 0.159585, val_loss: 0.151764 ---\n",
      "--- epoch: 261, loss: 0.159342, val_loss: 0.151521 ---\n",
      "--- epoch: 262, loss: 0.159100, val_loss: 0.151280 ---\n",
      "--- epoch: 263, loss: 0.158860, val_loss: 0.151040 ---\n",
      "--- epoch: 264, loss: 0.158620, val_loss: 0.150800 ---\n",
      "--- epoch: 265, loss: 0.158381, val_loss: 0.150562 ---\n",
      "--- epoch: 266, loss: 0.158144, val_loss: 0.150325 ---\n",
      "--- epoch: 267, loss: 0.157907, val_loss: 0.150088 ---\n",
      "--- epoch: 268, loss: 0.157672, val_loss: 0.149853 ---\n",
      "--- epoch: 269, loss: 0.157438, val_loss: 0.149619 ---\n",
      "--- epoch: 270, loss: 0.157204, val_loss: 0.149386 ---\n",
      "--- epoch: 271, loss: 0.156972, val_loss: 0.149154 ---\n",
      "--- epoch: 272, loss: 0.156741, val_loss: 0.148923 ---\n",
      "--- epoch: 273, loss: 0.156511, val_loss: 0.148692 ---\n",
      "--- epoch: 274, loss: 0.156282, val_loss: 0.148463 ---\n",
      "--- epoch: 275, loss: 0.156054, val_loss: 0.148235 ---\n",
      "--- epoch: 276, loss: 0.155827, val_loss: 0.148008 ---\n",
      "--- epoch: 277, loss: 0.155601, val_loss: 0.147782 ---\n",
      "--- epoch: 278, loss: 0.155375, val_loss: 0.147557 ---\n",
      "--- epoch: 279, loss: 0.155151, val_loss: 0.147332 ---\n",
      "--- epoch: 280, loss: 0.154928, val_loss: 0.147109 ---\n",
      "--- epoch: 281, loss: 0.154706, val_loss: 0.146887 ---\n",
      "--- epoch: 282, loss: 0.154485, val_loss: 0.146665 ---\n",
      "--- epoch: 283, loss: 0.154265, val_loss: 0.146445 ---\n",
      "--- epoch: 284, loss: 0.154046, val_loss: 0.146225 ---\n",
      "--- epoch: 285, loss: 0.153827, val_loss: 0.146007 ---\n",
      "--- epoch: 286, loss: 0.153610, val_loss: 0.145789 ---\n",
      "--- epoch: 287, loss: 0.153394, val_loss: 0.145572 ---\n",
      "--- epoch: 288, loss: 0.153178, val_loss: 0.145357 ---\n",
      "--- epoch: 289, loss: 0.152964, val_loss: 0.145142 ---\n",
      "--- epoch: 290, loss: 0.152750, val_loss: 0.144928 ---\n",
      "--- epoch: 291, loss: 0.152537, val_loss: 0.144715 ---\n",
      "--- epoch: 292, loss: 0.152326, val_loss: 0.144502 ---\n",
      "--- epoch: 293, loss: 0.152115, val_loss: 0.144291 ---\n",
      "--- epoch: 294, loss: 0.151905, val_loss: 0.144080 ---\n",
      "--- epoch: 295, loss: 0.151696, val_loss: 0.143871 ---\n",
      "--- epoch: 296, loss: 0.151488, val_loss: 0.143662 ---\n",
      "--- epoch: 297, loss: 0.151280, val_loss: 0.143454 ---\n",
      "--- epoch: 298, loss: 0.151074, val_loss: 0.143247 ---\n",
      "--- epoch: 299, loss: 0.150869, val_loss: 0.143041 ---\n",
      "--- epoch: 300, loss: 0.150664, val_loss: 0.142836 ---\n",
      "--- epoch: 301, loss: 0.150460, val_loss: 0.142631 ---\n",
      "--- epoch: 302, loss: 0.150257, val_loss: 0.142427 ---\n",
      "--- epoch: 303, loss: 0.150055, val_loss: 0.142225 ---\n",
      "--- epoch: 304, loss: 0.149854, val_loss: 0.142023 ---\n",
      "--- epoch: 305, loss: 0.149654, val_loss: 0.141821 ---\n",
      "--- epoch: 306, loss: 0.149454, val_loss: 0.141621 ---\n",
      "--- epoch: 307, loss: 0.149255, val_loss: 0.141421 ---\n",
      "--- epoch: 308, loss: 0.149057, val_loss: 0.141223 ---\n",
      "--- epoch: 309, loss: 0.148860, val_loss: 0.141025 ---\n",
      "--- epoch: 310, loss: 0.148664, val_loss: 0.140828 ---\n",
      "--- epoch: 311, loss: 0.148469, val_loss: 0.140631 ---\n",
      "--- epoch: 312, loss: 0.148274, val_loss: 0.140436 ---\n",
      "--- epoch: 313, loss: 0.148080, val_loss: 0.140241 ---\n",
      "--- epoch: 314, loss: 0.147887, val_loss: 0.140047 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 315, loss: 0.147695, val_loss: 0.139854 ---\n",
      "--- epoch: 316, loss: 0.147504, val_loss: 0.139661 ---\n",
      "--- epoch: 317, loss: 0.147313, val_loss: 0.139469 ---\n",
      "--- epoch: 318, loss: 0.147123, val_loss: 0.139278 ---\n",
      "--- epoch: 319, loss: 0.146934, val_loss: 0.139088 ---\n",
      "--- epoch: 320, loss: 0.146746, val_loss: 0.138899 ---\n",
      "--- epoch: 321, loss: 0.146558, val_loss: 0.138710 ---\n",
      "--- epoch: 322, loss: 0.146371, val_loss: 0.138522 ---\n",
      "--- epoch: 323, loss: 0.146185, val_loss: 0.138335 ---\n",
      "--- epoch: 324, loss: 0.146000, val_loss: 0.138148 ---\n",
      "--- epoch: 325, loss: 0.145815, val_loss: 0.137962 ---\n",
      "--- epoch: 326, loss: 0.145632, val_loss: 0.137777 ---\n",
      "--- epoch: 327, loss: 0.145449, val_loss: 0.137593 ---\n",
      "--- epoch: 328, loss: 0.145266, val_loss: 0.137409 ---\n",
      "--- epoch: 329, loss: 0.145085, val_loss: 0.137227 ---\n",
      "--- epoch: 330, loss: 0.144904, val_loss: 0.137044 ---\n",
      "--- epoch: 331, loss: 0.144724, val_loss: 0.136863 ---\n",
      "--- epoch: 332, loss: 0.144544, val_loss: 0.136682 ---\n",
      "--- epoch: 333, loss: 0.144365, val_loss: 0.136502 ---\n",
      "--- epoch: 334, loss: 0.144187, val_loss: 0.136323 ---\n",
      "--- epoch: 335, loss: 0.144010, val_loss: 0.136144 ---\n",
      "--- epoch: 336, loss: 0.143834, val_loss: 0.135966 ---\n",
      "--- epoch: 337, loss: 0.143658, val_loss: 0.135788 ---\n",
      "--- epoch: 338, loss: 0.143482, val_loss: 0.135612 ---\n",
      "--- epoch: 339, loss: 0.143308, val_loss: 0.135436 ---\n",
      "--- epoch: 340, loss: 0.143134, val_loss: 0.135260 ---\n",
      "--- epoch: 341, loss: 0.142961, val_loss: 0.135086 ---\n",
      "--- epoch: 342, loss: 0.142788, val_loss: 0.134912 ---\n",
      "--- epoch: 343, loss: 0.142617, val_loss: 0.134738 ---\n",
      "--- epoch: 344, loss: 0.142446, val_loss: 0.134566 ---\n",
      "--- epoch: 345, loss: 0.142275, val_loss: 0.134394 ---\n",
      "--- epoch: 346, loss: 0.142105, val_loss: 0.134222 ---\n",
      "--- epoch: 347, loss: 0.141936, val_loss: 0.134051 ---\n",
      "--- epoch: 348, loss: 0.141768, val_loss: 0.133881 ---\n",
      "--- epoch: 349, loss: 0.141600, val_loss: 0.133712 ---\n",
      "--- epoch: 350, loss: 0.141433, val_loss: 0.133543 ---\n",
      "--- epoch: 351, loss: 0.141266, val_loss: 0.133375 ---\n",
      "--- epoch: 352, loss: 0.141100, val_loss: 0.133207 ---\n",
      "--- epoch: 353, loss: 0.140935, val_loss: 0.133040 ---\n",
      "--- epoch: 354, loss: 0.140770, val_loss: 0.132874 ---\n",
      "--- epoch: 355, loss: 0.140606, val_loss: 0.132708 ---\n",
      "--- epoch: 356, loss: 0.140443, val_loss: 0.132543 ---\n",
      "--- epoch: 357, loss: 0.140280, val_loss: 0.132378 ---\n",
      "--- epoch: 358, loss: 0.140118, val_loss: 0.132214 ---\n",
      "--- epoch: 359, loss: 0.139956, val_loss: 0.132051 ---\n",
      "--- epoch: 360, loss: 0.139795, val_loss: 0.131888 ---\n",
      "--- epoch: 361, loss: 0.139635, val_loss: 0.131726 ---\n",
      "--- epoch: 362, loss: 0.139475, val_loss: 0.131564 ---\n",
      "--- epoch: 363, loss: 0.139316, val_loss: 0.131403 ---\n",
      "--- epoch: 364, loss: 0.139158, val_loss: 0.131243 ---\n",
      "--- epoch: 365, loss: 0.139000, val_loss: 0.131083 ---\n",
      "--- epoch: 366, loss: 0.138843, val_loss: 0.130924 ---\n",
      "--- epoch: 367, loss: 0.138686, val_loss: 0.130765 ---\n",
      "--- epoch: 368, loss: 0.138530, val_loss: 0.130607 ---\n",
      "--- epoch: 369, loss: 0.138374, val_loss: 0.130450 ---\n",
      "--- epoch: 370, loss: 0.138219, val_loss: 0.130293 ---\n",
      "--- epoch: 371, loss: 0.138065, val_loss: 0.130136 ---\n",
      "--- epoch: 372, loss: 0.137911, val_loss: 0.129980 ---\n",
      "--- epoch: 373, loss: 0.137758, val_loss: 0.129825 ---\n",
      "--- epoch: 374, loss: 0.137605, val_loss: 0.129670 ---\n",
      "--- epoch: 375, loss: 0.137453, val_loss: 0.129516 ---\n",
      "--- epoch: 376, loss: 0.137301, val_loss: 0.129363 ---\n",
      "--- epoch: 377, loss: 0.137150, val_loss: 0.129210 ---\n",
      "--- epoch: 378, loss: 0.137000, val_loss: 0.129057 ---\n",
      "--- epoch: 379, loss: 0.136850, val_loss: 0.128905 ---\n",
      "--- epoch: 380, loss: 0.136700, val_loss: 0.128754 ---\n",
      "--- epoch: 381, loss: 0.136552, val_loss: 0.128603 ---\n",
      "--- epoch: 382, loss: 0.136403, val_loss: 0.128452 ---\n",
      "--- epoch: 383, loss: 0.136256, val_loss: 0.128302 ---\n",
      "--- epoch: 384, loss: 0.136108, val_loss: 0.128153 ---\n",
      "--- epoch: 385, loss: 0.135962, val_loss: 0.128004 ---\n",
      "--- epoch: 386, loss: 0.135816, val_loss: 0.127856 ---\n",
      "--- epoch: 387, loss: 0.135670, val_loss: 0.127708 ---\n",
      "--- epoch: 388, loss: 0.135525, val_loss: 0.127561 ---\n",
      "--- epoch: 389, loss: 0.135380, val_loss: 0.127414 ---\n",
      "--- epoch: 390, loss: 0.135236, val_loss: 0.127268 ---\n",
      "--- epoch: 391, loss: 0.135093, val_loss: 0.127122 ---\n",
      "--- epoch: 392, loss: 0.134950, val_loss: 0.126977 ---\n",
      "--- epoch: 393, loss: 0.134807, val_loss: 0.126832 ---\n",
      "--- epoch: 394, loss: 0.134665, val_loss: 0.126688 ---\n",
      "--- epoch: 395, loss: 0.134524, val_loss: 0.126544 ---\n",
      "--- epoch: 396, loss: 0.134383, val_loss: 0.126401 ---\n",
      "--- epoch: 397, loss: 0.134242, val_loss: 0.126258 ---\n",
      "--- epoch: 398, loss: 0.134102, val_loss: 0.126116 ---\n",
      "--- epoch: 399, loss: 0.133963, val_loss: 0.125974 ---\n",
      "--- epoch: 400, loss: 0.133824, val_loss: 0.125832 ---\n",
      "--- epoch: 401, loss: 0.133685, val_loss: 0.125692 ---\n",
      "--- epoch: 402, loss: 0.133547, val_loss: 0.125551 ---\n",
      "--- epoch: 403, loss: 0.133410, val_loss: 0.125411 ---\n",
      "--- epoch: 404, loss: 0.133273, val_loss: 0.125272 ---\n",
      "--- epoch: 405, loss: 0.133136, val_loss: 0.125133 ---\n",
      "--- epoch: 406, loss: 0.133000, val_loss: 0.124995 ---\n",
      "--- epoch: 407, loss: 0.132865, val_loss: 0.124857 ---\n",
      "--- epoch: 408, loss: 0.132729, val_loss: 0.124719 ---\n",
      "--- epoch: 409, loss: 0.132595, val_loss: 0.124582 ---\n",
      "--- epoch: 410, loss: 0.132461, val_loss: 0.124445 ---\n",
      "--- epoch: 411, loss: 0.132327, val_loss: 0.124309 ---\n",
      "--- epoch: 412, loss: 0.132194, val_loss: 0.124173 ---\n",
      "--- epoch: 413, loss: 0.132061, val_loss: 0.124038 ---\n",
      "--- epoch: 414, loss: 0.131928, val_loss: 0.123903 ---\n",
      "--- epoch: 415, loss: 0.131797, val_loss: 0.123769 ---\n",
      "--- epoch: 416, loss: 0.131665, val_loss: 0.123635 ---\n",
      "--- epoch: 417, loss: 0.131534, val_loss: 0.123501 ---\n",
      "--- epoch: 418, loss: 0.131404, val_loss: 0.123368 ---\n",
      "--- epoch: 419, loss: 0.131273, val_loss: 0.123236 ---\n",
      "--- epoch: 420, loss: 0.131144, val_loss: 0.123104 ---\n",
      "--- epoch: 421, loss: 0.131015, val_loss: 0.122972 ---\n",
      "--- epoch: 422, loss: 0.130886, val_loss: 0.122841 ---\n",
      "--- epoch: 423, loss: 0.130758, val_loss: 0.122710 ---\n",
      "--- epoch: 424, loss: 0.130630, val_loss: 0.122579 ---\n",
      "--- epoch: 425, loss: 0.130502, val_loss: 0.122449 ---\n",
      "--- epoch: 426, loss: 0.130375, val_loss: 0.122320 ---\n",
      "--- epoch: 427, loss: 0.130249, val_loss: 0.122191 ---\n",
      "--- epoch: 428, loss: 0.130122, val_loss: 0.122062 ---\n",
      "--- epoch: 429, loss: 0.129997, val_loss: 0.121933 ---\n",
      "--- epoch: 430, loss: 0.129871, val_loss: 0.121805 ---\n",
      "--- epoch: 431, loss: 0.129746, val_loss: 0.121678 ---\n",
      "--- epoch: 432, loss: 0.129622, val_loss: 0.121551 ---\n",
      "--- epoch: 433, loss: 0.129498, val_loss: 0.121424 ---\n",
      "--- epoch: 434, loss: 0.129374, val_loss: 0.121298 ---\n",
      "--- epoch: 435, loss: 0.129251, val_loss: 0.121172 ---\n",
      "--- epoch: 436, loss: 0.129128, val_loss: 0.121046 ---\n",
      "--- epoch: 437, loss: 0.129006, val_loss: 0.120921 ---\n",
      "--- epoch: 438, loss: 0.128884, val_loss: 0.120797 ---\n",
      "--- epoch: 439, loss: 0.128762, val_loss: 0.120672 ---\n",
      "--- epoch: 440, loss: 0.128641, val_loss: 0.120549 ---\n",
      "--- epoch: 441, loss: 0.128520, val_loss: 0.120425 ---\n",
      "--- epoch: 442, loss: 0.128400, val_loss: 0.120302 ---\n",
      "--- epoch: 443, loss: 0.128280, val_loss: 0.120179 ---\n",
      "--- epoch: 444, loss: 0.128160, val_loss: 0.120057 ---\n",
      "--- epoch: 445, loss: 0.128041, val_loss: 0.119935 ---\n",
      "--- epoch: 446, loss: 0.127922, val_loss: 0.119813 ---\n",
      "--- epoch: 447, loss: 0.127804, val_loss: 0.119692 ---\n",
      "--- epoch: 448, loss: 0.127686, val_loss: 0.119571 ---\n",
      "--- epoch: 449, loss: 0.127568, val_loss: 0.119451 ---\n",
      "--- epoch: 450, loss: 0.127451, val_loss: 0.119331 ---\n",
      "--- epoch: 451, loss: 0.127334, val_loss: 0.119211 ---\n",
      "--- epoch: 452, loss: 0.127217, val_loss: 0.119092 ---\n",
      "--- epoch: 453, loss: 0.127101, val_loss: 0.118973 ---\n",
      "--- epoch: 454, loss: 0.126986, val_loss: 0.118855 ---\n",
      "--- epoch: 455, loss: 0.126870, val_loss: 0.118736 ---\n",
      "--- epoch: 456, loss: 0.126755, val_loss: 0.118618 ---\n",
      "--- epoch: 457, loss: 0.126640, val_loss: 0.118501 ---\n",
      "--- epoch: 458, loss: 0.126526, val_loss: 0.118384 ---\n",
      "--- epoch: 459, loss: 0.126412, val_loss: 0.118267 ---\n",
      "--- epoch: 460, loss: 0.126299, val_loss: 0.118151 ---\n",
      "--- epoch: 461, loss: 0.126186, val_loss: 0.118035 ---\n",
      "--- epoch: 462, loss: 0.126073, val_loss: 0.117919 ---\n",
      "--- epoch: 463, loss: 0.125960, val_loss: 0.117804 ---\n",
      "--- epoch: 464, loss: 0.125848, val_loss: 0.117689 ---\n",
      "--- epoch: 465, loss: 0.125736, val_loss: 0.117574 ---\n",
      "--- epoch: 466, loss: 0.125625, val_loss: 0.117460 ---\n",
      "--- epoch: 467, loss: 0.125514, val_loss: 0.117346 ---\n",
      "--- epoch: 468, loss: 0.125403, val_loss: 0.117233 ---\n",
      "--- epoch: 469, loss: 0.125293, val_loss: 0.117119 ---\n",
      "--- epoch: 470, loss: 0.125183, val_loss: 0.117006 ---\n",
      "--- epoch: 471, loss: 0.125073, val_loss: 0.116894 ---\n",
      "--- epoch: 472, loss: 0.124964, val_loss: 0.116782 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 473, loss: 0.124855, val_loss: 0.116670 ---\n",
      "--- epoch: 474, loss: 0.124747, val_loss: 0.116558 ---\n",
      "--- epoch: 475, loss: 0.124638, val_loss: 0.116447 ---\n",
      "--- epoch: 476, loss: 0.124530, val_loss: 0.116336 ---\n",
      "--- epoch: 477, loss: 0.124423, val_loss: 0.116226 ---\n",
      "--- epoch: 478, loss: 0.124316, val_loss: 0.116116 ---\n",
      "--- epoch: 479, loss: 0.124209, val_loss: 0.116006 ---\n",
      "--- epoch: 480, loss: 0.124102, val_loss: 0.115896 ---\n",
      "--- epoch: 481, loss: 0.123996, val_loss: 0.115787 ---\n",
      "--- epoch: 482, loss: 0.123890, val_loss: 0.115678 ---\n",
      "--- epoch: 483, loss: 0.123784, val_loss: 0.115570 ---\n",
      "--- epoch: 484, loss: 0.123679, val_loss: 0.115461 ---\n",
      "--- epoch: 485, loss: 0.123574, val_loss: 0.115353 ---\n",
      "--- epoch: 486, loss: 0.123469, val_loss: 0.115246 ---\n",
      "--- epoch: 487, loss: 0.123365, val_loss: 0.115139 ---\n",
      "--- epoch: 488, loss: 0.123261, val_loss: 0.115032 ---\n",
      "--- epoch: 489, loss: 0.123158, val_loss: 0.114925 ---\n",
      "--- epoch: 490, loss: 0.123054, val_loss: 0.114819 ---\n",
      "--- epoch: 491, loss: 0.122951, val_loss: 0.114713 ---\n",
      "--- epoch: 492, loss: 0.122848, val_loss: 0.114607 ---\n",
      "--- epoch: 493, loss: 0.122746, val_loss: 0.114501 ---\n",
      "--- epoch: 494, loss: 0.122644, val_loss: 0.114396 ---\n",
      "--- epoch: 495, loss: 0.122542, val_loss: 0.114291 ---\n",
      "--- epoch: 496, loss: 0.122441, val_loss: 0.114187 ---\n",
      "--- epoch: 497, loss: 0.122340, val_loss: 0.114083 ---\n",
      "--- epoch: 498, loss: 0.122239, val_loss: 0.113979 ---\n",
      "--- epoch: 499, loss: 0.122138, val_loss: 0.113875 ---\n",
      "--- epoch: 500, loss: 0.122038, val_loss: 0.113772 ---\n",
      "--- epoch: 501, loss: 0.121938, val_loss: 0.113669 ---\n",
      "--- epoch: 502, loss: 0.121838, val_loss: 0.113566 ---\n",
      "--- epoch: 503, loss: 0.121739, val_loss: 0.113464 ---\n",
      "--- epoch: 504, loss: 0.121640, val_loss: 0.113362 ---\n",
      "--- epoch: 505, loss: 0.121541, val_loss: 0.113260 ---\n",
      "--- epoch: 506, loss: 0.121443, val_loss: 0.113159 ---\n",
      "--- epoch: 507, loss: 0.121345, val_loss: 0.113057 ---\n",
      "--- epoch: 508, loss: 0.121247, val_loss: 0.112956 ---\n",
      "--- epoch: 509, loss: 0.121149, val_loss: 0.112856 ---\n",
      "--- epoch: 510, loss: 0.121052, val_loss: 0.112755 ---\n",
      "--- epoch: 511, loss: 0.120955, val_loss: 0.112655 ---\n",
      "--- epoch: 512, loss: 0.120858, val_loss: 0.112555 ---\n",
      "--- epoch: 513, loss: 0.120762, val_loss: 0.112456 ---\n",
      "--- epoch: 514, loss: 0.120666, val_loss: 0.112357 ---\n",
      "--- epoch: 515, loss: 0.120570, val_loss: 0.112258 ---\n",
      "--- epoch: 516, loss: 0.120474, val_loss: 0.112159 ---\n",
      "--- epoch: 517, loss: 0.120379, val_loss: 0.112061 ---\n",
      "--- epoch: 518, loss: 0.120284, val_loss: 0.111963 ---\n",
      "--- epoch: 519, loss: 0.120189, val_loss: 0.111865 ---\n",
      "--- epoch: 520, loss: 0.120095, val_loss: 0.111767 ---\n",
      "--- epoch: 521, loss: 0.120001, val_loss: 0.111670 ---\n",
      "--- epoch: 522, loss: 0.119907, val_loss: 0.111573 ---\n",
      "--- epoch: 523, loss: 0.119813, val_loss: 0.111476 ---\n",
      "--- epoch: 524, loss: 0.119720, val_loss: 0.111380 ---\n",
      "--- epoch: 525, loss: 0.119627, val_loss: 0.111283 ---\n",
      "--- epoch: 526, loss: 0.119534, val_loss: 0.111187 ---\n",
      "--- epoch: 527, loss: 0.119442, val_loss: 0.111092 ---\n",
      "--- epoch: 528, loss: 0.119349, val_loss: 0.110996 ---\n",
      "--- epoch: 529, loss: 0.119257, val_loss: 0.110901 ---\n",
      "--- epoch: 530, loss: 0.119166, val_loss: 0.110806 ---\n",
      "--- epoch: 531, loss: 0.119074, val_loss: 0.110712 ---\n",
      "--- epoch: 532, loss: 0.118983, val_loss: 0.110617 ---\n",
      "--- epoch: 533, loss: 0.118892, val_loss: 0.110523 ---\n",
      "--- epoch: 534, loss: 0.118801, val_loss: 0.110429 ---\n",
      "--- epoch: 535, loss: 0.118711, val_loss: 0.110336 ---\n",
      "--- epoch: 536, loss: 0.118621, val_loss: 0.110242 ---\n",
      "--- epoch: 537, loss: 0.118531, val_loss: 0.110149 ---\n",
      "--- epoch: 538, loss: 0.118441, val_loss: 0.110056 ---\n",
      "--- epoch: 539, loss: 0.118352, val_loss: 0.109964 ---\n",
      "--- epoch: 540, loss: 0.118263, val_loss: 0.109872 ---\n",
      "--- epoch: 541, loss: 0.118174, val_loss: 0.109779 ---\n",
      "--- epoch: 542, loss: 0.118085, val_loss: 0.109688 ---\n",
      "--- epoch: 543, loss: 0.117997, val_loss: 0.109596 ---\n",
      "--- epoch: 544, loss: 0.117909, val_loss: 0.109505 ---\n",
      "--- epoch: 545, loss: 0.117821, val_loss: 0.109414 ---\n",
      "--- epoch: 546, loss: 0.117733, val_loss: 0.109323 ---\n",
      "--- epoch: 547, loss: 0.117646, val_loss: 0.109232 ---\n",
      "--- epoch: 548, loss: 0.117559, val_loss: 0.109142 ---\n",
      "--- epoch: 549, loss: 0.117472, val_loss: 0.109052 ---\n",
      "--- epoch: 550, loss: 0.117385, val_loss: 0.108962 ---\n",
      "--- epoch: 551, loss: 0.117299, val_loss: 0.108872 ---\n",
      "--- epoch: 552, loss: 0.117212, val_loss: 0.108783 ---\n",
      "--- epoch: 553, loss: 0.117126, val_loss: 0.108694 ---\n",
      "--- epoch: 554, loss: 0.117041, val_loss: 0.108605 ---\n",
      "--- epoch: 555, loss: 0.116955, val_loss: 0.108516 ---\n",
      "--- epoch: 556, loss: 0.116870, val_loss: 0.108428 ---\n",
      "--- epoch: 557, loss: 0.116785, val_loss: 0.108339 ---\n",
      "--- epoch: 558, loss: 0.116700, val_loss: 0.108251 ---\n",
      "--- epoch: 559, loss: 0.116616, val_loss: 0.108164 ---\n",
      "--- epoch: 560, loss: 0.116532, val_loss: 0.108076 ---\n",
      "--- epoch: 561, loss: 0.116448, val_loss: 0.107989 ---\n",
      "--- epoch: 562, loss: 0.116364, val_loss: 0.107902 ---\n",
      "--- epoch: 563, loss: 0.116280, val_loss: 0.107815 ---\n",
      "--- epoch: 564, loss: 0.116197, val_loss: 0.107728 ---\n",
      "--- epoch: 565, loss: 0.116114, val_loss: 0.107642 ---\n",
      "--- epoch: 566, loss: 0.116031, val_loss: 0.107556 ---\n",
      "--- epoch: 567, loss: 0.115948, val_loss: 0.107470 ---\n",
      "--- epoch: 568, loss: 0.115866, val_loss: 0.107384 ---\n",
      "--- epoch: 569, loss: 0.115784, val_loss: 0.107299 ---\n",
      "--- epoch: 570, loss: 0.115702, val_loss: 0.107214 ---\n",
      "--- epoch: 571, loss: 0.115620, val_loss: 0.107129 ---\n",
      "--- epoch: 572, loss: 0.115538, val_loss: 0.107044 ---\n",
      "--- epoch: 573, loss: 0.115457, val_loss: 0.106959 ---\n",
      "--- epoch: 574, loss: 0.115376, val_loss: 0.106875 ---\n",
      "--- epoch: 575, loss: 0.115295, val_loss: 0.106791 ---\n",
      "--- epoch: 576, loss: 0.115215, val_loss: 0.106707 ---\n",
      "--- epoch: 577, loss: 0.115134, val_loss: 0.106623 ---\n",
      "--- epoch: 578, loss: 0.115054, val_loss: 0.106540 ---\n",
      "--- epoch: 579, loss: 0.114974, val_loss: 0.106456 ---\n",
      "--- epoch: 580, loss: 0.114894, val_loss: 0.106373 ---\n",
      "--- epoch: 581, loss: 0.114815, val_loss: 0.106290 ---\n",
      "--- epoch: 582, loss: 0.114735, val_loss: 0.106208 ---\n",
      "--- epoch: 583, loss: 0.114656, val_loss: 0.106125 ---\n",
      "--- epoch: 584, loss: 0.114577, val_loss: 0.106043 ---\n",
      "--- epoch: 585, loss: 0.114498, val_loss: 0.105961 ---\n",
      "--- epoch: 586, loss: 0.114420, val_loss: 0.105879 ---\n",
      "--- epoch: 587, loss: 0.114342, val_loss: 0.105798 ---\n",
      "--- epoch: 588, loss: 0.114264, val_loss: 0.105716 ---\n",
      "--- epoch: 589, loss: 0.114186, val_loss: 0.105635 ---\n",
      "--- epoch: 590, loss: 0.114108, val_loss: 0.105554 ---\n",
      "--- epoch: 591, loss: 0.114031, val_loss: 0.105473 ---\n",
      "--- epoch: 592, loss: 0.113953, val_loss: 0.105393 ---\n",
      "--- epoch: 593, loss: 0.113876, val_loss: 0.105312 ---\n",
      "--- epoch: 594, loss: 0.113799, val_loss: 0.105232 ---\n",
      "--- epoch: 595, loss: 0.113723, val_loss: 0.105152 ---\n",
      "--- epoch: 596, loss: 0.113646, val_loss: 0.105072 ---\n",
      "--- epoch: 597, loss: 0.113570, val_loss: 0.104993 ---\n",
      "--- epoch: 598, loss: 0.113494, val_loss: 0.104914 ---\n",
      "--- epoch: 599, loss: 0.113418, val_loss: 0.104834 ---\n",
      "--- epoch: 600, loss: 0.113343, val_loss: 0.104755 ---\n",
      "--- epoch: 601, loss: 0.113267, val_loss: 0.104677 ---\n",
      "--- epoch: 602, loss: 0.113192, val_loss: 0.104598 ---\n",
      "--- epoch: 603, loss: 0.113117, val_loss: 0.104520 ---\n",
      "--- epoch: 604, loss: 0.113042, val_loss: 0.104442 ---\n",
      "--- epoch: 605, loss: 0.112967, val_loss: 0.104364 ---\n",
      "--- epoch: 606, loss: 0.112893, val_loss: 0.104286 ---\n",
      "--- epoch: 607, loss: 0.112819, val_loss: 0.104208 ---\n",
      "--- epoch: 608, loss: 0.112744, val_loss: 0.104131 ---\n",
      "--- epoch: 609, loss: 0.112671, val_loss: 0.104053 ---\n",
      "--- epoch: 610, loss: 0.112597, val_loss: 0.103976 ---\n",
      "--- epoch: 611, loss: 0.112523, val_loss: 0.103900 ---\n",
      "--- epoch: 612, loss: 0.112450, val_loss: 0.103823 ---\n",
      "--- epoch: 613, loss: 0.112377, val_loss: 0.103746 ---\n",
      "--- epoch: 614, loss: 0.112304, val_loss: 0.103670 ---\n",
      "--- epoch: 615, loss: 0.112231, val_loss: 0.103594 ---\n",
      "--- epoch: 616, loss: 0.112159, val_loss: 0.103518 ---\n",
      "--- epoch: 617, loss: 0.112086, val_loss: 0.103442 ---\n",
      "--- epoch: 618, loss: 0.112014, val_loss: 0.103367 ---\n",
      "--- epoch: 619, loss: 0.111942, val_loss: 0.103292 ---\n",
      "--- epoch: 620, loss: 0.111870, val_loss: 0.103216 ---\n",
      "--- epoch: 621, loss: 0.111799, val_loss: 0.103141 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 622, loss: 0.111727, val_loss: 0.103067 ---\n",
      "--- epoch: 623, loss: 0.111656, val_loss: 0.102992 ---\n",
      "--- epoch: 624, loss: 0.111585, val_loss: 0.102918 ---\n",
      "--- epoch: 625, loss: 0.111514, val_loss: 0.102843 ---\n",
      "--- epoch: 626, loss: 0.111443, val_loss: 0.102769 ---\n",
      "--- epoch: 627, loss: 0.111373, val_loss: 0.102695 ---\n",
      "--- epoch: 628, loss: 0.111302, val_loss: 0.102622 ---\n",
      "--- epoch: 629, loss: 0.111232, val_loss: 0.102548 ---\n",
      "--- epoch: 630, loss: 0.111162, val_loss: 0.102475 ---\n",
      "--- epoch: 631, loss: 0.111092, val_loss: 0.102401 ---\n",
      "--- epoch: 632, loss: 0.111022, val_loss: 0.102328 ---\n",
      "--- epoch: 633, loss: 0.110953, val_loss: 0.102256 ---\n",
      "--- epoch: 634, loss: 0.110884, val_loss: 0.102183 ---\n",
      "--- epoch: 635, loss: 0.110815, val_loss: 0.102110 ---\n",
      "--- epoch: 636, loss: 0.110746, val_loss: 0.102038 ---\n",
      "--- epoch: 637, loss: 0.110677, val_loss: 0.101966 ---\n",
      "--- epoch: 638, loss: 0.110608, val_loss: 0.101894 ---\n",
      "--- epoch: 639, loss: 0.110540, val_loss: 0.101822 ---\n",
      "--- epoch: 640, loss: 0.110471, val_loss: 0.101750 ---\n",
      "--- epoch: 641, loss: 0.110403, val_loss: 0.101679 ---\n",
      "--- epoch: 642, loss: 0.110335, val_loss: 0.101608 ---\n",
      "--- epoch: 643, loss: 0.110268, val_loss: 0.101536 ---\n",
      "--- epoch: 644, loss: 0.110200, val_loss: 0.101466 ---\n",
      "--- epoch: 645, loss: 0.110132, val_loss: 0.101395 ---\n",
      "--- epoch: 646, loss: 0.110065, val_loss: 0.101324 ---\n",
      "--- epoch: 647, loss: 0.109998, val_loss: 0.101254 ---\n",
      "--- epoch: 648, loss: 0.109931, val_loss: 0.101183 ---\n",
      "--- epoch: 649, loss: 0.109864, val_loss: 0.101113 ---\n",
      "--- epoch: 650, loss: 0.109798, val_loss: 0.101043 ---\n",
      "--- epoch: 651, loss: 0.109731, val_loss: 0.100973 ---\n",
      "--- epoch: 652, loss: 0.109665, val_loss: 0.100904 ---\n",
      "--- epoch: 653, loss: 0.109599, val_loss: 0.100834 ---\n",
      "--- epoch: 654, loss: 0.109533, val_loss: 0.100765 ---\n",
      "--- epoch: 655, loss: 0.109467, val_loss: 0.100696 ---\n",
      "--- epoch: 656, loss: 0.109401, val_loss: 0.100627 ---\n",
      "--- epoch: 657, loss: 0.109336, val_loss: 0.100558 ---\n",
      "--- epoch: 658, loss: 0.109271, val_loss: 0.100489 ---\n",
      "--- epoch: 659, loss: 0.109205, val_loss: 0.100420 ---\n",
      "--- epoch: 660, loss: 0.109140, val_loss: 0.100352 ---\n",
      "--- epoch: 661, loss: 0.109076, val_loss: 0.100284 ---\n",
      "--- epoch: 662, loss: 0.109011, val_loss: 0.100216 ---\n",
      "--- epoch: 663, loss: 0.108946, val_loss: 0.100148 ---\n",
      "--- epoch: 664, loss: 0.108882, val_loss: 0.100080 ---\n",
      "--- epoch: 665, loss: 0.108818, val_loss: 0.100013 ---\n",
      "--- epoch: 666, loss: 0.108754, val_loss: 0.099945 ---\n",
      "--- epoch: 667, loss: 0.108690, val_loss: 0.099878 ---\n",
      "--- epoch: 668, loss: 0.108626, val_loss: 0.099811 ---\n",
      "--- epoch: 669, loss: 0.108562, val_loss: 0.099744 ---\n",
      "--- epoch: 670, loss: 0.108499, val_loss: 0.099677 ---\n",
      "--- epoch: 671, loss: 0.108436, val_loss: 0.099610 ---\n",
      "--- epoch: 672, loss: 0.108372, val_loss: 0.099544 ---\n",
      "--- epoch: 673, loss: 0.108309, val_loss: 0.099477 ---\n",
      "--- epoch: 674, loss: 0.108247, val_loss: 0.099411 ---\n",
      "--- epoch: 675, loss: 0.108184, val_loss: 0.099345 ---\n",
      "--- epoch: 676, loss: 0.108121, val_loss: 0.099279 ---\n",
      "--- epoch: 677, loss: 0.108059, val_loss: 0.099213 ---\n",
      "--- epoch: 678, loss: 0.107997, val_loss: 0.099148 ---\n",
      "--- epoch: 679, loss: 0.107935, val_loss: 0.099082 ---\n",
      "--- epoch: 680, loss: 0.107873, val_loss: 0.099017 ---\n",
      "--- epoch: 681, loss: 0.107811, val_loss: 0.098952 ---\n",
      "--- epoch: 682, loss: 0.107749, val_loss: 0.098886 ---\n",
      "--- epoch: 683, loss: 0.107688, val_loss: 0.098822 ---\n",
      "--- epoch: 684, loss: 0.107626, val_loss: 0.098757 ---\n",
      "--- epoch: 685, loss: 0.107565, val_loss: 0.098692 ---\n",
      "--- epoch: 686, loss: 0.107504, val_loss: 0.098628 ---\n",
      "--- epoch: 687, loss: 0.107443, val_loss: 0.098563 ---\n",
      "--- epoch: 688, loss: 0.107382, val_loss: 0.098499 ---\n",
      "--- epoch: 689, loss: 0.107321, val_loss: 0.098435 ---\n",
      "--- epoch: 690, loss: 0.107261, val_loss: 0.098371 ---\n",
      "--- epoch: 691, loss: 0.107201, val_loss: 0.098308 ---\n",
      "--- epoch: 692, loss: 0.107140, val_loss: 0.098244 ---\n",
      "--- epoch: 693, loss: 0.107080, val_loss: 0.098180 ---\n",
      "--- epoch: 694, loss: 0.107020, val_loss: 0.098117 ---\n",
      "--- epoch: 695, loss: 0.106960, val_loss: 0.098054 ---\n",
      "--- epoch: 696, loss: 0.106901, val_loss: 0.097991 ---\n",
      "--- epoch: 697, loss: 0.106841, val_loss: 0.097928 ---\n",
      "--- epoch: 698, loss: 0.106782, val_loss: 0.097865 ---\n",
      "--- epoch: 699, loss: 0.106723, val_loss: 0.097803 ---\n",
      "--- epoch: 700, loss: 0.106663, val_loss: 0.097740 ---\n",
      "--- epoch: 701, loss: 0.106604, val_loss: 0.097678 ---\n",
      "--- epoch: 702, loss: 0.106546, val_loss: 0.097615 ---\n",
      "--- epoch: 703, loss: 0.106487, val_loss: 0.097553 ---\n",
      "--- epoch: 704, loss: 0.106428, val_loss: 0.097491 ---\n",
      "--- epoch: 705, loss: 0.106370, val_loss: 0.097430 ---\n",
      "--- epoch: 706, loss: 0.106311, val_loss: 0.097368 ---\n",
      "--- epoch: 707, loss: 0.106253, val_loss: 0.097306 ---\n",
      "--- epoch: 708, loss: 0.106195, val_loss: 0.097245 ---\n",
      "--- epoch: 709, loss: 0.106137, val_loss: 0.097184 ---\n",
      "--- epoch: 710, loss: 0.106080, val_loss: 0.097122 ---\n",
      "--- epoch: 711, loss: 0.106022, val_loss: 0.097061 ---\n",
      "--- epoch: 712, loss: 0.105964, val_loss: 0.097000 ---\n",
      "--- epoch: 713, loss: 0.105907, val_loss: 0.096940 ---\n",
      "--- epoch: 714, loss: 0.105850, val_loss: 0.096879 ---\n",
      "--- epoch: 715, loss: 0.105793, val_loss: 0.096819 ---\n",
      "--- epoch: 716, loss: 0.105736, val_loss: 0.096758 ---\n",
      "--- epoch: 717, loss: 0.105679, val_loss: 0.096698 ---\n",
      "--- epoch: 718, loss: 0.105622, val_loss: 0.096638 ---\n",
      "--- epoch: 719, loss: 0.105565, val_loss: 0.096578 ---\n",
      "--- epoch: 720, loss: 0.105509, val_loss: 0.096518 ---\n",
      "--- epoch: 721, loss: 0.105452, val_loss: 0.096458 ---\n",
      "--- epoch: 722, loss: 0.105396, val_loss: 0.096399 ---\n",
      "--- epoch: 723, loss: 0.105340, val_loss: 0.096339 ---\n",
      "--- epoch: 724, loss: 0.105284, val_loss: 0.096280 ---\n",
      "--- epoch: 725, loss: 0.105228, val_loss: 0.096221 ---\n",
      "--- epoch: 726, loss: 0.105173, val_loss: 0.096161 ---\n",
      "--- epoch: 727, loss: 0.105117, val_loss: 0.096102 ---\n",
      "--- epoch: 728, loss: 0.105061, val_loss: 0.096044 ---\n",
      "--- epoch: 729, loss: 0.105006, val_loss: 0.095985 ---\n",
      "--- epoch: 730, loss: 0.104951, val_loss: 0.095926 ---\n",
      "--- epoch: 731, loss: 0.104896, val_loss: 0.095868 ---\n",
      "--- epoch: 732, loss: 0.104841, val_loss: 0.095809 ---\n",
      "--- epoch: 733, loss: 0.104786, val_loss: 0.095751 ---\n",
      "--- epoch: 734, loss: 0.104731, val_loss: 0.095693 ---\n",
      "--- epoch: 735, loss: 0.104677, val_loss: 0.095635 ---\n",
      "--- epoch: 736, loss: 0.104622, val_loss: 0.095577 ---\n",
      "--- epoch: 737, loss: 0.104568, val_loss: 0.095520 ---\n",
      "--- epoch: 738, loss: 0.104513, val_loss: 0.095462 ---\n",
      "--- epoch: 739, loss: 0.104459, val_loss: 0.095404 ---\n",
      "--- epoch: 740, loss: 0.104405, val_loss: 0.095347 ---\n",
      "--- epoch: 741, loss: 0.104351, val_loss: 0.095290 ---\n",
      "--- epoch: 742, loss: 0.104298, val_loss: 0.095233 ---\n",
      "--- epoch: 743, loss: 0.104244, val_loss: 0.095176 ---\n",
      "--- epoch: 744, loss: 0.104190, val_loss: 0.095119 ---\n",
      "--- epoch: 745, loss: 0.104137, val_loss: 0.095062 ---\n",
      "--- epoch: 746, loss: 0.104084, val_loss: 0.095005 ---\n",
      "--- epoch: 747, loss: 0.104030, val_loss: 0.094949 ---\n",
      "--- epoch: 748, loss: 0.103977, val_loss: 0.094892 ---\n",
      "--- epoch: 749, loss: 0.103924, val_loss: 0.094836 ---\n",
      "--- epoch: 750, loss: 0.103871, val_loss: 0.094780 ---\n",
      "--- epoch: 751, loss: 0.103819, val_loss: 0.094724 ---\n",
      "--- epoch: 752, loss: 0.103766, val_loss: 0.094668 ---\n",
      "--- epoch: 753, loss: 0.103714, val_loss: 0.094612 ---\n",
      "--- epoch: 754, loss: 0.103661, val_loss: 0.094556 ---\n",
      "--- epoch: 755, loss: 0.103609, val_loss: 0.094500 ---\n",
      "--- epoch: 756, loss: 0.103557, val_loss: 0.094445 ---\n",
      "--- epoch: 757, loss: 0.103505, val_loss: 0.094389 ---\n",
      "--- epoch: 758, loss: 0.103453, val_loss: 0.094334 ---\n",
      "--- epoch: 759, loss: 0.103401, val_loss: 0.094279 ---\n",
      "--- epoch: 760, loss: 0.103349, val_loss: 0.094224 ---\n",
      "--- epoch: 761, loss: 0.103298, val_loss: 0.094169 ---\n",
      "--- epoch: 762, loss: 0.103246, val_loss: 0.094114 ---\n",
      "--- epoch: 763, loss: 0.103195, val_loss: 0.094059 ---\n",
      "--- epoch: 764, loss: 0.103143, val_loss: 0.094005 ---\n",
      "--- epoch: 765, loss: 0.103092, val_loss: 0.093950 ---\n",
      "--- epoch: 766, loss: 0.103041, val_loss: 0.093896 ---\n",
      "--- epoch: 767, loss: 0.102990, val_loss: 0.093841 ---\n",
      "--- epoch: 768, loss: 0.102939, val_loss: 0.093787 ---\n",
      "--- epoch: 769, loss: 0.102889, val_loss: 0.093733 ---\n",
      "--- epoch: 770, loss: 0.102838, val_loss: 0.093679 ---\n",
      "--- epoch: 771, loss: 0.102788, val_loss: 0.093625 ---\n",
      "--- epoch: 772, loss: 0.102737, val_loss: 0.093572 ---\n",
      "--- epoch: 773, loss: 0.102687, val_loss: 0.093518 ---\n",
      "--- epoch: 774, loss: 0.102637, val_loss: 0.093464 ---\n",
      "--- epoch: 775, loss: 0.102587, val_loss: 0.093411 ---\n",
      "--- epoch: 776, loss: 0.102537, val_loss: 0.093358 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 777, loss: 0.102487, val_loss: 0.093304 ---\n",
      "--- epoch: 778, loss: 0.102437, val_loss: 0.093251 ---\n",
      "--- epoch: 779, loss: 0.102387, val_loss: 0.093198 ---\n",
      "--- epoch: 780, loss: 0.102338, val_loss: 0.093145 ---\n",
      "--- epoch: 781, loss: 0.102288, val_loss: 0.093093 ---\n",
      "--- epoch: 782, loss: 0.102239, val_loss: 0.093040 ---\n",
      "--- epoch: 783, loss: 0.102190, val_loss: 0.092987 ---\n",
      "--- epoch: 784, loss: 0.102141, val_loss: 0.092935 ---\n",
      "--- epoch: 785, loss: 0.102092, val_loss: 0.092883 ---\n",
      "--- epoch: 786, loss: 0.102043, val_loss: 0.092830 ---\n",
      "--- epoch: 787, loss: 0.101994, val_loss: 0.092778 ---\n",
      "--- epoch: 788, loss: 0.101945, val_loss: 0.092726 ---\n",
      "--- epoch: 789, loss: 0.101896, val_loss: 0.092674 ---\n",
      "--- epoch: 790, loss: 0.101848, val_loss: 0.092622 ---\n",
      "--- epoch: 791, loss: 0.101799, val_loss: 0.092570 ---\n",
      "--- epoch: 792, loss: 0.101751, val_loss: 0.092519 ---\n",
      "--- epoch: 793, loss: 0.101703, val_loss: 0.092467 ---\n",
      "--- epoch: 794, loss: 0.101655, val_loss: 0.092416 ---\n",
      "--- epoch: 795, loss: 0.101607, val_loss: 0.092364 ---\n",
      "--- epoch: 796, loss: 0.101559, val_loss: 0.092313 ---\n",
      "--- epoch: 797, loss: 0.101511, val_loss: 0.092262 ---\n",
      "--- epoch: 798, loss: 0.101463, val_loss: 0.092211 ---\n",
      "--- epoch: 799, loss: 0.101416, val_loss: 0.092160 ---\n",
      "--- epoch: 800, loss: 0.101368, val_loss: 0.092109 ---\n",
      "--- epoch: 801, loss: 0.101321, val_loss: 0.092058 ---\n",
      "--- epoch: 802, loss: 0.101273, val_loss: 0.092008 ---\n",
      "--- epoch: 803, loss: 0.101226, val_loss: 0.091957 ---\n",
      "--- epoch: 804, loss: 0.101179, val_loss: 0.091907 ---\n",
      "--- epoch: 805, loss: 0.101132, val_loss: 0.091856 ---\n",
      "--- epoch: 806, loss: 0.101085, val_loss: 0.091806 ---\n",
      "--- epoch: 807, loss: 0.101038, val_loss: 0.091756 ---\n",
      "--- epoch: 808, loss: 0.100991, val_loss: 0.091706 ---\n",
      "--- epoch: 809, loss: 0.100944, val_loss: 0.091656 ---\n",
      "--- epoch: 810, loss: 0.100898, val_loss: 0.091606 ---\n",
      "--- epoch: 811, loss: 0.100851, val_loss: 0.091556 ---\n",
      "--- epoch: 812, loss: 0.100805, val_loss: 0.091506 ---\n",
      "--- epoch: 813, loss: 0.100759, val_loss: 0.091457 ---\n",
      "--- epoch: 814, loss: 0.100713, val_loss: 0.091407 ---\n",
      "--- epoch: 815, loss: 0.100666, val_loss: 0.091358 ---\n",
      "--- epoch: 816, loss: 0.100620, val_loss: 0.091308 ---\n",
      "--- epoch: 817, loss: 0.100574, val_loss: 0.091259 ---\n",
      "--- epoch: 818, loss: 0.100529, val_loss: 0.091210 ---\n",
      "--- epoch: 819, loss: 0.100483, val_loss: 0.091161 ---\n",
      "--- epoch: 820, loss: 0.100437, val_loss: 0.091112 ---\n",
      "--- epoch: 821, loss: 0.100392, val_loss: 0.091063 ---\n",
      "--- epoch: 822, loss: 0.100346, val_loss: 0.091015 ---\n",
      "--- epoch: 823, loss: 0.100301, val_loss: 0.090966 ---\n",
      "--- epoch: 824, loss: 0.100256, val_loss: 0.090917 ---\n",
      "--- epoch: 825, loss: 0.100211, val_loss: 0.090869 ---\n",
      "--- epoch: 826, loss: 0.100165, val_loss: 0.090821 ---\n",
      "--- epoch: 827, loss: 0.100120, val_loss: 0.090772 ---\n",
      "--- epoch: 828, loss: 0.100076, val_loss: 0.090724 ---\n",
      "--- epoch: 829, loss: 0.100031, val_loss: 0.090676 ---\n",
      "--- epoch: 830, loss: 0.099986, val_loss: 0.090628 ---\n",
      "--- epoch: 831, loss: 0.099941, val_loss: 0.090580 ---\n",
      "--- epoch: 832, loss: 0.099897, val_loss: 0.090532 ---\n",
      "--- epoch: 833, loss: 0.099852, val_loss: 0.090484 ---\n",
      "--- epoch: 834, loss: 0.099808, val_loss: 0.090437 ---\n",
      "--- epoch: 835, loss: 0.099764, val_loss: 0.090389 ---\n",
      "--- epoch: 836, loss: 0.099719, val_loss: 0.090342 ---\n",
      "--- epoch: 837, loss: 0.099675, val_loss: 0.090294 ---\n",
      "--- epoch: 838, loss: 0.099631, val_loss: 0.090247 ---\n",
      "--- epoch: 839, loss: 0.099587, val_loss: 0.090200 ---\n",
      "--- epoch: 840, loss: 0.099543, val_loss: 0.090152 ---\n",
      "--- epoch: 841, loss: 0.099500, val_loss: 0.090105 ---\n",
      "--- epoch: 842, loss: 0.099456, val_loss: 0.090058 ---\n",
      "--- epoch: 843, loss: 0.099412, val_loss: 0.090012 ---\n",
      "--- epoch: 844, loss: 0.099369, val_loss: 0.089965 ---\n",
      "--- epoch: 845, loss: 0.099325, val_loss: 0.089918 ---\n",
      "--- epoch: 846, loss: 0.099282, val_loss: 0.089871 ---\n",
      "--- epoch: 847, loss: 0.099239, val_loss: 0.089825 ---\n",
      "--- epoch: 848, loss: 0.099196, val_loss: 0.089778 ---\n",
      "--- epoch: 849, loss: 0.099153, val_loss: 0.089732 ---\n",
      "--- epoch: 850, loss: 0.099110, val_loss: 0.089686 ---\n",
      "--- epoch: 851, loss: 0.099067, val_loss: 0.089640 ---\n",
      "--- epoch: 852, loss: 0.099024, val_loss: 0.089594 ---\n",
      "--- epoch: 853, loss: 0.098981, val_loss: 0.089548 ---\n",
      "--- epoch: 854, loss: 0.098939, val_loss: 0.089502 ---\n",
      "--- epoch: 855, loss: 0.098896, val_loss: 0.089456 ---\n",
      "--- epoch: 856, loss: 0.098853, val_loss: 0.089410 ---\n",
      "--- epoch: 857, loss: 0.098811, val_loss: 0.089364 ---\n",
      "--- epoch: 858, loss: 0.098769, val_loss: 0.089319 ---\n",
      "--- epoch: 859, loss: 0.098726, val_loss: 0.089273 ---\n",
      "--- epoch: 860, loss: 0.098684, val_loss: 0.089228 ---\n",
      "--- epoch: 861, loss: 0.098642, val_loss: 0.089182 ---\n",
      "--- epoch: 862, loss: 0.098600, val_loss: 0.089137 ---\n",
      "--- epoch: 863, loss: 0.098558, val_loss: 0.089092 ---\n",
      "--- epoch: 864, loss: 0.098516, val_loss: 0.089047 ---\n",
      "--- epoch: 865, loss: 0.098475, val_loss: 0.089002 ---\n",
      "--- epoch: 866, loss: 0.098433, val_loss: 0.088957 ---\n",
      "--- epoch: 867, loss: 0.098391, val_loss: 0.088912 ---\n",
      "--- epoch: 868, loss: 0.098350, val_loss: 0.088867 ---\n",
      "--- epoch: 869, loss: 0.098308, val_loss: 0.088823 ---\n",
      "--- epoch: 870, loss: 0.098267, val_loss: 0.088778 ---\n",
      "--- epoch: 871, loss: 0.098226, val_loss: 0.088733 ---\n",
      "--- epoch: 872, loss: 0.098184, val_loss: 0.088689 ---\n",
      "--- epoch: 873, loss: 0.098143, val_loss: 0.088645 ---\n",
      "--- epoch: 874, loss: 0.098102, val_loss: 0.088600 ---\n",
      "--- epoch: 875, loss: 0.098061, val_loss: 0.088556 ---\n",
      "--- epoch: 876, loss: 0.098020, val_loss: 0.088512 ---\n",
      "--- epoch: 877, loss: 0.097980, val_loss: 0.088468 ---\n",
      "--- epoch: 878, loss: 0.097939, val_loss: 0.088424 ---\n",
      "--- epoch: 879, loss: 0.097898, val_loss: 0.088380 ---\n",
      "--- epoch: 880, loss: 0.097857, val_loss: 0.088336 ---\n",
      "--- epoch: 881, loss: 0.097817, val_loss: 0.088292 ---\n",
      "--- epoch: 882, loss: 0.097777, val_loss: 0.088249 ---\n",
      "--- epoch: 883, loss: 0.097736, val_loss: 0.088205 ---\n",
      "--- epoch: 884, loss: 0.097696, val_loss: 0.088162 ---\n",
      "--- epoch: 885, loss: 0.097656, val_loss: 0.088118 ---\n",
      "--- epoch: 886, loss: 0.097616, val_loss: 0.088075 ---\n",
      "--- epoch: 887, loss: 0.097576, val_loss: 0.088032 ---\n",
      "--- epoch: 888, loss: 0.097536, val_loss: 0.087988 ---\n",
      "--- epoch: 889, loss: 0.097496, val_loss: 0.087945 ---\n",
      "--- epoch: 890, loss: 0.097456, val_loss: 0.087902 ---\n",
      "--- epoch: 891, loss: 0.097416, val_loss: 0.087859 ---\n",
      "--- epoch: 892, loss: 0.097376, val_loss: 0.087816 ---\n",
      "--- epoch: 893, loss: 0.097337, val_loss: 0.087773 ---\n",
      "--- epoch: 894, loss: 0.097297, val_loss: 0.087731 ---\n",
      "--- epoch: 895, loss: 0.097258, val_loss: 0.087688 ---\n",
      "--- epoch: 896, loss: 0.097218, val_loss: 0.087645 ---\n",
      "--- epoch: 897, loss: 0.097179, val_loss: 0.087603 ---\n",
      "--- epoch: 898, loss: 0.097140, val_loss: 0.087560 ---\n",
      "--- epoch: 899, loss: 0.097101, val_loss: 0.087518 ---\n",
      "--- epoch: 900, loss: 0.097061, val_loss: 0.087476 ---\n",
      "--- epoch: 901, loss: 0.097022, val_loss: 0.087433 ---\n",
      "--- epoch: 902, loss: 0.096983, val_loss: 0.087391 ---\n",
      "--- epoch: 903, loss: 0.096945, val_loss: 0.087349 ---\n",
      "--- epoch: 904, loss: 0.096906, val_loss: 0.087307 ---\n",
      "--- epoch: 905, loss: 0.096867, val_loss: 0.087265 ---\n",
      "--- epoch: 906, loss: 0.096828, val_loss: 0.087223 ---\n",
      "--- epoch: 907, loss: 0.096790, val_loss: 0.087181 ---\n",
      "--- epoch: 908, loss: 0.096751, val_loss: 0.087140 ---\n",
      "--- epoch: 909, loss: 0.096713, val_loss: 0.087098 ---\n",
      "--- epoch: 910, loss: 0.096674, val_loss: 0.087057 ---\n",
      "--- epoch: 911, loss: 0.096636, val_loss: 0.087015 ---\n",
      "--- epoch: 912, loss: 0.096598, val_loss: 0.086974 ---\n",
      "--- epoch: 913, loss: 0.096560, val_loss: 0.086932 ---\n",
      "--- epoch: 914, loss: 0.096522, val_loss: 0.086891 ---\n",
      "--- epoch: 915, loss: 0.096484, val_loss: 0.086850 ---\n",
      "--- epoch: 916, loss: 0.096446, val_loss: 0.086809 ---\n",
      "--- epoch: 917, loss: 0.096408, val_loss: 0.086767 ---\n",
      "--- epoch: 918, loss: 0.096370, val_loss: 0.086726 ---\n",
      "--- epoch: 919, loss: 0.096332, val_loss: 0.086685 ---\n",
      "--- epoch: 920, loss: 0.096294, val_loss: 0.086645 ---\n",
      "--- epoch: 921, loss: 0.096257, val_loss: 0.086604 ---\n",
      "--- epoch: 922, loss: 0.096219, val_loss: 0.086563 ---\n",
      "--- epoch: 923, loss: 0.096182, val_loss: 0.086522 ---\n",
      "--- epoch: 924, loss: 0.096144, val_loss: 0.086482 ---\n",
      "--- epoch: 925, loss: 0.096107, val_loss: 0.086441 ---\n",
      "--- epoch: 926, loss: 0.096070, val_loss: 0.086401 ---\n",
      "--- epoch: 927, loss: 0.096032, val_loss: 0.086360 ---\n",
      "--- epoch: 928, loss: 0.095995, val_loss: 0.086320 ---\n",
      "--- epoch: 929, loss: 0.095958, val_loss: 0.086280 ---\n",
      "--- epoch: 930, loss: 0.095921, val_loss: 0.086240 ---\n",
      "--- epoch: 931, loss: 0.095884, val_loss: 0.086199 ---\n",
      "--- epoch: 932, loss: 0.095847, val_loss: 0.086159 ---\n",
      "--- epoch: 933, loss: 0.095811, val_loss: 0.086119 ---\n",
      "--- epoch: 934, loss: 0.095774, val_loss: 0.086080 ---\n",
      "--- epoch: 935, loss: 0.095737, val_loss: 0.086040 ---\n",
      "--- epoch: 936, loss: 0.095701, val_loss: 0.086000 ---\n",
      "--- epoch: 937, loss: 0.095664, val_loss: 0.085960 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 938, loss: 0.095628, val_loss: 0.085921 ---\n",
      "--- epoch: 939, loss: 0.095591, val_loss: 0.085881 ---\n",
      "--- epoch: 940, loss: 0.095555, val_loss: 0.085841 ---\n",
      "--- epoch: 941, loss: 0.095519, val_loss: 0.085802 ---\n",
      "--- epoch: 942, loss: 0.095482, val_loss: 0.085763 ---\n",
      "--- epoch: 943, loss: 0.095446, val_loss: 0.085723 ---\n",
      "--- epoch: 944, loss: 0.095410, val_loss: 0.085684 ---\n",
      "--- epoch: 945, loss: 0.095374, val_loss: 0.085645 ---\n",
      "--- epoch: 946, loss: 0.095338, val_loss: 0.085606 ---\n",
      "--- epoch: 947, loss: 0.095302, val_loss: 0.085567 ---\n",
      "--- epoch: 948, loss: 0.095266, val_loss: 0.085528 ---\n",
      "--- epoch: 949, loss: 0.095230, val_loss: 0.085489 ---\n",
      "--- epoch: 950, loss: 0.095195, val_loss: 0.085450 ---\n",
      "--- epoch: 951, loss: 0.095159, val_loss: 0.085411 ---\n",
      "--- epoch: 952, loss: 0.095124, val_loss: 0.085372 ---\n",
      "--- epoch: 953, loss: 0.095088, val_loss: 0.085334 ---\n",
      "--- epoch: 954, loss: 0.095052, val_loss: 0.085295 ---\n",
      "--- epoch: 955, loss: 0.095017, val_loss: 0.085256 ---\n",
      "--- epoch: 956, loss: 0.094982, val_loss: 0.085218 ---\n",
      "--- epoch: 957, loss: 0.094946, val_loss: 0.085180 ---\n",
      "--- epoch: 958, loss: 0.094911, val_loss: 0.085141 ---\n",
      "--- epoch: 959, loss: 0.094876, val_loss: 0.085103 ---\n",
      "--- epoch: 960, loss: 0.094841, val_loss: 0.085065 ---\n",
      "--- epoch: 961, loss: 0.094806, val_loss: 0.085027 ---\n",
      "--- epoch: 962, loss: 0.094771, val_loss: 0.084988 ---\n",
      "--- epoch: 963, loss: 0.094736, val_loss: 0.084950 ---\n",
      "--- epoch: 964, loss: 0.094701, val_loss: 0.084912 ---\n",
      "--- epoch: 965, loss: 0.094666, val_loss: 0.084874 ---\n",
      "--- epoch: 966, loss: 0.094632, val_loss: 0.084837 ---\n",
      "--- epoch: 967, loss: 0.094597, val_loss: 0.084799 ---\n",
      "--- epoch: 968, loss: 0.094562, val_loss: 0.084761 ---\n",
      "--- epoch: 969, loss: 0.094528, val_loss: 0.084723 ---\n",
      "--- epoch: 970, loss: 0.094493, val_loss: 0.084686 ---\n",
      "--- epoch: 971, loss: 0.094459, val_loss: 0.084648 ---\n",
      "--- epoch: 972, loss: 0.094425, val_loss: 0.084611 ---\n",
      "--- epoch: 973, loss: 0.094390, val_loss: 0.084573 ---\n",
      "--- epoch: 974, loss: 0.094356, val_loss: 0.084536 ---\n",
      "--- epoch: 975, loss: 0.094322, val_loss: 0.084499 ---\n",
      "--- epoch: 976, loss: 0.094288, val_loss: 0.084461 ---\n",
      "--- epoch: 977, loss: 0.094254, val_loss: 0.084424 ---\n",
      "--- epoch: 978, loss: 0.094220, val_loss: 0.084387 ---\n",
      "--- epoch: 979, loss: 0.094186, val_loss: 0.084350 ---\n",
      "--- epoch: 980, loss: 0.094152, val_loss: 0.084313 ---\n",
      "--- epoch: 981, loss: 0.094118, val_loss: 0.084276 ---\n",
      "--- epoch: 982, loss: 0.094084, val_loss: 0.084239 ---\n",
      "--- epoch: 983, loss: 0.094050, val_loss: 0.084202 ---\n",
      "--- epoch: 984, loss: 0.094017, val_loss: 0.084166 ---\n",
      "--- epoch: 985, loss: 0.093983, val_loss: 0.084129 ---\n",
      "--- epoch: 986, loss: 0.093950, val_loss: 0.084092 ---\n",
      "--- epoch: 987, loss: 0.093916, val_loss: 0.084056 ---\n",
      "--- epoch: 988, loss: 0.093883, val_loss: 0.084019 ---\n",
      "--- epoch: 989, loss: 0.093849, val_loss: 0.083983 ---\n",
      "--- epoch: 990, loss: 0.093816, val_loss: 0.083946 ---\n",
      "--- epoch: 991, loss: 0.093783, val_loss: 0.083910 ---\n",
      "--- epoch: 992, loss: 0.093749, val_loss: 0.083874 ---\n",
      "--- epoch: 993, loss: 0.093716, val_loss: 0.083837 ---\n",
      "--- epoch: 994, loss: 0.093683, val_loss: 0.083801 ---\n",
      "--- epoch: 995, loss: 0.093650, val_loss: 0.083765 ---\n",
      "--- epoch: 996, loss: 0.093617, val_loss: 0.083729 ---\n",
      "--- epoch: 997, loss: 0.093584, val_loss: 0.083693 ---\n",
      "--- epoch: 998, loss: 0.093551, val_loss: 0.083657 ---\n",
      "--- epoch: 999, loss: 0.093518, val_loss: 0.083621 ---\n",
      "--- epoch: 1000, loss: 0.093486, val_loss: 0.083585 ---\n",
      "--- epoch: 1001, loss: 0.093453, val_loss: 0.083549 ---\n",
      "--- epoch: 1002, loss: 0.093420, val_loss: 0.083514 ---\n",
      "--- epoch: 1003, loss: 0.093388, val_loss: 0.083478 ---\n",
      "--- epoch: 1004, loss: 0.093355, val_loss: 0.083442 ---\n",
      "--- epoch: 1005, loss: 0.093323, val_loss: 0.083407 ---\n",
      "--- epoch: 1006, loss: 0.093290, val_loss: 0.083371 ---\n",
      "--- epoch: 1007, loss: 0.093258, val_loss: 0.083336 ---\n",
      "--- epoch: 1008, loss: 0.093226, val_loss: 0.083300 ---\n",
      "--- epoch: 1009, loss: 0.093193, val_loss: 0.083265 ---\n",
      "--- epoch: 1010, loss: 0.093161, val_loss: 0.083230 ---\n",
      "--- epoch: 1011, loss: 0.093129, val_loss: 0.083195 ---\n",
      "--- epoch: 1012, loss: 0.093097, val_loss: 0.083159 ---\n",
      "--- epoch: 1013, loss: 0.093065, val_loss: 0.083124 ---\n",
      "--- epoch: 1014, loss: 0.093033, val_loss: 0.083089 ---\n",
      "--- epoch: 1015, loss: 0.093001, val_loss: 0.083054 ---\n",
      "--- epoch: 1016, loss: 0.092969, val_loss: 0.083019 ---\n",
      "--- epoch: 1017, loss: 0.092937, val_loss: 0.082984 ---\n",
      "--- epoch: 1018, loss: 0.092905, val_loss: 0.082949 ---\n",
      "--- epoch: 1019, loss: 0.092873, val_loss: 0.082915 ---\n",
      "--- epoch: 1020, loss: 0.092842, val_loss: 0.082880 ---\n",
      "--- epoch: 1021, loss: 0.092810, val_loss: 0.082845 ---\n",
      "--- epoch: 1022, loss: 0.092778, val_loss: 0.082811 ---\n",
      "--- epoch: 1023, loss: 0.092747, val_loss: 0.082776 ---\n",
      "--- epoch: 1024, loss: 0.092715, val_loss: 0.082741 ---\n",
      "--- epoch: 1025, loss: 0.092684, val_loss: 0.082707 ---\n",
      "--- epoch: 1026, loss: 0.092653, val_loss: 0.082673 ---\n",
      "--- epoch: 1027, loss: 0.092621, val_loss: 0.082638 ---\n",
      "--- epoch: 1028, loss: 0.092590, val_loss: 0.082604 ---\n",
      "--- epoch: 1029, loss: 0.092559, val_loss: 0.082570 ---\n",
      "--- epoch: 1030, loss: 0.092528, val_loss: 0.082535 ---\n",
      "--- epoch: 1031, loss: 0.092496, val_loss: 0.082501 ---\n",
      "--- epoch: 1032, loss: 0.092465, val_loss: 0.082467 ---\n",
      "--- epoch: 1033, loss: 0.092434, val_loss: 0.082433 ---\n",
      "--- epoch: 1034, loss: 0.092403, val_loss: 0.082399 ---\n",
      "--- epoch: 1035, loss: 0.092372, val_loss: 0.082365 ---\n",
      "--- epoch: 1036, loss: 0.092342, val_loss: 0.082331 ---\n",
      "--- epoch: 1037, loss: 0.092311, val_loss: 0.082297 ---\n",
      "--- epoch: 1038, loss: 0.092280, val_loss: 0.082263 ---\n",
      "--- epoch: 1039, loss: 0.092249, val_loss: 0.082230 ---\n",
      "--- epoch: 1040, loss: 0.092219, val_loss: 0.082196 ---\n",
      "--- epoch: 1041, loss: 0.092188, val_loss: 0.082162 ---\n",
      "--- epoch: 1042, loss: 0.092157, val_loss: 0.082129 ---\n",
      "--- epoch: 1043, loss: 0.092127, val_loss: 0.082095 ---\n",
      "--- epoch: 1044, loss: 0.092096, val_loss: 0.082062 ---\n",
      "--- epoch: 1045, loss: 0.092066, val_loss: 0.082028 ---\n",
      "--- epoch: 1046, loss: 0.092036, val_loss: 0.081995 ---\n",
      "--- epoch: 1047, loss: 0.092005, val_loss: 0.081962 ---\n",
      "--- epoch: 1048, loss: 0.091975, val_loss: 0.081928 ---\n",
      "--- epoch: 1049, loss: 0.091945, val_loss: 0.081895 ---\n",
      "--- epoch: 1050, loss: 0.091915, val_loss: 0.081862 ---\n",
      "--- epoch: 1051, loss: 0.091884, val_loss: 0.081829 ---\n",
      "--- epoch: 1052, loss: 0.091854, val_loss: 0.081796 ---\n",
      "--- epoch: 1053, loss: 0.091824, val_loss: 0.081763 ---\n",
      "--- epoch: 1054, loss: 0.091794, val_loss: 0.081730 ---\n",
      "--- epoch: 1055, loss: 0.091764, val_loss: 0.081697 ---\n",
      "--- epoch: 1056, loss: 0.091735, val_loss: 0.081664 ---\n",
      "--- epoch: 1057, loss: 0.091705, val_loss: 0.081631 ---\n",
      "--- epoch: 1058, loss: 0.091675, val_loss: 0.081598 ---\n",
      "--- epoch: 1059, loss: 0.091645, val_loss: 0.081565 ---\n",
      "--- epoch: 1060, loss: 0.091615, val_loss: 0.081533 ---\n",
      "--- epoch: 1061, loss: 0.091586, val_loss: 0.081500 ---\n",
      "--- epoch: 1062, loss: 0.091556, val_loss: 0.081467 ---\n",
      "--- epoch: 1063, loss: 0.091527, val_loss: 0.081435 ---\n",
      "--- epoch: 1064, loss: 0.091497, val_loss: 0.081402 ---\n",
      "--- epoch: 1065, loss: 0.091468, val_loss: 0.081370 ---\n",
      "--- epoch: 1066, loss: 0.091438, val_loss: 0.081338 ---\n",
      "--- epoch: 1067, loss: 0.091409, val_loss: 0.081305 ---\n",
      "--- epoch: 1068, loss: 0.091380, val_loss: 0.081273 ---\n",
      "--- epoch: 1069, loss: 0.091350, val_loss: 0.081241 ---\n",
      "--- epoch: 1070, loss: 0.091321, val_loss: 0.081208 ---\n",
      "--- epoch: 1071, loss: 0.091292, val_loss: 0.081176 ---\n",
      "--- epoch: 1072, loss: 0.091263, val_loss: 0.081144 ---\n",
      "--- epoch: 1073, loss: 0.091234, val_loss: 0.081112 ---\n",
      "--- epoch: 1074, loss: 0.091205, val_loss: 0.081080 ---\n",
      "--- epoch: 1075, loss: 0.091176, val_loss: 0.081048 ---\n",
      "--- epoch: 1076, loss: 0.091147, val_loss: 0.081016 ---\n",
      "--- epoch: 1077, loss: 0.091118, val_loss: 0.080984 ---\n",
      "--- epoch: 1078, loss: 0.091089, val_loss: 0.080952 ---\n",
      "--- epoch: 1079, loss: 0.091060, val_loss: 0.080921 ---\n",
      "--- epoch: 1080, loss: 0.091031, val_loss: 0.080889 ---\n",
      "--- epoch: 1081, loss: 0.091002, val_loss: 0.080857 ---\n",
      "--- epoch: 1082, loss: 0.090974, val_loss: 0.080825 ---\n",
      "--- epoch: 1083, loss: 0.090945, val_loss: 0.080794 ---\n",
      "--- epoch: 1084, loss: 0.090917, val_loss: 0.080762 ---\n",
      "--- epoch: 1085, loss: 0.090888, val_loss: 0.080731 ---\n",
      "--- epoch: 1086, loss: 0.090859, val_loss: 0.080699 ---\n",
      "--- epoch: 1087, loss: 0.090831, val_loss: 0.080668 ---\n",
      "--- epoch: 1088, loss: 0.090803, val_loss: 0.080637 ---\n",
      "--- epoch: 1089, loss: 0.090774, val_loss: 0.080605 ---\n",
      "--- epoch: 1090, loss: 0.090746, val_loss: 0.080574 ---\n",
      "--- epoch: 1091, loss: 0.090718, val_loss: 0.080543 ---\n",
      "--- epoch: 1092, loss: 0.090689, val_loss: 0.080511 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1093, loss: 0.090661, val_loss: 0.080480 ---\n",
      "--- epoch: 1094, loss: 0.090633, val_loss: 0.080449 ---\n",
      "--- epoch: 1095, loss: 0.090605, val_loss: 0.080418 ---\n",
      "--- epoch: 1096, loss: 0.090577, val_loss: 0.080387 ---\n",
      "--- epoch: 1097, loss: 0.090549, val_loss: 0.080356 ---\n",
      "--- epoch: 1098, loss: 0.090521, val_loss: 0.080325 ---\n",
      "--- epoch: 1099, loss: 0.090493, val_loss: 0.080294 ---\n",
      "--- epoch: 1100, loss: 0.090465, val_loss: 0.080264 ---\n",
      "--- epoch: 1101, loss: 0.090437, val_loss: 0.080233 ---\n",
      "--- epoch: 1102, loss: 0.090409, val_loss: 0.080202 ---\n",
      "--- epoch: 1103, loss: 0.090382, val_loss: 0.080171 ---\n",
      "--- epoch: 1104, loss: 0.090354, val_loss: 0.080141 ---\n",
      "--- epoch: 1105, loss: 0.090326, val_loss: 0.080110 ---\n",
      "--- epoch: 1106, loss: 0.090298, val_loss: 0.080079 ---\n",
      "--- epoch: 1107, loss: 0.090271, val_loss: 0.080049 ---\n",
      "--- epoch: 1108, loss: 0.090243, val_loss: 0.080018 ---\n",
      "--- epoch: 1109, loss: 0.090216, val_loss: 0.079988 ---\n",
      "--- epoch: 1110, loss: 0.090188, val_loss: 0.079958 ---\n",
      "--- epoch: 1111, loss: 0.090161, val_loss: 0.079927 ---\n",
      "--- epoch: 1112, loss: 0.090133, val_loss: 0.079897 ---\n",
      "--- epoch: 1113, loss: 0.090106, val_loss: 0.079867 ---\n",
      "--- epoch: 1114, loss: 0.090079, val_loss: 0.079836 ---\n",
      "--- epoch: 1115, loss: 0.090052, val_loss: 0.079806 ---\n",
      "--- epoch: 1116, loss: 0.090024, val_loss: 0.079776 ---\n",
      "--- epoch: 1117, loss: 0.089997, val_loss: 0.079746 ---\n",
      "--- epoch: 1118, loss: 0.089970, val_loss: 0.079716 ---\n",
      "--- epoch: 1119, loss: 0.089943, val_loss: 0.079686 ---\n",
      "--- epoch: 1120, loss: 0.089916, val_loss: 0.079656 ---\n",
      "--- epoch: 1121, loss: 0.089889, val_loss: 0.079626 ---\n",
      "--- epoch: 1122, loss: 0.089862, val_loss: 0.079596 ---\n",
      "--- epoch: 1123, loss: 0.089835, val_loss: 0.079566 ---\n",
      "--- epoch: 1124, loss: 0.089808, val_loss: 0.079537 ---\n",
      "--- epoch: 1125, loss: 0.089781, val_loss: 0.079507 ---\n",
      "--- epoch: 1126, loss: 0.089754, val_loss: 0.079477 ---\n",
      "--- epoch: 1127, loss: 0.089728, val_loss: 0.079447 ---\n",
      "--- epoch: 1128, loss: 0.089701, val_loss: 0.079418 ---\n",
      "--- epoch: 1129, loss: 0.089674, val_loss: 0.079388 ---\n",
      "--- epoch: 1130, loss: 0.089647, val_loss: 0.079359 ---\n",
      "--- epoch: 1131, loss: 0.089621, val_loss: 0.079329 ---\n",
      "--- epoch: 1132, loss: 0.089594, val_loss: 0.079300 ---\n",
      "--- epoch: 1133, loss: 0.089568, val_loss: 0.079270 ---\n",
      "--- epoch: 1134, loss: 0.089541, val_loss: 0.079241 ---\n",
      "--- epoch: 1135, loss: 0.089515, val_loss: 0.079211 ---\n",
      "--- epoch: 1136, loss: 0.089488, val_loss: 0.079182 ---\n",
      "--- epoch: 1137, loss: 0.089462, val_loss: 0.079153 ---\n",
      "--- epoch: 1138, loss: 0.089436, val_loss: 0.079124 ---\n",
      "--- epoch: 1139, loss: 0.089409, val_loss: 0.079094 ---\n",
      "--- epoch: 1140, loss: 0.089383, val_loss: 0.079065 ---\n",
      "--- epoch: 1141, loss: 0.089357, val_loss: 0.079036 ---\n",
      "--- epoch: 1142, loss: 0.089331, val_loss: 0.079007 ---\n",
      "--- epoch: 1143, loss: 0.089305, val_loss: 0.078978 ---\n",
      "--- epoch: 1144, loss: 0.089278, val_loss: 0.078949 ---\n",
      "--- epoch: 1145, loss: 0.089252, val_loss: 0.078920 ---\n",
      "--- epoch: 1146, loss: 0.089226, val_loss: 0.078891 ---\n",
      "--- epoch: 1147, loss: 0.089200, val_loss: 0.078862 ---\n",
      "--- epoch: 1148, loss: 0.089174, val_loss: 0.078834 ---\n",
      "--- epoch: 1149, loss: 0.089148, val_loss: 0.078805 ---\n",
      "--- epoch: 1150, loss: 0.089123, val_loss: 0.078776 ---\n",
      "--- epoch: 1151, loss: 0.089097, val_loss: 0.078747 ---\n",
      "--- epoch: 1152, loss: 0.089071, val_loss: 0.078719 ---\n",
      "--- epoch: 1153, loss: 0.089045, val_loss: 0.078690 ---\n",
      "--- epoch: 1154, loss: 0.089019, val_loss: 0.078662 ---\n",
      "--- epoch: 1155, loss: 0.088994, val_loss: 0.078633 ---\n",
      "--- epoch: 1156, loss: 0.088968, val_loss: 0.078605 ---\n",
      "--- epoch: 1157, loss: 0.088943, val_loss: 0.078576 ---\n",
      "--- epoch: 1158, loss: 0.088917, val_loss: 0.078548 ---\n",
      "--- epoch: 1159, loss: 0.088891, val_loss: 0.078519 ---\n",
      "--- epoch: 1160, loss: 0.088866, val_loss: 0.078491 ---\n",
      "--- epoch: 1161, loss: 0.088841, val_loss: 0.078463 ---\n",
      "--- epoch: 1162, loss: 0.088815, val_loss: 0.078434 ---\n",
      "--- epoch: 1163, loss: 0.088790, val_loss: 0.078406 ---\n",
      "--- epoch: 1164, loss: 0.088764, val_loss: 0.078378 ---\n",
      "--- epoch: 1165, loss: 0.088739, val_loss: 0.078350 ---\n",
      "--- epoch: 1166, loss: 0.088714, val_loss: 0.078322 ---\n",
      "--- epoch: 1167, loss: 0.088689, val_loss: 0.078294 ---\n",
      "--- epoch: 1168, loss: 0.088663, val_loss: 0.078265 ---\n",
      "--- epoch: 1169, loss: 0.088638, val_loss: 0.078237 ---\n",
      "--- epoch: 1170, loss: 0.088613, val_loss: 0.078210 ---\n",
      "--- epoch: 1171, loss: 0.088588, val_loss: 0.078182 ---\n",
      "--- epoch: 1172, loss: 0.088563, val_loss: 0.078154 ---\n",
      "--- epoch: 1173, loss: 0.088538, val_loss: 0.078126 ---\n",
      "--- epoch: 1174, loss: 0.088513, val_loss: 0.078098 ---\n",
      "--- epoch: 1175, loss: 0.088488, val_loss: 0.078070 ---\n",
      "--- epoch: 1176, loss: 0.088463, val_loss: 0.078043 ---\n",
      "--- epoch: 1177, loss: 0.088438, val_loss: 0.078015 ---\n",
      "--- epoch: 1178, loss: 0.088413, val_loss: 0.077987 ---\n",
      "--- epoch: 1179, loss: 0.088389, val_loss: 0.077960 ---\n",
      "--- epoch: 1180, loss: 0.088364, val_loss: 0.077932 ---\n",
      "--- epoch: 1181, loss: 0.088339, val_loss: 0.077904 ---\n",
      "--- epoch: 1182, loss: 0.088314, val_loss: 0.077877 ---\n",
      "--- epoch: 1183, loss: 0.088290, val_loss: 0.077849 ---\n",
      "--- epoch: 1184, loss: 0.088265, val_loss: 0.077822 ---\n",
      "--- epoch: 1185, loss: 0.088240, val_loss: 0.077795 ---\n",
      "--- epoch: 1186, loss: 0.088216, val_loss: 0.077767 ---\n",
      "--- epoch: 1187, loss: 0.088191, val_loss: 0.077740 ---\n",
      "--- epoch: 1188, loss: 0.088167, val_loss: 0.077713 ---\n",
      "--- epoch: 1189, loss: 0.088142, val_loss: 0.077685 ---\n",
      "--- epoch: 1190, loss: 0.088118, val_loss: 0.077658 ---\n",
      "--- epoch: 1191, loss: 0.088094, val_loss: 0.077631 ---\n",
      "--- epoch: 1192, loss: 0.088069, val_loss: 0.077604 ---\n",
      "--- epoch: 1193, loss: 0.088045, val_loss: 0.077577 ---\n",
      "--- epoch: 1194, loss: 0.088021, val_loss: 0.077549 ---\n",
      "--- epoch: 1195, loss: 0.087996, val_loss: 0.077522 ---\n",
      "--- epoch: 1196, loss: 0.087972, val_loss: 0.077495 ---\n",
      "--- epoch: 1197, loss: 0.087948, val_loss: 0.077468 ---\n",
      "--- epoch: 1198, loss: 0.087924, val_loss: 0.077442 ---\n",
      "--- epoch: 1199, loss: 0.087900, val_loss: 0.077415 ---\n",
      "--- epoch: 1200, loss: 0.087876, val_loss: 0.077388 ---\n",
      "--- epoch: 1201, loss: 0.087852, val_loss: 0.077361 ---\n",
      "--- epoch: 1202, loss: 0.087828, val_loss: 0.077334 ---\n",
      "--- epoch: 1203, loss: 0.087804, val_loss: 0.077307 ---\n",
      "--- epoch: 1204, loss: 0.087780, val_loss: 0.077281 ---\n",
      "--- epoch: 1205, loss: 0.087756, val_loss: 0.077254 ---\n",
      "--- epoch: 1206, loss: 0.087732, val_loss: 0.077227 ---\n",
      "--- epoch: 1207, loss: 0.087708, val_loss: 0.077201 ---\n",
      "--- epoch: 1208, loss: 0.087684, val_loss: 0.077174 ---\n",
      "--- epoch: 1209, loss: 0.087661, val_loss: 0.077148 ---\n",
      "--- epoch: 1210, loss: 0.087637, val_loss: 0.077121 ---\n",
      "--- epoch: 1211, loss: 0.087613, val_loss: 0.077095 ---\n",
      "--- epoch: 1212, loss: 0.087590, val_loss: 0.077068 ---\n",
      "--- epoch: 1213, loss: 0.087566, val_loss: 0.077042 ---\n",
      "--- epoch: 1214, loss: 0.087542, val_loss: 0.077015 ---\n",
      "--- epoch: 1215, loss: 0.087519, val_loss: 0.076989 ---\n",
      "--- epoch: 1216, loss: 0.087495, val_loss: 0.076963 ---\n",
      "--- epoch: 1217, loss: 0.087472, val_loss: 0.076936 ---\n",
      "--- epoch: 1218, loss: 0.087448, val_loss: 0.076910 ---\n",
      "--- epoch: 1219, loss: 0.087425, val_loss: 0.076884 ---\n",
      "--- epoch: 1220, loss: 0.087401, val_loss: 0.076858 ---\n",
      "--- epoch: 1221, loss: 0.087378, val_loss: 0.076832 ---\n",
      "--- epoch: 1222, loss: 0.087355, val_loss: 0.076805 ---\n",
      "--- epoch: 1223, loss: 0.087331, val_loss: 0.076779 ---\n",
      "--- epoch: 1224, loss: 0.087308, val_loss: 0.076753 ---\n",
      "--- epoch: 1225, loss: 0.087285, val_loss: 0.076727 ---\n",
      "--- epoch: 1226, loss: 0.087262, val_loss: 0.076701 ---\n",
      "--- epoch: 1227, loss: 0.087238, val_loss: 0.076675 ---\n",
      "--- epoch: 1228, loss: 0.087215, val_loss: 0.076650 ---\n",
      "--- epoch: 1229, loss: 0.087192, val_loss: 0.076624 ---\n",
      "--- epoch: 1230, loss: 0.087169, val_loss: 0.076598 ---\n",
      "--- epoch: 1231, loss: 0.087146, val_loss: 0.076572 ---\n",
      "--- epoch: 1232, loss: 0.087123, val_loss: 0.076546 ---\n",
      "--- epoch: 1233, loss: 0.087100, val_loss: 0.076521 ---\n",
      "--- epoch: 1234, loss: 0.087077, val_loss: 0.076495 ---\n",
      "--- epoch: 1235, loss: 0.087054, val_loss: 0.076469 ---\n",
      "--- epoch: 1236, loss: 0.087031, val_loss: 0.076444 ---\n",
      "--- epoch: 1237, loss: 0.087008, val_loss: 0.076418 ---\n",
      "--- epoch: 1238, loss: 0.086986, val_loss: 0.076392 ---\n",
      "--- epoch: 1239, loss: 0.086963, val_loss: 0.076367 ---\n",
      "--- epoch: 1240, loss: 0.086940, val_loss: 0.076341 ---\n",
      "--- epoch: 1241, loss: 0.086917, val_loss: 0.076316 ---\n",
      "--- epoch: 1242, loss: 0.086895, val_loss: 0.076290 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1243, loss: 0.086872, val_loss: 0.076265 ---\n",
      "--- epoch: 1244, loss: 0.086849, val_loss: 0.076240 ---\n",
      "--- epoch: 1245, loss: 0.086827, val_loss: 0.076214 ---\n",
      "--- epoch: 1246, loss: 0.086804, val_loss: 0.076189 ---\n",
      "--- epoch: 1247, loss: 0.086782, val_loss: 0.076164 ---\n",
      "--- epoch: 1248, loss: 0.086759, val_loss: 0.076138 ---\n",
      "--- epoch: 1249, loss: 0.086737, val_loss: 0.076113 ---\n",
      "--- epoch: 1250, loss: 0.086714, val_loss: 0.076088 ---\n",
      "--- epoch: 1251, loss: 0.086692, val_loss: 0.076063 ---\n",
      "--- epoch: 1252, loss: 0.086669, val_loss: 0.076038 ---\n",
      "--- epoch: 1253, loss: 0.086647, val_loss: 0.076013 ---\n",
      "--- epoch: 1254, loss: 0.086625, val_loss: 0.075988 ---\n",
      "--- epoch: 1255, loss: 0.086602, val_loss: 0.075963 ---\n",
      "--- epoch: 1256, loss: 0.086580, val_loss: 0.075938 ---\n",
      "--- epoch: 1257, loss: 0.086558, val_loss: 0.075913 ---\n",
      "--- epoch: 1258, loss: 0.086536, val_loss: 0.075888 ---\n",
      "--- epoch: 1259, loss: 0.086513, val_loss: 0.075863 ---\n",
      "--- epoch: 1260, loss: 0.086491, val_loss: 0.075838 ---\n",
      "--- epoch: 1261, loss: 0.086469, val_loss: 0.075813 ---\n",
      "--- epoch: 1262, loss: 0.086447, val_loss: 0.075788 ---\n",
      "--- epoch: 1263, loss: 0.086425, val_loss: 0.075764 ---\n",
      "--- epoch: 1264, loss: 0.086403, val_loss: 0.075739 ---\n",
      "--- epoch: 1265, loss: 0.086381, val_loss: 0.075714 ---\n",
      "--- epoch: 1266, loss: 0.086359, val_loss: 0.075689 ---\n",
      "--- epoch: 1267, loss: 0.086337, val_loss: 0.075665 ---\n",
      "--- epoch: 1268, loss: 0.086315, val_loss: 0.075640 ---\n",
      "--- epoch: 1269, loss: 0.086293, val_loss: 0.075616 ---\n",
      "--- epoch: 1270, loss: 0.086271, val_loss: 0.075591 ---\n",
      "--- epoch: 1271, loss: 0.086250, val_loss: 0.075566 ---\n",
      "--- epoch: 1272, loss: 0.086228, val_loss: 0.075542 ---\n",
      "--- epoch: 1273, loss: 0.086206, val_loss: 0.075517 ---\n",
      "--- epoch: 1274, loss: 0.086184, val_loss: 0.075493 ---\n",
      "--- epoch: 1275, loss: 0.086162, val_loss: 0.075469 ---\n",
      "--- epoch: 1276, loss: 0.086141, val_loss: 0.075444 ---\n",
      "--- epoch: 1277, loss: 0.086119, val_loss: 0.075420 ---\n",
      "--- epoch: 1278, loss: 0.086098, val_loss: 0.075396 ---\n",
      "--- epoch: 1279, loss: 0.086076, val_loss: 0.075371 ---\n",
      "--- epoch: 1280, loss: 0.086054, val_loss: 0.075347 ---\n",
      "--- epoch: 1281, loss: 0.086033, val_loss: 0.075323 ---\n",
      "--- epoch: 1282, loss: 0.086011, val_loss: 0.075299 ---\n",
      "--- epoch: 1283, loss: 0.085990, val_loss: 0.075275 ---\n",
      "--- epoch: 1284, loss: 0.085968, val_loss: 0.075250 ---\n",
      "--- epoch: 1285, loss: 0.085947, val_loss: 0.075226 ---\n",
      "--- epoch: 1286, loss: 0.085926, val_loss: 0.075202 ---\n",
      "--- epoch: 1287, loss: 0.085904, val_loss: 0.075178 ---\n",
      "--- epoch: 1288, loss: 0.085883, val_loss: 0.075154 ---\n",
      "--- epoch: 1289, loss: 0.085862, val_loss: 0.075130 ---\n",
      "--- epoch: 1290, loss: 0.085840, val_loss: 0.075106 ---\n",
      "--- epoch: 1291, loss: 0.085819, val_loss: 0.075082 ---\n",
      "--- epoch: 1292, loss: 0.085798, val_loss: 0.075058 ---\n",
      "--- epoch: 1293, loss: 0.085777, val_loss: 0.075035 ---\n",
      "--- epoch: 1294, loss: 0.085755, val_loss: 0.075011 ---\n",
      "--- epoch: 1295, loss: 0.085734, val_loss: 0.074987 ---\n",
      "--- epoch: 1296, loss: 0.085713, val_loss: 0.074963 ---\n",
      "--- epoch: 1297, loss: 0.085692, val_loss: 0.074939 ---\n",
      "--- epoch: 1298, loss: 0.085671, val_loss: 0.074916 ---\n",
      "--- epoch: 1299, loss: 0.085650, val_loss: 0.074892 ---\n",
      "--- epoch: 1300, loss: 0.085629, val_loss: 0.074868 ---\n",
      "--- epoch: 1301, loss: 0.085608, val_loss: 0.074845 ---\n",
      "--- epoch: 1302, loss: 0.085587, val_loss: 0.074821 ---\n",
      "--- epoch: 1303, loss: 0.085566, val_loss: 0.074797 ---\n",
      "--- epoch: 1304, loss: 0.085545, val_loss: 0.074774 ---\n",
      "--- epoch: 1305, loss: 0.085524, val_loss: 0.074750 ---\n",
      "--- epoch: 1306, loss: 0.085504, val_loss: 0.074727 ---\n",
      "--- epoch: 1307, loss: 0.085483, val_loss: 0.074703 ---\n",
      "--- epoch: 1308, loss: 0.085462, val_loss: 0.074680 ---\n",
      "--- epoch: 1309, loss: 0.085441, val_loss: 0.074657 ---\n",
      "--- epoch: 1310, loss: 0.085420, val_loss: 0.074633 ---\n",
      "--- epoch: 1311, loss: 0.085400, val_loss: 0.074610 ---\n",
      "--- epoch: 1312, loss: 0.085379, val_loss: 0.074587 ---\n",
      "--- epoch: 1313, loss: 0.085358, val_loss: 0.074563 ---\n",
      "--- epoch: 1314, loss: 0.085338, val_loss: 0.074540 ---\n",
      "--- epoch: 1315, loss: 0.085317, val_loss: 0.074517 ---\n",
      "--- epoch: 1316, loss: 0.085297, val_loss: 0.074494 ---\n",
      "--- epoch: 1317, loss: 0.085276, val_loss: 0.074470 ---\n",
      "--- epoch: 1318, loss: 0.085256, val_loss: 0.074447 ---\n",
      "--- epoch: 1319, loss: 0.085235, val_loss: 0.074424 ---\n",
      "--- epoch: 1320, loss: 0.085215, val_loss: 0.074401 ---\n",
      "--- epoch: 1321, loss: 0.085194, val_loss: 0.074378 ---\n",
      "--- epoch: 1322, loss: 0.085174, val_loss: 0.074355 ---\n",
      "--- epoch: 1323, loss: 0.085153, val_loss: 0.074332 ---\n",
      "--- epoch: 1324, loss: 0.085133, val_loss: 0.074309 ---\n",
      "--- epoch: 1325, loss: 0.085113, val_loss: 0.074286 ---\n",
      "--- epoch: 1326, loss: 0.085092, val_loss: 0.074263 ---\n",
      "--- epoch: 1327, loss: 0.085072, val_loss: 0.074240 ---\n",
      "--- epoch: 1328, loss: 0.085052, val_loss: 0.074217 ---\n",
      "--- epoch: 1329, loss: 0.085032, val_loss: 0.074194 ---\n",
      "--- epoch: 1330, loss: 0.085011, val_loss: 0.074172 ---\n",
      "--- epoch: 1331, loss: 0.084991, val_loss: 0.074149 ---\n",
      "--- epoch: 1332, loss: 0.084971, val_loss: 0.074126 ---\n",
      "--- epoch: 1333, loss: 0.084951, val_loss: 0.074103 ---\n",
      "--- epoch: 1334, loss: 0.084931, val_loss: 0.074081 ---\n",
      "--- epoch: 1335, loss: 0.084911, val_loss: 0.074058 ---\n",
      "--- epoch: 1336, loss: 0.084891, val_loss: 0.074035 ---\n",
      "--- epoch: 1337, loss: 0.084871, val_loss: 0.074013 ---\n",
      "--- epoch: 1338, loss: 0.084851, val_loss: 0.073990 ---\n",
      "--- epoch: 1339, loss: 0.084831, val_loss: 0.073967 ---\n",
      "--- epoch: 1340, loss: 0.084811, val_loss: 0.073945 ---\n",
      "--- epoch: 1341, loss: 0.084791, val_loss: 0.073922 ---\n",
      "--- epoch: 1342, loss: 0.084771, val_loss: 0.073900 ---\n",
      "--- epoch: 1343, loss: 0.084751, val_loss: 0.073877 ---\n",
      "--- epoch: 1344, loss: 0.084731, val_loss: 0.073855 ---\n",
      "--- epoch: 1345, loss: 0.084711, val_loss: 0.073832 ---\n",
      "--- epoch: 1346, loss: 0.084692, val_loss: 0.073810 ---\n",
      "--- epoch: 1347, loss: 0.084672, val_loss: 0.073788 ---\n",
      "--- epoch: 1348, loss: 0.084652, val_loss: 0.073765 ---\n",
      "--- epoch: 1349, loss: 0.084632, val_loss: 0.073743 ---\n",
      "--- epoch: 1350, loss: 0.084613, val_loss: 0.073721 ---\n",
      "--- epoch: 1351, loss: 0.084593, val_loss: 0.073698 ---\n",
      "--- epoch: 1352, loss: 0.084573, val_loss: 0.073676 ---\n",
      "--- epoch: 1353, loss: 0.084554, val_loss: 0.073654 ---\n",
      "--- epoch: 1354, loss: 0.084534, val_loss: 0.073632 ---\n",
      "--- epoch: 1355, loss: 0.084515, val_loss: 0.073610 ---\n",
      "--- epoch: 1356, loss: 0.084495, val_loss: 0.073587 ---\n",
      "--- epoch: 1357, loss: 0.084476, val_loss: 0.073565 ---\n",
      "--- epoch: 1358, loss: 0.084456, val_loss: 0.073543 ---\n",
      "--- epoch: 1359, loss: 0.084437, val_loss: 0.073521 ---\n",
      "--- epoch: 1360, loss: 0.084417, val_loss: 0.073499 ---\n",
      "--- epoch: 1361, loss: 0.084398, val_loss: 0.073477 ---\n",
      "--- epoch: 1362, loss: 0.084378, val_loss: 0.073455 ---\n",
      "--- epoch: 1363, loss: 0.084359, val_loss: 0.073433 ---\n",
      "--- epoch: 1364, loss: 0.084340, val_loss: 0.073411 ---\n",
      "--- epoch: 1365, loss: 0.084320, val_loss: 0.073390 ---\n",
      "--- epoch: 1366, loss: 0.084301, val_loss: 0.073368 ---\n",
      "--- epoch: 1367, loss: 0.084282, val_loss: 0.073346 ---\n",
      "--- epoch: 1368, loss: 0.084262, val_loss: 0.073324 ---\n",
      "--- epoch: 1369, loss: 0.084243, val_loss: 0.073302 ---\n",
      "--- epoch: 1370, loss: 0.084224, val_loss: 0.073280 ---\n",
      "--- epoch: 1371, loss: 0.084205, val_loss: 0.073259 ---\n",
      "--- epoch: 1372, loss: 0.084186, val_loss: 0.073237 ---\n",
      "--- epoch: 1373, loss: 0.084167, val_loss: 0.073215 ---\n",
      "--- epoch: 1374, loss: 0.084147, val_loss: 0.073194 ---\n",
      "--- epoch: 1375, loss: 0.084128, val_loss: 0.073172 ---\n",
      "--- epoch: 1376, loss: 0.084109, val_loss: 0.073150 ---\n",
      "--- epoch: 1377, loss: 0.084090, val_loss: 0.073129 ---\n",
      "--- epoch: 1378, loss: 0.084071, val_loss: 0.073107 ---\n",
      "--- epoch: 1379, loss: 0.084052, val_loss: 0.073086 ---\n",
      "--- epoch: 1380, loss: 0.084033, val_loss: 0.073064 ---\n",
      "--- epoch: 1381, loss: 0.084014, val_loss: 0.073043 ---\n",
      "--- epoch: 1382, loss: 0.083995, val_loss: 0.073021 ---\n",
      "--- epoch: 1383, loss: 0.083976, val_loss: 0.073000 ---\n",
      "--- epoch: 1384, loss: 0.083958, val_loss: 0.072978 ---\n",
      "--- epoch: 1385, loss: 0.083939, val_loss: 0.072957 ---\n",
      "--- epoch: 1386, loss: 0.083920, val_loss: 0.072935 ---\n",
      "--- epoch: 1387, loss: 0.083901, val_loss: 0.072914 ---\n",
      "--- epoch: 1388, loss: 0.083882, val_loss: 0.072893 ---\n",
      "--- epoch: 1389, loss: 0.083864, val_loss: 0.072871 ---\n",
      "--- epoch: 1390, loss: 0.083845, val_loss: 0.072850 ---\n",
      "--- epoch: 1391, loss: 0.083826, val_loss: 0.072829 ---\n",
      "--- epoch: 1392, loss: 0.083807, val_loss: 0.072808 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1393, loss: 0.083789, val_loss: 0.072786 ---\n",
      "--- epoch: 1394, loss: 0.083770, val_loss: 0.072765 ---\n",
      "--- epoch: 1395, loss: 0.083752, val_loss: 0.072744 ---\n",
      "--- epoch: 1396, loss: 0.083733, val_loss: 0.072723 ---\n",
      "--- epoch: 1397, loss: 0.083714, val_loss: 0.072702 ---\n",
      "--- epoch: 1398, loss: 0.083696, val_loss: 0.072681 ---\n",
      "--- epoch: 1399, loss: 0.083677, val_loss: 0.072660 ---\n",
      "--- epoch: 1400, loss: 0.083659, val_loss: 0.072639 ---\n",
      "--- epoch: 1401, loss: 0.083640, val_loss: 0.072618 ---\n",
      "--- epoch: 1402, loss: 0.083622, val_loss: 0.072597 ---\n",
      "--- epoch: 1403, loss: 0.083603, val_loss: 0.072576 ---\n",
      "--- epoch: 1404, loss: 0.083585, val_loss: 0.072555 ---\n",
      "--- epoch: 1405, loss: 0.083567, val_loss: 0.072534 ---\n",
      "--- epoch: 1406, loss: 0.083548, val_loss: 0.072513 ---\n",
      "--- epoch: 1407, loss: 0.083530, val_loss: 0.072492 ---\n",
      "--- epoch: 1408, loss: 0.083511, val_loss: 0.072471 ---\n",
      "--- epoch: 1409, loss: 0.083493, val_loss: 0.072450 ---\n",
      "--- epoch: 1410, loss: 0.083475, val_loss: 0.072430 ---\n",
      "--- epoch: 1411, loss: 0.083457, val_loss: 0.072409 ---\n",
      "--- epoch: 1412, loss: 0.083438, val_loss: 0.072388 ---\n",
      "--- epoch: 1413, loss: 0.083420, val_loss: 0.072367 ---\n",
      "--- epoch: 1414, loss: 0.083402, val_loss: 0.072347 ---\n",
      "--- epoch: 1415, loss: 0.083384, val_loss: 0.072326 ---\n",
      "--- epoch: 1416, loss: 0.083366, val_loss: 0.072305 ---\n",
      "--- epoch: 1417, loss: 0.083347, val_loss: 0.072285 ---\n",
      "--- epoch: 1418, loss: 0.083329, val_loss: 0.072264 ---\n",
      "--- epoch: 1419, loss: 0.083311, val_loss: 0.072243 ---\n",
      "--- epoch: 1420, loss: 0.083293, val_loss: 0.072223 ---\n",
      "--- epoch: 1421, loss: 0.083275, val_loss: 0.072202 ---\n",
      "--- epoch: 1422, loss: 0.083257, val_loss: 0.072182 ---\n",
      "--- epoch: 1423, loss: 0.083239, val_loss: 0.072161 ---\n",
      "--- epoch: 1424, loss: 0.083221, val_loss: 0.072141 ---\n",
      "--- epoch: 1425, loss: 0.083203, val_loss: 0.072120 ---\n",
      "--- epoch: 1426, loss: 0.083185, val_loss: 0.072100 ---\n",
      "--- epoch: 1427, loss: 0.083167, val_loss: 0.072080 ---\n",
      "--- epoch: 1428, loss: 0.083149, val_loss: 0.072059 ---\n",
      "--- epoch: 1429, loss: 0.083132, val_loss: 0.072039 ---\n",
      "--- epoch: 1430, loss: 0.083114, val_loss: 0.072018 ---\n",
      "--- epoch: 1431, loss: 0.083096, val_loss: 0.071998 ---\n",
      "--- epoch: 1432, loss: 0.083078, val_loss: 0.071978 ---\n",
      "--- epoch: 1433, loss: 0.083060, val_loss: 0.071957 ---\n",
      "--- epoch: 1434, loss: 0.083043, val_loss: 0.071937 ---\n",
      "--- epoch: 1435, loss: 0.083025, val_loss: 0.071917 ---\n",
      "--- epoch: 1436, loss: 0.083007, val_loss: 0.071897 ---\n",
      "--- epoch: 1437, loss: 0.082989, val_loss: 0.071877 ---\n",
      "--- epoch: 1438, loss: 0.082972, val_loss: 0.071856 ---\n",
      "--- epoch: 1439, loss: 0.082954, val_loss: 0.071836 ---\n",
      "--- epoch: 1440, loss: 0.082936, val_loss: 0.071816 ---\n",
      "--- epoch: 1441, loss: 0.082919, val_loss: 0.071796 ---\n",
      "--- epoch: 1442, loss: 0.082901, val_loss: 0.071776 ---\n",
      "--- epoch: 1443, loss: 0.082884, val_loss: 0.071756 ---\n",
      "--- epoch: 1444, loss: 0.082866, val_loss: 0.071736 ---\n",
      "--- epoch: 1445, loss: 0.082848, val_loss: 0.071716 ---\n",
      "--- epoch: 1446, loss: 0.082831, val_loss: 0.071696 ---\n",
      "--- epoch: 1447, loss: 0.082814, val_loss: 0.071676 ---\n",
      "--- epoch: 1448, loss: 0.082796, val_loss: 0.071656 ---\n",
      "--- epoch: 1449, loss: 0.082779, val_loss: 0.071636 ---\n",
      "--- epoch: 1450, loss: 0.082761, val_loss: 0.071616 ---\n",
      "--- epoch: 1451, loss: 0.082744, val_loss: 0.071596 ---\n",
      "--- epoch: 1452, loss: 0.082726, val_loss: 0.071577 ---\n",
      "--- epoch: 1453, loss: 0.082709, val_loss: 0.071557 ---\n",
      "--- epoch: 1454, loss: 0.082692, val_loss: 0.071537 ---\n",
      "--- epoch: 1455, loss: 0.082674, val_loss: 0.071517 ---\n",
      "--- epoch: 1456, loss: 0.082657, val_loss: 0.071497 ---\n",
      "--- epoch: 1457, loss: 0.082640, val_loss: 0.071478 ---\n",
      "--- epoch: 1458, loss: 0.082622, val_loss: 0.071458 ---\n",
      "--- epoch: 1459, loss: 0.082605, val_loss: 0.071438 ---\n",
      "--- epoch: 1460, loss: 0.082588, val_loss: 0.071418 ---\n",
      "--- epoch: 1461, loss: 0.082571, val_loss: 0.071399 ---\n",
      "--- epoch: 1462, loss: 0.082554, val_loss: 0.071379 ---\n",
      "--- epoch: 1463, loss: 0.082536, val_loss: 0.071360 ---\n",
      "--- epoch: 1464, loss: 0.082519, val_loss: 0.071340 ---\n",
      "--- epoch: 1465, loss: 0.082502, val_loss: 0.071320 ---\n",
      "--- epoch: 1466, loss: 0.082485, val_loss: 0.071301 ---\n",
      "--- epoch: 1467, loss: 0.082468, val_loss: 0.071281 ---\n",
      "--- epoch: 1468, loss: 0.082451, val_loss: 0.071262 ---\n",
      "--- epoch: 1469, loss: 0.082434, val_loss: 0.071242 ---\n",
      "--- epoch: 1470, loss: 0.082417, val_loss: 0.071223 ---\n",
      "--- epoch: 1471, loss: 0.082400, val_loss: 0.071203 ---\n",
      "--- epoch: 1472, loss: 0.082383, val_loss: 0.071184 ---\n",
      "--- epoch: 1473, loss: 0.082366, val_loss: 0.071164 ---\n",
      "--- epoch: 1474, loss: 0.082349, val_loss: 0.071145 ---\n",
      "--- epoch: 1475, loss: 0.082332, val_loss: 0.071126 ---\n",
      "--- epoch: 1476, loss: 0.082315, val_loss: 0.071106 ---\n",
      "--- epoch: 1477, loss: 0.082298, val_loss: 0.071087 ---\n",
      "--- epoch: 1478, loss: 0.082281, val_loss: 0.071068 ---\n",
      "--- epoch: 1479, loss: 0.082264, val_loss: 0.071048 ---\n",
      "--- epoch: 1480, loss: 0.082248, val_loss: 0.071029 ---\n",
      "--- epoch: 1481, loss: 0.082231, val_loss: 0.071010 ---\n",
      "--- epoch: 1482, loss: 0.082214, val_loss: 0.070991 ---\n",
      "--- epoch: 1483, loss: 0.082197, val_loss: 0.070972 ---\n",
      "--- epoch: 1484, loss: 0.082180, val_loss: 0.070952 ---\n",
      "--- epoch: 1485, loss: 0.082164, val_loss: 0.070933 ---\n",
      "--- epoch: 1486, loss: 0.082147, val_loss: 0.070914 ---\n",
      "--- epoch: 1487, loss: 0.082130, val_loss: 0.070895 ---\n",
      "--- epoch: 1488, loss: 0.082114, val_loss: 0.070876 ---\n",
      "--- epoch: 1489, loss: 0.082097, val_loss: 0.070857 ---\n",
      "--- epoch: 1490, loss: 0.082080, val_loss: 0.070838 ---\n",
      "--- epoch: 1491, loss: 0.082064, val_loss: 0.070819 ---\n",
      "--- epoch: 1492, loss: 0.082047, val_loss: 0.070800 ---\n",
      "--- epoch: 1493, loss: 0.082031, val_loss: 0.070781 ---\n",
      "--- epoch: 1494, loss: 0.082014, val_loss: 0.070762 ---\n",
      "--- epoch: 1495, loss: 0.081997, val_loss: 0.070743 ---\n",
      "--- epoch: 1496, loss: 0.081981, val_loss: 0.070724 ---\n",
      "--- epoch: 1497, loss: 0.081964, val_loss: 0.070705 ---\n",
      "--- epoch: 1498, loss: 0.081948, val_loss: 0.070686 ---\n",
      "--- epoch: 1499, loss: 0.081931, val_loss: 0.070667 ---\n",
      "--- epoch: 1500, loss: 0.081915, val_loss: 0.070648 ---\n",
      "--- epoch: 1501, loss: 0.081899, val_loss: 0.070629 ---\n",
      "--- epoch: 1502, loss: 0.081882, val_loss: 0.070611 ---\n",
      "--- epoch: 1503, loss: 0.081866, val_loss: 0.070592 ---\n",
      "--- epoch: 1504, loss: 0.081849, val_loss: 0.070573 ---\n",
      "--- epoch: 1505, loss: 0.081833, val_loss: 0.070554 ---\n",
      "--- epoch: 1506, loss: 0.081817, val_loss: 0.070535 ---\n",
      "--- epoch: 1507, loss: 0.081800, val_loss: 0.070517 ---\n",
      "--- epoch: 1508, loss: 0.081784, val_loss: 0.070498 ---\n",
      "--- epoch: 1509, loss: 0.081768, val_loss: 0.070479 ---\n",
      "--- epoch: 1510, loss: 0.081751, val_loss: 0.070461 ---\n",
      "--- epoch: 1511, loss: 0.081735, val_loss: 0.070442 ---\n",
      "--- epoch: 1512, loss: 0.081719, val_loss: 0.070423 ---\n",
      "--- epoch: 1513, loss: 0.081703, val_loss: 0.070405 ---\n",
      "--- epoch: 1514, loss: 0.081687, val_loss: 0.070386 ---\n",
      "--- epoch: 1515, loss: 0.081670, val_loss: 0.070368 ---\n",
      "--- epoch: 1516, loss: 0.081654, val_loss: 0.070349 ---\n",
      "--- epoch: 1517, loss: 0.081638, val_loss: 0.070331 ---\n",
      "--- epoch: 1518, loss: 0.081622, val_loss: 0.070312 ---\n",
      "--- epoch: 1519, loss: 0.081606, val_loss: 0.070294 ---\n",
      "--- epoch: 1520, loss: 0.081590, val_loss: 0.070275 ---\n",
      "--- epoch: 1521, loss: 0.081574, val_loss: 0.070257 ---\n",
      "--- epoch: 1522, loss: 0.081558, val_loss: 0.070238 ---\n",
      "--- epoch: 1523, loss: 0.081542, val_loss: 0.070220 ---\n",
      "--- epoch: 1524, loss: 0.081526, val_loss: 0.070202 ---\n",
      "--- epoch: 1525, loss: 0.081510, val_loss: 0.070183 ---\n",
      "--- epoch: 1526, loss: 0.081494, val_loss: 0.070165 ---\n",
      "--- epoch: 1527, loss: 0.081478, val_loss: 0.070146 ---\n",
      "--- epoch: 1528, loss: 0.081462, val_loss: 0.070128 ---\n",
      "--- epoch: 1529, loss: 0.081446, val_loss: 0.070110 ---\n",
      "--- epoch: 1530, loss: 0.081430, val_loss: 0.070092 ---\n",
      "--- epoch: 1531, loss: 0.081414, val_loss: 0.070073 ---\n",
      "--- epoch: 1532, loss: 0.081398, val_loss: 0.070055 ---\n",
      "--- epoch: 1533, loss: 0.081382, val_loss: 0.070037 ---\n",
      "--- epoch: 1534, loss: 0.081367, val_loss: 0.070019 ---\n",
      "--- epoch: 1535, loss: 0.081351, val_loss: 0.070000 ---\n",
      "--- epoch: 1536, loss: 0.081335, val_loss: 0.069982 ---\n",
      "--- epoch: 1537, loss: 0.081319, val_loss: 0.069964 ---\n",
      "--- epoch: 1538, loss: 0.081303, val_loss: 0.069946 ---\n",
      "--- epoch: 1539, loss: 0.081288, val_loss: 0.069928 ---\n",
      "--- epoch: 1540, loss: 0.081272, val_loss: 0.069910 ---\n",
      "--- epoch: 1541, loss: 0.081256, val_loss: 0.069892 ---\n",
      "--- epoch: 1542, loss: 0.081241, val_loss: 0.069874 ---\n",
      "--- epoch: 1543, loss: 0.081225, val_loss: 0.069856 ---\n",
      "--- epoch: 1544, loss: 0.081209, val_loss: 0.069838 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1545, loss: 0.081194, val_loss: 0.069820 ---\n",
      "--- epoch: 1546, loss: 0.081178, val_loss: 0.069802 ---\n",
      "--- epoch: 1547, loss: 0.081162, val_loss: 0.069784 ---\n",
      "--- epoch: 1548, loss: 0.081147, val_loss: 0.069766 ---\n",
      "--- epoch: 1549, loss: 0.081131, val_loss: 0.069748 ---\n",
      "--- epoch: 1550, loss: 0.081116, val_loss: 0.069730 ---\n",
      "--- epoch: 1551, loss: 0.081100, val_loss: 0.069712 ---\n",
      "--- epoch: 1552, loss: 0.081085, val_loss: 0.069694 ---\n",
      "--- epoch: 1553, loss: 0.081069, val_loss: 0.069677 ---\n",
      "--- epoch: 1554, loss: 0.081054, val_loss: 0.069659 ---\n",
      "--- epoch: 1555, loss: 0.081038, val_loss: 0.069641 ---\n",
      "--- epoch: 1556, loss: 0.081023, val_loss: 0.069623 ---\n",
      "--- epoch: 1557, loss: 0.081007, val_loss: 0.069605 ---\n",
      "--- epoch: 1558, loss: 0.080992, val_loss: 0.069588 ---\n",
      "--- epoch: 1559, loss: 0.080976, val_loss: 0.069570 ---\n",
      "--- epoch: 1560, loss: 0.080961, val_loss: 0.069552 ---\n",
      "--- epoch: 1561, loss: 0.080946, val_loss: 0.069534 ---\n",
      "--- epoch: 1562, loss: 0.080930, val_loss: 0.069517 ---\n",
      "--- epoch: 1563, loss: 0.080915, val_loss: 0.069499 ---\n",
      "--- epoch: 1564, loss: 0.080900, val_loss: 0.069481 ---\n",
      "--- epoch: 1565, loss: 0.080884, val_loss: 0.069464 ---\n",
      "--- epoch: 1566, loss: 0.080869, val_loss: 0.069446 ---\n",
      "--- epoch: 1567, loss: 0.080854, val_loss: 0.069428 ---\n",
      "--- epoch: 1568, loss: 0.080839, val_loss: 0.069411 ---\n",
      "--- epoch: 1569, loss: 0.080823, val_loss: 0.069393 ---\n",
      "--- epoch: 1570, loss: 0.080808, val_loss: 0.069376 ---\n",
      "--- epoch: 1571, loss: 0.080793, val_loss: 0.069358 ---\n",
      "--- epoch: 1572, loss: 0.080778, val_loss: 0.069341 ---\n",
      "--- epoch: 1573, loss: 0.080763, val_loss: 0.069323 ---\n",
      "--- epoch: 1574, loss: 0.080747, val_loss: 0.069306 ---\n",
      "--- epoch: 1575, loss: 0.080732, val_loss: 0.069288 ---\n",
      "--- epoch: 1576, loss: 0.080717, val_loss: 0.069271 ---\n",
      "--- epoch: 1577, loss: 0.080702, val_loss: 0.069253 ---\n",
      "--- epoch: 1578, loss: 0.080687, val_loss: 0.069236 ---\n",
      "--- epoch: 1579, loss: 0.080672, val_loss: 0.069219 ---\n",
      "--- epoch: 1580, loss: 0.080657, val_loss: 0.069201 ---\n",
      "--- epoch: 1581, loss: 0.080642, val_loss: 0.069184 ---\n",
      "--- epoch: 1582, loss: 0.080627, val_loss: 0.069167 ---\n",
      "--- epoch: 1583, loss: 0.080612, val_loss: 0.069149 ---\n",
      "--- epoch: 1584, loss: 0.080597, val_loss: 0.069132 ---\n",
      "--- epoch: 1585, loss: 0.080582, val_loss: 0.069115 ---\n",
      "--- epoch: 1586, loss: 0.080567, val_loss: 0.069098 ---\n",
      "--- epoch: 1587, loss: 0.080552, val_loss: 0.069080 ---\n",
      "--- epoch: 1588, loss: 0.080537, val_loss: 0.069063 ---\n",
      "--- epoch: 1589, loss: 0.080522, val_loss: 0.069046 ---\n",
      "--- epoch: 1590, loss: 0.080507, val_loss: 0.069029 ---\n",
      "--- epoch: 1591, loss: 0.080492, val_loss: 0.069012 ---\n",
      "--- epoch: 1592, loss: 0.080478, val_loss: 0.068994 ---\n",
      "--- epoch: 1593, loss: 0.080463, val_loss: 0.068977 ---\n",
      "--- epoch: 1594, loss: 0.080448, val_loss: 0.068960 ---\n",
      "--- epoch: 1595, loss: 0.080433, val_loss: 0.068943 ---\n",
      "--- epoch: 1596, loss: 0.080418, val_loss: 0.068926 ---\n",
      "--- epoch: 1597, loss: 0.080404, val_loss: 0.068909 ---\n",
      "--- epoch: 1598, loss: 0.080389, val_loss: 0.068892 ---\n",
      "--- epoch: 1599, loss: 0.080374, val_loss: 0.068875 ---\n",
      "--- epoch: 1600, loss: 0.080359, val_loss: 0.068858 ---\n",
      "--- epoch: 1601, loss: 0.080345, val_loss: 0.068841 ---\n",
      "--- epoch: 1602, loss: 0.080330, val_loss: 0.068824 ---\n",
      "--- epoch: 1603, loss: 0.080315, val_loss: 0.068807 ---\n",
      "--- epoch: 1604, loss: 0.080301, val_loss: 0.068790 ---\n",
      "--- epoch: 1605, loss: 0.080286, val_loss: 0.068773 ---\n",
      "--- epoch: 1606, loss: 0.080271, val_loss: 0.068756 ---\n",
      "--- epoch: 1607, loss: 0.080257, val_loss: 0.068739 ---\n",
      "--- epoch: 1608, loss: 0.080242, val_loss: 0.068722 ---\n",
      "--- epoch: 1609, loss: 0.080227, val_loss: 0.068705 ---\n",
      "--- epoch: 1610, loss: 0.080213, val_loss: 0.068688 ---\n",
      "--- epoch: 1611, loss: 0.080198, val_loss: 0.068671 ---\n",
      "--- epoch: 1612, loss: 0.080184, val_loss: 0.068655 ---\n",
      "--- epoch: 1613, loss: 0.080169, val_loss: 0.068638 ---\n",
      "--- epoch: 1614, loss: 0.080155, val_loss: 0.068621 ---\n",
      "--- epoch: 1615, loss: 0.080140, val_loss: 0.068604 ---\n",
      "--- epoch: 1616, loss: 0.080126, val_loss: 0.068588 ---\n",
      "--- epoch: 1617, loss: 0.080111, val_loss: 0.068571 ---\n",
      "--- epoch: 1618, loss: 0.080097, val_loss: 0.068554 ---\n",
      "--- epoch: 1619, loss: 0.080082, val_loss: 0.068537 ---\n",
      "--- epoch: 1620, loss: 0.080068, val_loss: 0.068521 ---\n",
      "--- epoch: 1621, loss: 0.080054, val_loss: 0.068504 ---\n",
      "--- epoch: 1622, loss: 0.080039, val_loss: 0.068487 ---\n",
      "--- epoch: 1623, loss: 0.080025, val_loss: 0.068471 ---\n",
      "--- epoch: 1624, loss: 0.080010, val_loss: 0.068454 ---\n",
      "--- epoch: 1625, loss: 0.079996, val_loss: 0.068438 ---\n",
      "--- epoch: 1626, loss: 0.079982, val_loss: 0.068421 ---\n",
      "--- epoch: 1627, loss: 0.079967, val_loss: 0.068404 ---\n",
      "--- epoch: 1628, loss: 0.079953, val_loss: 0.068388 ---\n",
      "--- epoch: 1629, loss: 0.079939, val_loss: 0.068371 ---\n",
      "--- epoch: 1630, loss: 0.079925, val_loss: 0.068355 ---\n",
      "--- epoch: 1631, loss: 0.079910, val_loss: 0.068338 ---\n",
      "--- epoch: 1632, loss: 0.079896, val_loss: 0.068322 ---\n",
      "--- epoch: 1633, loss: 0.079882, val_loss: 0.068305 ---\n",
      "--- epoch: 1634, loss: 0.079868, val_loss: 0.068289 ---\n",
      "--- epoch: 1635, loss: 0.079854, val_loss: 0.068272 ---\n",
      "--- epoch: 1636, loss: 0.079839, val_loss: 0.068256 ---\n",
      "--- epoch: 1637, loss: 0.079825, val_loss: 0.068239 ---\n",
      "--- epoch: 1638, loss: 0.079811, val_loss: 0.068223 ---\n",
      "--- epoch: 1639, loss: 0.079797, val_loss: 0.068207 ---\n",
      "--- epoch: 1640, loss: 0.079783, val_loss: 0.068190 ---\n",
      "--- epoch: 1641, loss: 0.079769, val_loss: 0.068174 ---\n",
      "--- epoch: 1642, loss: 0.079755, val_loss: 0.068158 ---\n",
      "--- epoch: 1643, loss: 0.079740, val_loss: 0.068141 ---\n",
      "--- epoch: 1644, loss: 0.079726, val_loss: 0.068125 ---\n",
      "--- epoch: 1645, loss: 0.079712, val_loss: 0.068109 ---\n",
      "--- epoch: 1646, loss: 0.079698, val_loss: 0.068092 ---\n",
      "--- epoch: 1647, loss: 0.079684, val_loss: 0.068076 ---\n",
      "--- epoch: 1648, loss: 0.079670, val_loss: 0.068060 ---\n",
      "--- epoch: 1649, loss: 0.079656, val_loss: 0.068044 ---\n",
      "--- epoch: 1650, loss: 0.079642, val_loss: 0.068027 ---\n",
      "--- epoch: 1651, loss: 0.079628, val_loss: 0.068011 ---\n",
      "--- epoch: 1652, loss: 0.079614, val_loss: 0.067995 ---\n",
      "--- epoch: 1653, loss: 0.079601, val_loss: 0.067979 ---\n",
      "--- epoch: 1654, loss: 0.079587, val_loss: 0.067963 ---\n",
      "--- epoch: 1655, loss: 0.079573, val_loss: 0.067947 ---\n",
      "--- epoch: 1656, loss: 0.079559, val_loss: 0.067931 ---\n",
      "--- epoch: 1657, loss: 0.079545, val_loss: 0.067914 ---\n",
      "--- epoch: 1658, loss: 0.079531, val_loss: 0.067898 ---\n",
      "--- epoch: 1659, loss: 0.079517, val_loss: 0.067882 ---\n",
      "--- epoch: 1660, loss: 0.079503, val_loss: 0.067866 ---\n",
      "--- epoch: 1661, loss: 0.079490, val_loss: 0.067850 ---\n",
      "--- epoch: 1662, loss: 0.079476, val_loss: 0.067834 ---\n",
      "--- epoch: 1663, loss: 0.079462, val_loss: 0.067818 ---\n",
      "--- epoch: 1664, loss: 0.079448, val_loss: 0.067802 ---\n",
      "--- epoch: 1665, loss: 0.079434, val_loss: 0.067786 ---\n",
      "--- epoch: 1666, loss: 0.079421, val_loss: 0.067770 ---\n",
      "--- epoch: 1667, loss: 0.079407, val_loss: 0.067754 ---\n",
      "--- epoch: 1668, loss: 0.079393, val_loss: 0.067738 ---\n",
      "--- epoch: 1669, loss: 0.079380, val_loss: 0.067722 ---\n",
      "--- epoch: 1670, loss: 0.079366, val_loss: 0.067706 ---\n",
      "--- epoch: 1671, loss: 0.079352, val_loss: 0.067691 ---\n",
      "--- epoch: 1672, loss: 0.079339, val_loss: 0.067675 ---\n",
      "--- epoch: 1673, loss: 0.079325, val_loss: 0.067659 ---\n",
      "--- epoch: 1674, loss: 0.079311, val_loss: 0.067643 ---\n",
      "--- epoch: 1675, loss: 0.079298, val_loss: 0.067627 ---\n",
      "--- epoch: 1676, loss: 0.079284, val_loss: 0.067611 ---\n",
      "--- epoch: 1677, loss: 0.079270, val_loss: 0.067596 ---\n",
      "--- epoch: 1678, loss: 0.079257, val_loss: 0.067580 ---\n",
      "--- epoch: 1679, loss: 0.079243, val_loss: 0.067564 ---\n",
      "--- epoch: 1680, loss: 0.079230, val_loss: 0.067548 ---\n",
      "--- epoch: 1681, loss: 0.079216, val_loss: 0.067532 ---\n",
      "--- epoch: 1682, loss: 0.079203, val_loss: 0.067517 ---\n",
      "--- epoch: 1683, loss: 0.079189, val_loss: 0.067501 ---\n",
      "--- epoch: 1684, loss: 0.079176, val_loss: 0.067485 ---\n",
      "--- epoch: 1685, loss: 0.079162, val_loss: 0.067470 ---\n",
      "--- epoch: 1686, loss: 0.079149, val_loss: 0.067454 ---\n",
      "--- epoch: 1687, loss: 0.079135, val_loss: 0.067438 ---\n",
      "--- epoch: 1688, loss: 0.079122, val_loss: 0.067423 ---\n",
      "--- epoch: 1689, loss: 0.079109, val_loss: 0.067407 ---\n",
      "--- epoch: 1690, loss: 0.079095, val_loss: 0.067392 ---\n",
      "--- epoch: 1691, loss: 0.079082, val_loss: 0.067376 ---\n",
      "--- epoch: 1692, loss: 0.079068, val_loss: 0.067360 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1693, loss: 0.079055, val_loss: 0.067345 ---\n",
      "--- epoch: 1694, loss: 0.079042, val_loss: 0.067329 ---\n",
      "--- epoch: 1695, loss: 0.079028, val_loss: 0.067314 ---\n",
      "--- epoch: 1696, loss: 0.079015, val_loss: 0.067298 ---\n",
      "--- epoch: 1697, loss: 0.079002, val_loss: 0.067283 ---\n",
      "--- epoch: 1698, loss: 0.078988, val_loss: 0.067267 ---\n",
      "--- epoch: 1699, loss: 0.078975, val_loss: 0.067252 ---\n",
      "--- epoch: 1700, loss: 0.078962, val_loss: 0.067236 ---\n",
      "--- epoch: 1701, loss: 0.078948, val_loss: 0.067221 ---\n",
      "--- epoch: 1702, loss: 0.078935, val_loss: 0.067205 ---\n",
      "--- epoch: 1703, loss: 0.078922, val_loss: 0.067190 ---\n",
      "--- epoch: 1704, loss: 0.078909, val_loss: 0.067174 ---\n",
      "--- epoch: 1705, loss: 0.078896, val_loss: 0.067159 ---\n",
      "--- epoch: 1706, loss: 0.078882, val_loss: 0.067144 ---\n",
      "--- epoch: 1707, loss: 0.078869, val_loss: 0.067128 ---\n",
      "--- epoch: 1708, loss: 0.078856, val_loss: 0.067113 ---\n",
      "--- epoch: 1709, loss: 0.078843, val_loss: 0.067098 ---\n",
      "--- epoch: 1710, loss: 0.078830, val_loss: 0.067082 ---\n",
      "--- epoch: 1711, loss: 0.078816, val_loss: 0.067067 ---\n",
      "--- epoch: 1712, loss: 0.078803, val_loss: 0.067052 ---\n",
      "--- epoch: 1713, loss: 0.078790, val_loss: 0.067036 ---\n",
      "--- epoch: 1714, loss: 0.078777, val_loss: 0.067021 ---\n",
      "--- epoch: 1715, loss: 0.078764, val_loss: 0.067006 ---\n",
      "--- epoch: 1716, loss: 0.078751, val_loss: 0.066991 ---\n",
      "--- epoch: 1717, loss: 0.078738, val_loss: 0.066975 ---\n",
      "--- epoch: 1718, loss: 0.078725, val_loss: 0.066960 ---\n",
      "--- epoch: 1719, loss: 0.078712, val_loss: 0.066945 ---\n",
      "--- epoch: 1720, loss: 0.078699, val_loss: 0.066930 ---\n",
      "--- epoch: 1721, loss: 0.078686, val_loss: 0.066915 ---\n",
      "--- epoch: 1722, loss: 0.078673, val_loss: 0.066900 ---\n",
      "--- epoch: 1723, loss: 0.078660, val_loss: 0.066884 ---\n",
      "--- epoch: 1724, loss: 0.078647, val_loss: 0.066869 ---\n",
      "--- epoch: 1725, loss: 0.078634, val_loss: 0.066854 ---\n",
      "--- epoch: 1726, loss: 0.078621, val_loss: 0.066839 ---\n",
      "--- epoch: 1727, loss: 0.078608, val_loss: 0.066824 ---\n",
      "--- epoch: 1728, loss: 0.078595, val_loss: 0.066809 ---\n",
      "--- epoch: 1729, loss: 0.078582, val_loss: 0.066794 ---\n",
      "--- epoch: 1730, loss: 0.078570, val_loss: 0.066779 ---\n",
      "--- epoch: 1731, loss: 0.078557, val_loss: 0.066764 ---\n",
      "--- epoch: 1732, loss: 0.078544, val_loss: 0.066749 ---\n",
      "--- epoch: 1733, loss: 0.078531, val_loss: 0.066734 ---\n",
      "--- epoch: 1734, loss: 0.078518, val_loss: 0.066719 ---\n",
      "--- epoch: 1735, loss: 0.078505, val_loss: 0.066704 ---\n",
      "--- epoch: 1736, loss: 0.078493, val_loss: 0.066689 ---\n",
      "--- epoch: 1737, loss: 0.078480, val_loss: 0.066674 ---\n",
      "--- epoch: 1738, loss: 0.078467, val_loss: 0.066659 ---\n",
      "--- epoch: 1739, loss: 0.078454, val_loss: 0.066644 ---\n",
      "--- epoch: 1740, loss: 0.078441, val_loss: 0.066629 ---\n",
      "--- epoch: 1741, loss: 0.078429, val_loss: 0.066614 ---\n",
      "--- epoch: 1742, loss: 0.078416, val_loss: 0.066600 ---\n",
      "--- epoch: 1743, loss: 0.078403, val_loss: 0.066585 ---\n",
      "--- epoch: 1744, loss: 0.078391, val_loss: 0.066570 ---\n",
      "--- epoch: 1745, loss: 0.078378, val_loss: 0.066555 ---\n",
      "--- epoch: 1746, loss: 0.078365, val_loss: 0.066540 ---\n",
      "--- epoch: 1747, loss: 0.078352, val_loss: 0.066525 ---\n",
      "--- epoch: 1748, loss: 0.078340, val_loss: 0.066511 ---\n",
      "--- epoch: 1749, loss: 0.078327, val_loss: 0.066496 ---\n",
      "--- epoch: 1750, loss: 0.078315, val_loss: 0.066481 ---\n",
      "--- epoch: 1751, loss: 0.078302, val_loss: 0.066466 ---\n",
      "--- epoch: 1752, loss: 0.078289, val_loss: 0.066451 ---\n",
      "--- epoch: 1753, loss: 0.078277, val_loss: 0.066437 ---\n",
      "--- epoch: 1754, loss: 0.078264, val_loss: 0.066422 ---\n",
      "--- epoch: 1755, loss: 0.078251, val_loss: 0.066407 ---\n",
      "--- epoch: 1756, loss: 0.078239, val_loss: 0.066393 ---\n",
      "--- epoch: 1757, loss: 0.078226, val_loss: 0.066378 ---\n",
      "--- epoch: 1758, loss: 0.078214, val_loss: 0.066363 ---\n",
      "--- epoch: 1759, loss: 0.078201, val_loss: 0.066349 ---\n",
      "--- epoch: 1760, loss: 0.078189, val_loss: 0.066334 ---\n",
      "--- epoch: 1761, loss: 0.078176, val_loss: 0.066319 ---\n",
      "--- epoch: 1762, loss: 0.078164, val_loss: 0.066305 ---\n",
      "--- epoch: 1763, loss: 0.078151, val_loss: 0.066290 ---\n",
      "--- epoch: 1764, loss: 0.078139, val_loss: 0.066276 ---\n",
      "--- epoch: 1765, loss: 0.078126, val_loss: 0.066261 ---\n",
      "--- epoch: 1766, loss: 0.078114, val_loss: 0.066246 ---\n",
      "--- epoch: 1767, loss: 0.078102, val_loss: 0.066232 ---\n",
      "--- epoch: 1768, loss: 0.078089, val_loss: 0.066217 ---\n",
      "--- epoch: 1769, loss: 0.078077, val_loss: 0.066203 ---\n",
      "--- epoch: 1770, loss: 0.078064, val_loss: 0.066188 ---\n",
      "--- epoch: 1771, loss: 0.078052, val_loss: 0.066174 ---\n",
      "--- epoch: 1772, loss: 0.078040, val_loss: 0.066159 ---\n",
      "--- epoch: 1773, loss: 0.078027, val_loss: 0.066145 ---\n",
      "--- epoch: 1774, loss: 0.078015, val_loss: 0.066131 ---\n",
      "--- epoch: 1775, loss: 0.078003, val_loss: 0.066116 ---\n",
      "--- epoch: 1776, loss: 0.077990, val_loss: 0.066102 ---\n",
      "--- epoch: 1777, loss: 0.077978, val_loss: 0.066087 ---\n",
      "--- epoch: 1778, loss: 0.077966, val_loss: 0.066073 ---\n",
      "--- epoch: 1779, loss: 0.077954, val_loss: 0.066058 ---\n",
      "--- epoch: 1780, loss: 0.077941, val_loss: 0.066044 ---\n",
      "--- epoch: 1781, loss: 0.077929, val_loss: 0.066030 ---\n",
      "--- epoch: 1782, loss: 0.077917, val_loss: 0.066015 ---\n",
      "--- epoch: 1783, loss: 0.077905, val_loss: 0.066001 ---\n",
      "--- epoch: 1784, loss: 0.077892, val_loss: 0.065987 ---\n",
      "--- epoch: 1785, loss: 0.077880, val_loss: 0.065972 ---\n",
      "--- epoch: 1786, loss: 0.077868, val_loss: 0.065958 ---\n",
      "--- epoch: 1787, loss: 0.077856, val_loss: 0.065944 ---\n",
      "--- epoch: 1788, loss: 0.077843, val_loss: 0.065930 ---\n",
      "--- epoch: 1789, loss: 0.077831, val_loss: 0.065915 ---\n",
      "--- epoch: 1790, loss: 0.077819, val_loss: 0.065901 ---\n",
      "--- epoch: 1791, loss: 0.077807, val_loss: 0.065887 ---\n",
      "--- epoch: 1792, loss: 0.077795, val_loss: 0.065873 ---\n",
      "--- epoch: 1793, loss: 0.077783, val_loss: 0.065858 ---\n",
      "--- epoch: 1794, loss: 0.077771, val_loss: 0.065844 ---\n",
      "--- epoch: 1795, loss: 0.077759, val_loss: 0.065830 ---\n",
      "--- epoch: 1796, loss: 0.077746, val_loss: 0.065816 ---\n",
      "--- epoch: 1797, loss: 0.077734, val_loss: 0.065802 ---\n",
      "--- epoch: 1798, loss: 0.077722, val_loss: 0.065787 ---\n",
      "--- epoch: 1799, loss: 0.077710, val_loss: 0.065773 ---\n",
      "--- epoch: 1800, loss: 0.077698, val_loss: 0.065759 ---\n",
      "--- epoch: 1801, loss: 0.077686, val_loss: 0.065745 ---\n",
      "--- epoch: 1802, loss: 0.077674, val_loss: 0.065731 ---\n",
      "--- epoch: 1803, loss: 0.077662, val_loss: 0.065717 ---\n",
      "--- epoch: 1804, loss: 0.077650, val_loss: 0.065703 ---\n",
      "--- epoch: 1805, loss: 0.077638, val_loss: 0.065689 ---\n",
      "--- epoch: 1806, loss: 0.077626, val_loss: 0.065675 ---\n",
      "--- epoch: 1807, loss: 0.077614, val_loss: 0.065661 ---\n",
      "--- epoch: 1808, loss: 0.077602, val_loss: 0.065647 ---\n",
      "--- epoch: 1809, loss: 0.077590, val_loss: 0.065633 ---\n",
      "--- epoch: 1810, loss: 0.077579, val_loss: 0.065619 ---\n",
      "--- epoch: 1811, loss: 0.077567, val_loss: 0.065605 ---\n",
      "--- epoch: 1812, loss: 0.077555, val_loss: 0.065591 ---\n",
      "--- epoch: 1813, loss: 0.077543, val_loss: 0.065577 ---\n",
      "--- epoch: 1814, loss: 0.077531, val_loss: 0.065563 ---\n",
      "--- epoch: 1815, loss: 0.077519, val_loss: 0.065549 ---\n",
      "--- epoch: 1816, loss: 0.077507, val_loss: 0.065535 ---\n",
      "--- epoch: 1817, loss: 0.077495, val_loss: 0.065521 ---\n",
      "--- epoch: 1818, loss: 0.077484, val_loss: 0.065507 ---\n",
      "--- epoch: 1819, loss: 0.077472, val_loss: 0.065493 ---\n",
      "--- epoch: 1820, loss: 0.077460, val_loss: 0.065479 ---\n",
      "--- epoch: 1821, loss: 0.077448, val_loss: 0.065465 ---\n",
      "--- epoch: 1822, loss: 0.077436, val_loss: 0.065452 ---\n",
      "--- epoch: 1823, loss: 0.077425, val_loss: 0.065438 ---\n",
      "--- epoch: 1824, loss: 0.077413, val_loss: 0.065424 ---\n",
      "--- epoch: 1825, loss: 0.077401, val_loss: 0.065410 ---\n",
      "--- epoch: 1826, loss: 0.077389, val_loss: 0.065396 ---\n",
      "--- epoch: 1827, loss: 0.077378, val_loss: 0.065382 ---\n",
      "--- epoch: 1828, loss: 0.077366, val_loss: 0.065369 ---\n",
      "--- epoch: 1829, loss: 0.077354, val_loss: 0.065355 ---\n",
      "--- epoch: 1830, loss: 0.077342, val_loss: 0.065341 ---\n",
      "--- epoch: 1831, loss: 0.077331, val_loss: 0.065327 ---\n",
      "--- epoch: 1832, loss: 0.077319, val_loss: 0.065314 ---\n",
      "--- epoch: 1833, loss: 0.077307, val_loss: 0.065300 ---\n",
      "--- epoch: 1834, loss: 0.077296, val_loss: 0.065286 ---\n",
      "--- epoch: 1835, loss: 0.077284, val_loss: 0.065273 ---\n",
      "--- epoch: 1836, loss: 0.077272, val_loss: 0.065259 ---\n",
      "--- epoch: 1837, loss: 0.077261, val_loss: 0.065245 ---\n",
      "--- epoch: 1838, loss: 0.077249, val_loss: 0.065232 ---\n",
      "--- epoch: 1839, loss: 0.077238, val_loss: 0.065218 ---\n",
      "--- epoch: 1840, loss: 0.077226, val_loss: 0.065204 ---\n",
      "--- epoch: 1841, loss: 0.077214, val_loss: 0.065191 ---\n",
      "--- epoch: 1842, loss: 0.077203, val_loss: 0.065177 ---\n",
      "--- epoch: 1843, loss: 0.077191, val_loss: 0.065163 ---\n",
      "--- epoch: 1844, loss: 0.077180, val_loss: 0.065150 ---\n",
      "--- epoch: 1845, loss: 0.077168, val_loss: 0.065136 ---\n",
      "--- epoch: 1846, loss: 0.077157, val_loss: 0.065123 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1847, loss: 0.077145, val_loss: 0.065109 ---\n",
      "--- epoch: 1848, loss: 0.077134, val_loss: 0.065096 ---\n",
      "--- epoch: 1849, loss: 0.077122, val_loss: 0.065082 ---\n",
      "--- epoch: 1850, loss: 0.077111, val_loss: 0.065068 ---\n",
      "--- epoch: 1851, loss: 0.077099, val_loss: 0.065055 ---\n",
      "--- epoch: 1852, loss: 0.077088, val_loss: 0.065041 ---\n",
      "--- epoch: 1853, loss: 0.077076, val_loss: 0.065028 ---\n",
      "--- epoch: 1854, loss: 0.077065, val_loss: 0.065014 ---\n",
      "--- epoch: 1855, loss: 0.077053, val_loss: 0.065001 ---\n",
      "--- epoch: 1856, loss: 0.077042, val_loss: 0.064988 ---\n",
      "--- epoch: 1857, loss: 0.077031, val_loss: 0.064974 ---\n",
      "--- epoch: 1858, loss: 0.077019, val_loss: 0.064961 ---\n",
      "--- epoch: 1859, loss: 0.077008, val_loss: 0.064947 ---\n",
      "--- epoch: 1860, loss: 0.076996, val_loss: 0.064934 ---\n",
      "--- epoch: 1861, loss: 0.076985, val_loss: 0.064920 ---\n",
      "--- epoch: 1862, loss: 0.076974, val_loss: 0.064907 ---\n",
      "--- epoch: 1863, loss: 0.076962, val_loss: 0.064894 ---\n",
      "--- epoch: 1864, loss: 0.076951, val_loss: 0.064880 ---\n",
      "--- epoch: 1865, loss: 0.076940, val_loss: 0.064867 ---\n",
      "--- epoch: 1866, loss: 0.076928, val_loss: 0.064854 ---\n",
      "--- epoch: 1867, loss: 0.076917, val_loss: 0.064840 ---\n",
      "--- epoch: 1868, loss: 0.076906, val_loss: 0.064827 ---\n",
      "--- epoch: 1869, loss: 0.076895, val_loss: 0.064814 ---\n",
      "--- epoch: 1870, loss: 0.076883, val_loss: 0.064800 ---\n",
      "--- epoch: 1871, loss: 0.076872, val_loss: 0.064787 ---\n",
      "--- epoch: 1872, loss: 0.076861, val_loss: 0.064774 ---\n",
      "--- epoch: 1873, loss: 0.076849, val_loss: 0.064761 ---\n",
      "--- epoch: 1874, loss: 0.076838, val_loss: 0.064747 ---\n",
      "--- epoch: 1875, loss: 0.076827, val_loss: 0.064734 ---\n",
      "--- epoch: 1876, loss: 0.076816, val_loss: 0.064721 ---\n",
      "--- epoch: 1877, loss: 0.076805, val_loss: 0.064708 ---\n",
      "--- epoch: 1878, loss: 0.076793, val_loss: 0.064694 ---\n",
      "--- epoch: 1879, loss: 0.076782, val_loss: 0.064681 ---\n",
      "--- epoch: 1880, loss: 0.076771, val_loss: 0.064668 ---\n",
      "--- epoch: 1881, loss: 0.076760, val_loss: 0.064655 ---\n",
      "--- epoch: 1882, loss: 0.076749, val_loss: 0.064642 ---\n",
      "--- epoch: 1883, loss: 0.076738, val_loss: 0.064628 ---\n",
      "--- epoch: 1884, loss: 0.076726, val_loss: 0.064615 ---\n",
      "--- epoch: 1885, loss: 0.076715, val_loss: 0.064602 ---\n",
      "--- epoch: 1886, loss: 0.076704, val_loss: 0.064589 ---\n",
      "--- epoch: 1887, loss: 0.076693, val_loss: 0.064576 ---\n",
      "--- epoch: 1888, loss: 0.076682, val_loss: 0.064563 ---\n",
      "--- epoch: 1889, loss: 0.076671, val_loss: 0.064550 ---\n",
      "--- epoch: 1890, loss: 0.076660, val_loss: 0.064537 ---\n",
      "--- epoch: 1891, loss: 0.076649, val_loss: 0.064524 ---\n",
      "--- epoch: 1892, loss: 0.076638, val_loss: 0.064511 ---\n",
      "--- epoch: 1893, loss: 0.076627, val_loss: 0.064498 ---\n",
      "--- epoch: 1894, loss: 0.076616, val_loss: 0.064485 ---\n",
      "--- epoch: 1895, loss: 0.076605, val_loss: 0.064472 ---\n",
      "--- epoch: 1896, loss: 0.076594, val_loss: 0.064459 ---\n",
      "--- epoch: 1897, loss: 0.076583, val_loss: 0.064446 ---\n",
      "--- epoch: 1898, loss: 0.076572, val_loss: 0.064433 ---\n",
      "--- epoch: 1899, loss: 0.076561, val_loss: 0.064420 ---\n",
      "--- epoch: 1900, loss: 0.076550, val_loss: 0.064407 ---\n",
      "--- epoch: 1901, loss: 0.076539, val_loss: 0.064394 ---\n",
      "--- epoch: 1902, loss: 0.076528, val_loss: 0.064381 ---\n",
      "--- epoch: 1903, loss: 0.076517, val_loss: 0.064368 ---\n",
      "--- epoch: 1904, loss: 0.076506, val_loss: 0.064355 ---\n",
      "--- epoch: 1905, loss: 0.076495, val_loss: 0.064342 ---\n",
      "--- epoch: 1906, loss: 0.076484, val_loss: 0.064329 ---\n",
      "--- epoch: 1907, loss: 0.076473, val_loss: 0.064316 ---\n",
      "--- epoch: 1908, loss: 0.076462, val_loss: 0.064303 ---\n",
      "--- epoch: 1909, loss: 0.076452, val_loss: 0.064291 ---\n",
      "--- epoch: 1910, loss: 0.076441, val_loss: 0.064278 ---\n",
      "--- epoch: 1911, loss: 0.076430, val_loss: 0.064265 ---\n",
      "--- epoch: 1912, loss: 0.076419, val_loss: 0.064252 ---\n",
      "--- epoch: 1913, loss: 0.076408, val_loss: 0.064239 ---\n",
      "--- epoch: 1914, loss: 0.076397, val_loss: 0.064226 ---\n",
      "--- epoch: 1915, loss: 0.076386, val_loss: 0.064214 ---\n",
      "--- epoch: 1916, loss: 0.076376, val_loss: 0.064201 ---\n",
      "--- epoch: 1917, loss: 0.076365, val_loss: 0.064188 ---\n",
      "--- epoch: 1918, loss: 0.076354, val_loss: 0.064175 ---\n",
      "--- epoch: 1919, loss: 0.076343, val_loss: 0.064162 ---\n",
      "--- epoch: 1920, loss: 0.076332, val_loss: 0.064150 ---\n",
      "--- epoch: 1921, loss: 0.076322, val_loss: 0.064137 ---\n",
      "--- epoch: 1922, loss: 0.076311, val_loss: 0.064124 ---\n",
      "--- epoch: 1923, loss: 0.076300, val_loss: 0.064111 ---\n",
      "--- epoch: 1924, loss: 0.076289, val_loss: 0.064099 ---\n",
      "--- epoch: 1925, loss: 0.076279, val_loss: 0.064086 ---\n",
      "--- epoch: 1926, loss: 0.076268, val_loss: 0.064073 ---\n",
      "--- epoch: 1927, loss: 0.076257, val_loss: 0.064061 ---\n",
      "--- epoch: 1928, loss: 0.076247, val_loss: 0.064048 ---\n",
      "--- epoch: 1929, loss: 0.076236, val_loss: 0.064035 ---\n",
      "--- epoch: 1930, loss: 0.076225, val_loss: 0.064023 ---\n",
      "--- epoch: 1931, loss: 0.076215, val_loss: 0.064010 ---\n",
      "--- epoch: 1932, loss: 0.076204, val_loss: 0.063997 ---\n",
      "--- epoch: 1933, loss: 0.076193, val_loss: 0.063985 ---\n",
      "--- epoch: 1934, loss: 0.076183, val_loss: 0.063972 ---\n",
      "--- epoch: 1935, loss: 0.076172, val_loss: 0.063960 ---\n",
      "--- epoch: 1936, loss: 0.076161, val_loss: 0.063947 ---\n",
      "--- epoch: 1937, loss: 0.076151, val_loss: 0.063934 ---\n",
      "--- epoch: 1938, loss: 0.076140, val_loss: 0.063922 ---\n",
      "--- epoch: 1939, loss: 0.076129, val_loss: 0.063909 ---\n",
      "--- epoch: 1940, loss: 0.076119, val_loss: 0.063897 ---\n",
      "--- epoch: 1941, loss: 0.076108, val_loss: 0.063884 ---\n",
      "--- epoch: 1942, loss: 0.076098, val_loss: 0.063872 ---\n",
      "--- epoch: 1943, loss: 0.076087, val_loss: 0.063859 ---\n",
      "--- epoch: 1944, loss: 0.076077, val_loss: 0.063847 ---\n",
      "--- epoch: 1945, loss: 0.076066, val_loss: 0.063834 ---\n",
      "--- epoch: 1946, loss: 0.076056, val_loss: 0.063822 ---\n",
      "--- epoch: 1947, loss: 0.076045, val_loss: 0.063809 ---\n",
      "--- epoch: 1948, loss: 0.076035, val_loss: 0.063797 ---\n",
      "--- epoch: 1949, loss: 0.076024, val_loss: 0.063784 ---\n",
      "--- epoch: 1950, loss: 0.076014, val_loss: 0.063772 ---\n",
      "--- epoch: 1951, loss: 0.076003, val_loss: 0.063759 ---\n",
      "--- epoch: 1952, loss: 0.075993, val_loss: 0.063747 ---\n",
      "--- epoch: 1953, loss: 0.075982, val_loss: 0.063735 ---\n",
      "--- epoch: 1954, loss: 0.075972, val_loss: 0.063722 ---\n",
      "--- epoch: 1955, loss: 0.075961, val_loss: 0.063710 ---\n",
      "--- epoch: 1956, loss: 0.075951, val_loss: 0.063697 ---\n",
      "--- epoch: 1957, loss: 0.075940, val_loss: 0.063685 ---\n",
      "--- epoch: 1958, loss: 0.075930, val_loss: 0.063673 ---\n",
      "--- epoch: 1959, loss: 0.075920, val_loss: 0.063660 ---\n",
      "--- epoch: 1960, loss: 0.075909, val_loss: 0.063648 ---\n",
      "--- epoch: 1961, loss: 0.075899, val_loss: 0.063636 ---\n",
      "--- epoch: 1962, loss: 0.075888, val_loss: 0.063623 ---\n",
      "--- epoch: 1963, loss: 0.075878, val_loss: 0.063611 ---\n",
      "--- epoch: 1964, loss: 0.075868, val_loss: 0.063599 ---\n",
      "--- epoch: 1965, loss: 0.075857, val_loss: 0.063587 ---\n",
      "--- epoch: 1966, loss: 0.075847, val_loss: 0.063574 ---\n",
      "--- epoch: 1967, loss: 0.075837, val_loss: 0.063562 ---\n",
      "--- epoch: 1968, loss: 0.075826, val_loss: 0.063550 ---\n",
      "--- epoch: 1969, loss: 0.075816, val_loss: 0.063537 ---\n",
      "--- epoch: 1970, loss: 0.075806, val_loss: 0.063525 ---\n",
      "--- epoch: 1971, loss: 0.075796, val_loss: 0.063513 ---\n",
      "--- epoch: 1972, loss: 0.075785, val_loss: 0.063501 ---\n",
      "--- epoch: 1973, loss: 0.075775, val_loss: 0.063489 ---\n",
      "--- epoch: 1974, loss: 0.075765, val_loss: 0.063476 ---\n",
      "--- epoch: 1975, loss: 0.075754, val_loss: 0.063464 ---\n",
      "--- epoch: 1976, loss: 0.075744, val_loss: 0.063452 ---\n",
      "--- epoch: 1977, loss: 0.075734, val_loss: 0.063440 ---\n",
      "--- epoch: 1978, loss: 0.075724, val_loss: 0.063428 ---\n",
      "--- epoch: 1979, loss: 0.075713, val_loss: 0.063415 ---\n",
      "--- epoch: 1980, loss: 0.075703, val_loss: 0.063403 ---\n",
      "--- epoch: 1981, loss: 0.075693, val_loss: 0.063391 ---\n",
      "--- epoch: 1982, loss: 0.075683, val_loss: 0.063379 ---\n",
      "--- epoch: 1983, loss: 0.075673, val_loss: 0.063367 ---\n",
      "--- epoch: 1984, loss: 0.075662, val_loss: 0.063355 ---\n",
      "--- epoch: 1985, loss: 0.075652, val_loss: 0.063343 ---\n",
      "--- epoch: 1986, loss: 0.075642, val_loss: 0.063331 ---\n",
      "--- epoch: 1987, loss: 0.075632, val_loss: 0.063318 ---\n",
      "--- epoch: 1988, loss: 0.075622, val_loss: 0.063306 ---\n",
      "--- epoch: 1989, loss: 0.075612, val_loss: 0.063294 ---\n",
      "--- epoch: 1990, loss: 0.075601, val_loss: 0.063282 ---\n",
      "--- epoch: 1991, loss: 0.075591, val_loss: 0.063270 ---\n",
      "--- epoch: 1992, loss: 0.075581, val_loss: 0.063258 ---\n",
      "--- epoch: 1993, loss: 0.075571, val_loss: 0.063246 ---\n",
      "--- epoch: 1994, loss: 0.075561, val_loss: 0.063234 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 1995, loss: 0.075551, val_loss: 0.063222 ---\n",
      "--- epoch: 1996, loss: 0.075541, val_loss: 0.063210 ---\n",
      "--- epoch: 1997, loss: 0.075531, val_loss: 0.063198 ---\n",
      "--- epoch: 1998, loss: 0.075521, val_loss: 0.063186 ---\n",
      "--- epoch: 1999, loss: 0.075511, val_loss: 0.063174 ---\n",
      "--- epoch: 2000, loss: 0.075501, val_loss: 0.063162 ---\n",
      "--- epoch: 2001, loss: 0.075491, val_loss: 0.063150 ---\n",
      "--- epoch: 2002, loss: 0.075481, val_loss: 0.063138 ---\n",
      "--- epoch: 2003, loss: 0.075470, val_loss: 0.063126 ---\n",
      "--- epoch: 2004, loss: 0.075460, val_loss: 0.063115 ---\n",
      "--- epoch: 2005, loss: 0.075450, val_loss: 0.063103 ---\n",
      "--- epoch: 2006, loss: 0.075440, val_loss: 0.063091 ---\n",
      "--- epoch: 2007, loss: 0.075430, val_loss: 0.063079 ---\n",
      "--- epoch: 2008, loss: 0.075421, val_loss: 0.063067 ---\n",
      "--- epoch: 2009, loss: 0.075411, val_loss: 0.063055 ---\n",
      "--- epoch: 2010, loss: 0.075401, val_loss: 0.063043 ---\n",
      "--- epoch: 2011, loss: 0.075391, val_loss: 0.063031 ---\n",
      "--- epoch: 2012, loss: 0.075381, val_loss: 0.063020 ---\n",
      "--- epoch: 2013, loss: 0.075371, val_loss: 0.063008 ---\n",
      "--- epoch: 2014, loss: 0.075361, val_loss: 0.062996 ---\n",
      "--- epoch: 2015, loss: 0.075351, val_loss: 0.062984 ---\n",
      "--- epoch: 2016, loss: 0.075341, val_loss: 0.062972 ---\n",
      "--- epoch: 2017, loss: 0.075331, val_loss: 0.062961 ---\n",
      "--- epoch: 2018, loss: 0.075321, val_loss: 0.062949 ---\n",
      "--- epoch: 2019, loss: 0.075311, val_loss: 0.062937 ---\n",
      "--- epoch: 2020, loss: 0.075302, val_loss: 0.062925 ---\n",
      "--- epoch: 2021, loss: 0.075292, val_loss: 0.062914 ---\n",
      "--- epoch: 2022, loss: 0.075282, val_loss: 0.062902 ---\n",
      "--- epoch: 2023, loss: 0.075272, val_loss: 0.062890 ---\n",
      "--- epoch: 2024, loss: 0.075262, val_loss: 0.062878 ---\n",
      "--- epoch: 2025, loss: 0.075252, val_loss: 0.062867 ---\n",
      "--- epoch: 2026, loss: 0.075243, val_loss: 0.062855 ---\n",
      "--- epoch: 2027, loss: 0.075233, val_loss: 0.062843 ---\n",
      "--- epoch: 2028, loss: 0.075223, val_loss: 0.062832 ---\n",
      "--- epoch: 2029, loss: 0.075213, val_loss: 0.062820 ---\n",
      "--- epoch: 2030, loss: 0.075203, val_loss: 0.062808 ---\n",
      "--- epoch: 2031, loss: 0.075194, val_loss: 0.062796 ---\n",
      "--- epoch: 2032, loss: 0.075184, val_loss: 0.062785 ---\n",
      "--- epoch: 2033, loss: 0.075174, val_loss: 0.062773 ---\n",
      "--- epoch: 2034, loss: 0.075164, val_loss: 0.062762 ---\n",
      "--- epoch: 2035, loss: 0.075155, val_loss: 0.062750 ---\n",
      "--- epoch: 2036, loss: 0.075145, val_loss: 0.062738 ---\n",
      "--- epoch: 2037, loss: 0.075135, val_loss: 0.062727 ---\n",
      "--- epoch: 2038, loss: 0.075125, val_loss: 0.062715 ---\n",
      "--- epoch: 2039, loss: 0.075116, val_loss: 0.062703 ---\n",
      "--- epoch: 2040, loss: 0.075106, val_loss: 0.062692 ---\n",
      "--- epoch: 2041, loss: 0.075096, val_loss: 0.062680 ---\n",
      "--- epoch: 2042, loss: 0.075086, val_loss: 0.062669 ---\n",
      "--- epoch: 2043, loss: 0.075077, val_loss: 0.062657 ---\n",
      "--- epoch: 2044, loss: 0.075067, val_loss: 0.062646 ---\n",
      "--- epoch: 2045, loss: 0.075057, val_loss: 0.062634 ---\n",
      "--- epoch: 2046, loss: 0.075048, val_loss: 0.062622 ---\n",
      "--- epoch: 2047, loss: 0.075038, val_loss: 0.062611 ---\n",
      "--- epoch: 2048, loss: 0.075028, val_loss: 0.062599 ---\n",
      "--- epoch: 2049, loss: 0.075019, val_loss: 0.062588 ---\n",
      "--- epoch: 2050, loss: 0.075009, val_loss: 0.062576 ---\n",
      "--- epoch: 2051, loss: 0.075000, val_loss: 0.062565 ---\n",
      "--- epoch: 2052, loss: 0.074990, val_loss: 0.062553 ---\n",
      "--- epoch: 2053, loss: 0.074980, val_loss: 0.062542 ---\n",
      "--- epoch: 2054, loss: 0.074971, val_loss: 0.062531 ---\n",
      "--- epoch: 2055, loss: 0.074961, val_loss: 0.062519 ---\n",
      "--- epoch: 2056, loss: 0.074952, val_loss: 0.062508 ---\n",
      "--- epoch: 2057, loss: 0.074942, val_loss: 0.062496 ---\n",
      "--- epoch: 2058, loss: 0.074932, val_loss: 0.062485 ---\n",
      "--- epoch: 2059, loss: 0.074923, val_loss: 0.062473 ---\n",
      "--- epoch: 2060, loss: 0.074913, val_loss: 0.062462 ---\n",
      "--- epoch: 2061, loss: 0.074904, val_loss: 0.062451 ---\n",
      "--- epoch: 2062, loss: 0.074894, val_loss: 0.062439 ---\n",
      "--- epoch: 2063, loss: 0.074885, val_loss: 0.062428 ---\n",
      "--- epoch: 2064, loss: 0.074875, val_loss: 0.062416 ---\n",
      "--- epoch: 2065, loss: 0.074866, val_loss: 0.062405 ---\n",
      "--- epoch: 2066, loss: 0.074856, val_loss: 0.062394 ---\n",
      "--- epoch: 2067, loss: 0.074847, val_loss: 0.062382 ---\n",
      "--- epoch: 2068, loss: 0.074837, val_loss: 0.062371 ---\n",
      "--- epoch: 2069, loss: 0.074828, val_loss: 0.062360 ---\n",
      "--- epoch: 2070, loss: 0.074818, val_loss: 0.062348 ---\n",
      "--- epoch: 2071, loss: 0.074809, val_loss: 0.062337 ---\n",
      "--- epoch: 2072, loss: 0.074799, val_loss: 0.062326 ---\n",
      "--- epoch: 2073, loss: 0.074790, val_loss: 0.062314 ---\n",
      "--- epoch: 2074, loss: 0.074781, val_loss: 0.062303 ---\n",
      "--- epoch: 2075, loss: 0.074771, val_loss: 0.062292 ---\n",
      "--- epoch: 2076, loss: 0.074762, val_loss: 0.062281 ---\n",
      "--- epoch: 2077, loss: 0.074752, val_loss: 0.062269 ---\n",
      "--- epoch: 2078, loss: 0.074743, val_loss: 0.062258 ---\n",
      "--- epoch: 2079, loss: 0.074733, val_loss: 0.062247 ---\n",
      "--- epoch: 2080, loss: 0.074724, val_loss: 0.062236 ---\n",
      "--- epoch: 2081, loss: 0.074715, val_loss: 0.062224 ---\n",
      "--- epoch: 2082, loss: 0.074705, val_loss: 0.062213 ---\n",
      "--- epoch: 2083, loss: 0.074696, val_loss: 0.062202 ---\n",
      "--- epoch: 2084, loss: 0.074687, val_loss: 0.062191 ---\n",
      "--- epoch: 2085, loss: 0.074677, val_loss: 0.062180 ---\n",
      "--- epoch: 2086, loss: 0.074668, val_loss: 0.062168 ---\n",
      "--- epoch: 2087, loss: 0.074659, val_loss: 0.062157 ---\n",
      "--- epoch: 2088, loss: 0.074649, val_loss: 0.062146 ---\n",
      "--- epoch: 2089, loss: 0.074640, val_loss: 0.062135 ---\n",
      "--- epoch: 2090, loss: 0.074631, val_loss: 0.062124 ---\n",
      "--- epoch: 2091, loss: 0.074621, val_loss: 0.062113 ---\n",
      "--- epoch: 2092, loss: 0.074612, val_loss: 0.062101 ---\n",
      "--- epoch: 2093, loss: 0.074603, val_loss: 0.062090 ---\n",
      "--- epoch: 2094, loss: 0.074593, val_loss: 0.062079 ---\n",
      "--- epoch: 2095, loss: 0.074584, val_loss: 0.062068 ---\n",
      "--- epoch: 2096, loss: 0.074575, val_loss: 0.062057 ---\n",
      "--- epoch: 2097, loss: 0.074566, val_loss: 0.062046 ---\n",
      "--- epoch: 2098, loss: 0.074556, val_loss: 0.062035 ---\n",
      "--- epoch: 2099, loss: 0.074547, val_loss: 0.062024 ---\n",
      "--- epoch: 2100, loss: 0.074538, val_loss: 0.062013 ---\n",
      "--- epoch: 2101, loss: 0.074529, val_loss: 0.062002 ---\n",
      "--- epoch: 2102, loss: 0.074520, val_loss: 0.061991 ---\n",
      "--- epoch: 2103, loss: 0.074510, val_loss: 0.061980 ---\n",
      "--- epoch: 2104, loss: 0.074501, val_loss: 0.061969 ---\n",
      "--- epoch: 2105, loss: 0.074492, val_loss: 0.061958 ---\n",
      "--- epoch: 2106, loss: 0.074483, val_loss: 0.061947 ---\n",
      "--- epoch: 2107, loss: 0.074474, val_loss: 0.061936 ---\n",
      "--- epoch: 2108, loss: 0.074464, val_loss: 0.061925 ---\n",
      "--- epoch: 2109, loss: 0.074455, val_loss: 0.061914 ---\n",
      "--- epoch: 2110, loss: 0.074446, val_loss: 0.061903 ---\n",
      "--- epoch: 2111, loss: 0.074437, val_loss: 0.061892 ---\n",
      "--- epoch: 2112, loss: 0.074428, val_loss: 0.061881 ---\n",
      "--- epoch: 2113, loss: 0.074419, val_loss: 0.061870 ---\n",
      "--- epoch: 2114, loss: 0.074409, val_loss: 0.061859 ---\n",
      "--- epoch: 2115, loss: 0.074400, val_loss: 0.061848 ---\n",
      "--- epoch: 2116, loss: 0.074391, val_loss: 0.061837 ---\n",
      "--- epoch: 2117, loss: 0.074382, val_loss: 0.061826 ---\n",
      "--- epoch: 2118, loss: 0.074373, val_loss: 0.061815 ---\n",
      "--- epoch: 2119, loss: 0.074364, val_loss: 0.061804 ---\n",
      "--- epoch: 2120, loss: 0.074355, val_loss: 0.061793 ---\n",
      "--- epoch: 2121, loss: 0.074346, val_loss: 0.061782 ---\n",
      "--- epoch: 2122, loss: 0.074337, val_loss: 0.061771 ---\n",
      "--- epoch: 2123, loss: 0.074328, val_loss: 0.061761 ---\n",
      "--- epoch: 2124, loss: 0.074319, val_loss: 0.061750 ---\n",
      "--- epoch: 2125, loss: 0.074309, val_loss: 0.061739 ---\n",
      "--- epoch: 2126, loss: 0.074300, val_loss: 0.061728 ---\n",
      "--- epoch: 2127, loss: 0.074291, val_loss: 0.061717 ---\n",
      "--- epoch: 2128, loss: 0.074282, val_loss: 0.061706 ---\n",
      "--- epoch: 2129, loss: 0.074273, val_loss: 0.061695 ---\n",
      "--- epoch: 2130, loss: 0.074264, val_loss: 0.061685 ---\n",
      "--- epoch: 2131, loss: 0.074255, val_loss: 0.061674 ---\n",
      "--- epoch: 2132, loss: 0.074246, val_loss: 0.061663 ---\n",
      "--- epoch: 2133, loss: 0.074237, val_loss: 0.061652 ---\n",
      "--- epoch: 2134, loss: 0.074228, val_loss: 0.061641 ---\n",
      "--- epoch: 2135, loss: 0.074219, val_loss: 0.061631 ---\n",
      "--- epoch: 2136, loss: 0.074210, val_loss: 0.061620 ---\n",
      "--- epoch: 2137, loss: 0.074201, val_loss: 0.061609 ---\n",
      "--- epoch: 2138, loss: 0.074192, val_loss: 0.061598 ---\n",
      "--- epoch: 2139, loss: 0.074184, val_loss: 0.061588 ---\n",
      "--- epoch: 2140, loss: 0.074175, val_loss: 0.061577 ---\n",
      "--- epoch: 2141, loss: 0.074166, val_loss: 0.061566 ---\n",
      "--- epoch: 2142, loss: 0.074157, val_loss: 0.061555 ---\n",
      "--- epoch: 2143, loss: 0.074148, val_loss: 0.061545 ---\n",
      "--- epoch: 2144, loss: 0.074139, val_loss: 0.061534 ---\n",
      "--- epoch: 2145, loss: 0.074130, val_loss: 0.061523 ---\n",
      "--- epoch: 2146, loss: 0.074121, val_loss: 0.061513 ---\n",
      "--- epoch: 2147, loss: 0.074112, val_loss: 0.061502 ---\n",
      "--- epoch: 2148, loss: 0.074103, val_loss: 0.061491 ---\n",
      "--- epoch: 2149, loss: 0.074094, val_loss: 0.061481 ---\n",
      "--- epoch: 2150, loss: 0.074086, val_loss: 0.061470 ---\n",
      "--- epoch: 2151, loss: 0.074077, val_loss: 0.061459 ---\n",
      "--- epoch: 2152, loss: 0.074068, val_loss: 0.061449 ---\n",
      "--- epoch: 2153, loss: 0.074059, val_loss: 0.061438 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 2154, loss: 0.074050, val_loss: 0.061427 ---\n",
      "--- epoch: 2155, loss: 0.074041, val_loss: 0.061417 ---\n",
      "--- epoch: 2156, loss: 0.074033, val_loss: 0.061406 ---\n",
      "--- epoch: 2157, loss: 0.074024, val_loss: 0.061395 ---\n",
      "--- epoch: 2158, loss: 0.074015, val_loss: 0.061385 ---\n",
      "--- epoch: 2159, loss: 0.074006, val_loss: 0.061374 ---\n",
      "--- epoch: 2160, loss: 0.073997, val_loss: 0.061364 ---\n",
      "--- epoch: 2161, loss: 0.073988, val_loss: 0.061353 ---\n",
      "--- epoch: 2162, loss: 0.073980, val_loss: 0.061343 ---\n",
      "--- epoch: 2163, loss: 0.073971, val_loss: 0.061332 ---\n",
      "--- epoch: 2164, loss: 0.073962, val_loss: 0.061321 ---\n",
      "--- epoch: 2165, loss: 0.073953, val_loss: 0.061311 ---\n",
      "--- epoch: 2166, loss: 0.073945, val_loss: 0.061300 ---\n",
      "--- epoch: 2167, loss: 0.073936, val_loss: 0.061290 ---\n",
      "--- epoch: 2168, loss: 0.073927, val_loss: 0.061279 ---\n",
      "--- epoch: 2169, loss: 0.073918, val_loss: 0.061269 ---\n",
      "--- epoch: 2170, loss: 0.073910, val_loss: 0.061258 ---\n",
      "--- epoch: 2171, loss: 0.073901, val_loss: 0.061248 ---\n",
      "--- epoch: 2172, loss: 0.073892, val_loss: 0.061237 ---\n",
      "--- epoch: 2173, loss: 0.073884, val_loss: 0.061227 ---\n",
      "--- epoch: 2174, loss: 0.073875, val_loss: 0.061216 ---\n",
      "--- epoch: 2175, loss: 0.073866, val_loss: 0.061206 ---\n",
      "--- epoch: 2176, loss: 0.073857, val_loss: 0.061195 ---\n",
      "--- epoch: 2177, loss: 0.073849, val_loss: 0.061185 ---\n",
      "--- epoch: 2178, loss: 0.073840, val_loss: 0.061175 ---\n",
      "--- epoch: 2179, loss: 0.073831, val_loss: 0.061164 ---\n",
      "--- epoch: 2180, loss: 0.073823, val_loss: 0.061154 ---\n",
      "--- epoch: 2181, loss: 0.073814, val_loss: 0.061143 ---\n",
      "--- epoch: 2182, loss: 0.073806, val_loss: 0.061133 ---\n",
      "--- epoch: 2183, loss: 0.073797, val_loss: 0.061122 ---\n",
      "--- epoch: 2184, loss: 0.073788, val_loss: 0.061112 ---\n",
      "--- epoch: 2185, loss: 0.073780, val_loss: 0.061102 ---\n",
      "--- epoch: 2186, loss: 0.073771, val_loss: 0.061091 ---\n",
      "--- epoch: 2187, loss: 0.073762, val_loss: 0.061081 ---\n",
      "--- epoch: 2188, loss: 0.073754, val_loss: 0.061071 ---\n",
      "--- epoch: 2189, loss: 0.073745, val_loss: 0.061060 ---\n",
      "--- epoch: 2190, loss: 0.073737, val_loss: 0.061050 ---\n",
      "--- epoch: 2191, loss: 0.073728, val_loss: 0.061039 ---\n",
      "--- epoch: 2192, loss: 0.073719, val_loss: 0.061029 ---\n",
      "--- epoch: 2193, loss: 0.073711, val_loss: 0.061019 ---\n",
      "--- epoch: 2194, loss: 0.073702, val_loss: 0.061008 ---\n",
      "--- epoch: 2195, loss: 0.073694, val_loss: 0.060998 ---\n",
      "--- epoch: 2196, loss: 0.073685, val_loss: 0.060988 ---\n",
      "--- epoch: 2197, loss: 0.073677, val_loss: 0.060978 ---\n",
      "--- epoch: 2198, loss: 0.073668, val_loss: 0.060967 ---\n",
      "--- epoch: 2199, loss: 0.073660, val_loss: 0.060957 ---\n",
      "--- epoch: 2200, loss: 0.073651, val_loss: 0.060947 ---\n",
      "--- epoch: 2201, loss: 0.073643, val_loss: 0.060936 ---\n",
      "--- epoch: 2202, loss: 0.073634, val_loss: 0.060926 ---\n",
      "--- epoch: 2203, loss: 0.073625, val_loss: 0.060916 ---\n",
      "--- epoch: 2204, loss: 0.073617, val_loss: 0.060906 ---\n",
      "--- epoch: 2205, loss: 0.073609, val_loss: 0.060895 ---\n",
      "--- epoch: 2206, loss: 0.073600, val_loss: 0.060885 ---\n",
      "--- epoch: 2207, loss: 0.073592, val_loss: 0.060875 ---\n",
      "--- epoch: 2208, loss: 0.073583, val_loss: 0.060865 ---\n",
      "--- epoch: 2209, loss: 0.073575, val_loss: 0.060854 ---\n",
      "--- epoch: 2210, loss: 0.073566, val_loss: 0.060844 ---\n",
      "--- epoch: 2211, loss: 0.073558, val_loss: 0.060834 ---\n",
      "--- epoch: 2212, loss: 0.073549, val_loss: 0.060824 ---\n",
      "--- epoch: 2213, loss: 0.073541, val_loss: 0.060814 ---\n",
      "--- epoch: 2214, loss: 0.073532, val_loss: 0.060803 ---\n",
      "--- epoch: 2215, loss: 0.073524, val_loss: 0.060793 ---\n",
      "--- epoch: 2216, loss: 0.073516, val_loss: 0.060783 ---\n",
      "--- epoch: 2217, loss: 0.073507, val_loss: 0.060773 ---\n",
      "--- epoch: 2218, loss: 0.073499, val_loss: 0.060763 ---\n",
      "--- epoch: 2219, loss: 0.073490, val_loss: 0.060753 ---\n",
      "--- epoch: 2220, loss: 0.073482, val_loss: 0.060743 ---\n",
      "--- epoch: 2221, loss: 0.073473, val_loss: 0.060732 ---\n",
      "--- epoch: 2222, loss: 0.073465, val_loss: 0.060722 ---\n",
      "--- epoch: 2223, loss: 0.073457, val_loss: 0.060712 ---\n",
      "--- epoch: 2224, loss: 0.073448, val_loss: 0.060702 ---\n",
      "--- epoch: 2225, loss: 0.073440, val_loss: 0.060692 ---\n",
      "--- epoch: 2226, loss: 0.073432, val_loss: 0.060682 ---\n",
      "--- epoch: 2227, loss: 0.073423, val_loss: 0.060672 ---\n",
      "--- epoch: 2228, loss: 0.073415, val_loss: 0.060662 ---\n",
      "--- epoch: 2229, loss: 0.073407, val_loss: 0.060652 ---\n",
      "--- epoch: 2230, loss: 0.073398, val_loss: 0.060642 ---\n",
      "--- epoch: 2231, loss: 0.073390, val_loss: 0.060632 ---\n",
      "--- epoch: 2232, loss: 0.073382, val_loss: 0.060621 ---\n",
      "--- epoch: 2233, loss: 0.073373, val_loss: 0.060611 ---\n",
      "--- epoch: 2234, loss: 0.073365, val_loss: 0.060601 ---\n",
      "--- epoch: 2235, loss: 0.073357, val_loss: 0.060591 ---\n",
      "--- epoch: 2236, loss: 0.073348, val_loss: 0.060581 ---\n",
      "--- epoch: 2237, loss: 0.073340, val_loss: 0.060571 ---\n",
      "--- epoch: 2238, loss: 0.073332, val_loss: 0.060561 ---\n",
      "--- epoch: 2239, loss: 0.073324, val_loss: 0.060551 ---\n",
      "--- epoch: 2240, loss: 0.073315, val_loss: 0.060541 ---\n",
      "--- epoch: 2241, loss: 0.073307, val_loss: 0.060531 ---\n",
      "--- epoch: 2242, loss: 0.073299, val_loss: 0.060521 ---\n",
      "--- epoch: 2243, loss: 0.073291, val_loss: 0.060512 ---\n",
      "--- epoch: 2244, loss: 0.073282, val_loss: 0.060502 ---\n",
      "--- epoch: 2245, loss: 0.073274, val_loss: 0.060492 ---\n",
      "--- epoch: 2246, loss: 0.073266, val_loss: 0.060482 ---\n",
      "--- epoch: 2247, loss: 0.073258, val_loss: 0.060472 ---\n",
      "--- epoch: 2248, loss: 0.073250, val_loss: 0.060462 ---\n",
      "--- epoch: 2249, loss: 0.073241, val_loss: 0.060452 ---\n",
      "--- epoch: 2250, loss: 0.073233, val_loss: 0.060442 ---\n",
      "--- epoch: 2251, loss: 0.073225, val_loss: 0.060432 ---\n",
      "--- epoch: 2252, loss: 0.073217, val_loss: 0.060422 ---\n",
      "--- epoch: 2253, loss: 0.073209, val_loss: 0.060412 ---\n",
      "--- epoch: 2254, loss: 0.073200, val_loss: 0.060402 ---\n",
      "--- epoch: 2255, loss: 0.073192, val_loss: 0.060392 ---\n",
      "--- epoch: 2256, loss: 0.073184, val_loss: 0.060383 ---\n",
      "--- epoch: 2257, loss: 0.073176, val_loss: 0.060373 ---\n",
      "--- epoch: 2258, loss: 0.073168, val_loss: 0.060363 ---\n",
      "--- epoch: 2259, loss: 0.073160, val_loss: 0.060353 ---\n",
      "--- epoch: 2260, loss: 0.073151, val_loss: 0.060343 ---\n",
      "--- epoch: 2261, loss: 0.073143, val_loss: 0.060333 ---\n",
      "--- epoch: 2262, loss: 0.073135, val_loss: 0.060323 ---\n",
      "--- epoch: 2263, loss: 0.073127, val_loss: 0.060314 ---\n",
      "--- epoch: 2264, loss: 0.073119, val_loss: 0.060304 ---\n",
      "--- epoch: 2265, loss: 0.073111, val_loss: 0.060294 ---\n",
      "--- epoch: 2266, loss: 0.073103, val_loss: 0.060284 ---\n",
      "--- epoch: 2267, loss: 0.073095, val_loss: 0.060274 ---\n",
      "--- epoch: 2268, loss: 0.073087, val_loss: 0.060264 ---\n",
      "--- epoch: 2269, loss: 0.073079, val_loss: 0.060255 ---\n",
      "--- epoch: 2270, loss: 0.073070, val_loss: 0.060245 ---\n",
      "--- epoch: 2271, loss: 0.073062, val_loss: 0.060235 ---\n",
      "--- epoch: 2272, loss: 0.073054, val_loss: 0.060225 ---\n",
      "--- epoch: 2273, loss: 0.073046, val_loss: 0.060216 ---\n",
      "--- epoch: 2274, loss: 0.073038, val_loss: 0.060206 ---\n",
      "--- epoch: 2275, loss: 0.073030, val_loss: 0.060196 ---\n",
      "--- epoch: 2276, loss: 0.073022, val_loss: 0.060186 ---\n",
      "--- epoch: 2277, loss: 0.073014, val_loss: 0.060177 ---\n",
      "--- epoch: 2278, loss: 0.073006, val_loss: 0.060167 ---\n",
      "--- epoch: 2279, loss: 0.072998, val_loss: 0.060157 ---\n",
      "--- epoch: 2280, loss: 0.072990, val_loss: 0.060147 ---\n",
      "--- epoch: 2281, loss: 0.072982, val_loss: 0.060138 ---\n",
      "--- epoch: 2282, loss: 0.072974, val_loss: 0.060128 ---\n",
      "--- epoch: 2283, loss: 0.072966, val_loss: 0.060118 ---\n",
      "--- epoch: 2284, loss: 0.072958, val_loss: 0.060109 ---\n",
      "--- epoch: 2285, loss: 0.072950, val_loss: 0.060099 ---\n",
      "--- epoch: 2286, loss: 0.072942, val_loss: 0.060089 ---\n",
      "--- epoch: 2287, loss: 0.072934, val_loss: 0.060080 ---\n",
      "--- epoch: 2288, loss: 0.072926, val_loss: 0.060070 ---\n",
      "--- epoch: 2289, loss: 0.072918, val_loss: 0.060060 ---\n",
      "--- epoch: 2290, loss: 0.072910, val_loss: 0.060051 ---\n",
      "--- epoch: 2291, loss: 0.072902, val_loss: 0.060041 ---\n",
      "--- epoch: 2292, loss: 0.072894, val_loss: 0.060031 ---\n",
      "--- epoch: 2293, loss: 0.072886, val_loss: 0.060022 ---\n",
      "--- epoch: 2294, loss: 0.072878, val_loss: 0.060012 ---\n",
      "--- epoch: 2295, loss: 0.072870, val_loss: 0.060002 ---\n",
      "--- epoch: 2296, loss: 0.072863, val_loss: 0.059993 ---\n",
      "--- epoch: 2297, loss: 0.072855, val_loss: 0.059983 ---\n",
      "--- epoch: 2298, loss: 0.072847, val_loss: 0.059974 ---\n",
      "--- epoch: 2299, loss: 0.072839, val_loss: 0.059964 ---\n",
      "--- epoch: 2300, loss: 0.072831, val_loss: 0.059954 ---\n",
      "--- epoch: 2301, loss: 0.072823, val_loss: 0.059945 ---\n",
      "--- epoch: 2302, loss: 0.072815, val_loss: 0.059935 ---\n",
      "--- epoch: 2303, loss: 0.072807, val_loss: 0.059926 ---\n",
      "--- epoch: 2304, loss: 0.072799, val_loss: 0.059916 ---\n",
      "--- epoch: 2305, loss: 0.072792, val_loss: 0.059907 ---\n",
      "--- epoch: 2306, loss: 0.072784, val_loss: 0.059897 ---\n",
      "--- epoch: 2307, loss: 0.072776, val_loss: 0.059888 ---\n",
      "--- epoch: 2308, loss: 0.072768, val_loss: 0.059878 ---\n",
      "--- epoch: 2309, loss: 0.072760, val_loss: 0.059869 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 2310, loss: 0.072752, val_loss: 0.059859 ---\n",
      "--- epoch: 2311, loss: 0.072744, val_loss: 0.059849 ---\n",
      "--- epoch: 2312, loss: 0.072737, val_loss: 0.059840 ---\n",
      "--- epoch: 2313, loss: 0.072729, val_loss: 0.059830 ---\n",
      "--- epoch: 2314, loss: 0.072721, val_loss: 0.059821 ---\n",
      "--- epoch: 2315, loss: 0.072713, val_loss: 0.059812 ---\n",
      "--- epoch: 2316, loss: 0.072705, val_loss: 0.059802 ---\n",
      "--- epoch: 2317, loss: 0.072698, val_loss: 0.059793 ---\n",
      "--- epoch: 2318, loss: 0.072690, val_loss: 0.059783 ---\n",
      "--- epoch: 2319, loss: 0.072682, val_loss: 0.059774 ---\n",
      "--- epoch: 2320, loss: 0.072674, val_loss: 0.059764 ---\n",
      "--- epoch: 2321, loss: 0.072666, val_loss: 0.059755 ---\n",
      "--- epoch: 2322, loss: 0.072659, val_loss: 0.059745 ---\n",
      "--- epoch: 2323, loss: 0.072651, val_loss: 0.059736 ---\n",
      "--- epoch: 2324, loss: 0.072643, val_loss: 0.059727 ---\n",
      "--- epoch: 2325, loss: 0.072635, val_loss: 0.059717 ---\n",
      "--- epoch: 2326, loss: 0.072628, val_loss: 0.059708 ---\n",
      "--- epoch: 2327, loss: 0.072620, val_loss: 0.059698 ---\n",
      "--- epoch: 2328, loss: 0.072612, val_loss: 0.059689 ---\n",
      "--- epoch: 2329, loss: 0.072605, val_loss: 0.059680 ---\n",
      "--- epoch: 2330, loss: 0.072597, val_loss: 0.059670 ---\n",
      "--- epoch: 2331, loss: 0.072589, val_loss: 0.059661 ---\n",
      "--- epoch: 2332, loss: 0.072581, val_loss: 0.059651 ---\n",
      "--- epoch: 2333, loss: 0.072574, val_loss: 0.059642 ---\n",
      "--- epoch: 2334, loss: 0.072566, val_loss: 0.059633 ---\n",
      "--- epoch: 2335, loss: 0.072558, val_loss: 0.059623 ---\n",
      "--- epoch: 2336, loss: 0.072551, val_loss: 0.059614 ---\n",
      "--- epoch: 2337, loss: 0.072543, val_loss: 0.059605 ---\n",
      "--- epoch: 2338, loss: 0.072535, val_loss: 0.059595 ---\n",
      "--- epoch: 2339, loss: 0.072528, val_loss: 0.059586 ---\n",
      "--- epoch: 2340, loss: 0.072520, val_loss: 0.059577 ---\n",
      "--- epoch: 2341, loss: 0.072512, val_loss: 0.059567 ---\n",
      "--- epoch: 2342, loss: 0.072505, val_loss: 0.059558 ---\n",
      "--- epoch: 2343, loss: 0.072497, val_loss: 0.059549 ---\n",
      "--- epoch: 2344, loss: 0.072489, val_loss: 0.059539 ---\n",
      "--- epoch: 2345, loss: 0.072482, val_loss: 0.059530 ---\n",
      "--- epoch: 2346, loss: 0.072474, val_loss: 0.059521 ---\n",
      "--- epoch: 2347, loss: 0.072466, val_loss: 0.059511 ---\n",
      "--- epoch: 2348, loss: 0.072459, val_loss: 0.059502 ---\n",
      "--- epoch: 2349, loss: 0.072451, val_loss: 0.059493 ---\n",
      "--- epoch: 2350, loss: 0.072444, val_loss: 0.059484 ---\n",
      "--- epoch: 2351, loss: 0.072436, val_loss: 0.059474 ---\n",
      "--- epoch: 2352, loss: 0.072428, val_loss: 0.059465 ---\n",
      "--- epoch: 2353, loss: 0.072421, val_loss: 0.059456 ---\n",
      "--- epoch: 2354, loss: 0.072413, val_loss: 0.059447 ---\n",
      "--- epoch: 2355, loss: 0.072406, val_loss: 0.059437 ---\n",
      "--- epoch: 2356, loss: 0.072398, val_loss: 0.059428 ---\n",
      "--- epoch: 2357, loss: 0.072390, val_loss: 0.059419 ---\n",
      "--- epoch: 2358, loss: 0.072383, val_loss: 0.059410 ---\n",
      "--- epoch: 2359, loss: 0.072375, val_loss: 0.059401 ---\n",
      "--- epoch: 2360, loss: 0.072368, val_loss: 0.059391 ---\n",
      "--- epoch: 2361, loss: 0.072360, val_loss: 0.059382 ---\n",
      "--- epoch: 2362, loss: 0.072353, val_loss: 0.059373 ---\n",
      "--- epoch: 2363, loss: 0.072345, val_loss: 0.059364 ---\n",
      "--- epoch: 2364, loss: 0.072338, val_loss: 0.059355 ---\n",
      "--- epoch: 2365, loss: 0.072330, val_loss: 0.059345 ---\n",
      "--- epoch: 2366, loss: 0.072323, val_loss: 0.059336 ---\n",
      "--- epoch: 2367, loss: 0.072315, val_loss: 0.059327 ---\n",
      "--- epoch: 2368, loss: 0.072307, val_loss: 0.059318 ---\n",
      "--- epoch: 2369, loss: 0.072300, val_loss: 0.059309 ---\n",
      "--- epoch: 2370, loss: 0.072292, val_loss: 0.059300 ---\n",
      "--- epoch: 2371, loss: 0.072285, val_loss: 0.059290 ---\n",
      "--- epoch: 2372, loss: 0.072278, val_loss: 0.059281 ---\n",
      "--- epoch: 2373, loss: 0.072270, val_loss: 0.059272 ---\n",
      "--- epoch: 2374, loss: 0.072263, val_loss: 0.059263 ---\n",
      "--- epoch: 2375, loss: 0.072255, val_loss: 0.059254 ---\n",
      "--- epoch: 2376, loss: 0.072248, val_loss: 0.059245 ---\n",
      "--- epoch: 2377, loss: 0.072240, val_loss: 0.059236 ---\n",
      "--- epoch: 2378, loss: 0.072233, val_loss: 0.059227 ---\n",
      "--- epoch: 2379, loss: 0.072225, val_loss: 0.059218 ---\n",
      "--- epoch: 2380, loss: 0.072218, val_loss: 0.059209 ---\n",
      "--- epoch: 2381, loss: 0.072210, val_loss: 0.059200 ---\n",
      "--- epoch: 2382, loss: 0.072203, val_loss: 0.059191 ---\n",
      "--- epoch: 2383, loss: 0.072196, val_loss: 0.059181 ---\n",
      "--- epoch: 2384, loss: 0.072188, val_loss: 0.059172 ---\n",
      "--- epoch: 2385, loss: 0.072181, val_loss: 0.059163 ---\n",
      "--- epoch: 2386, loss: 0.072173, val_loss: 0.059154 ---\n",
      "--- epoch: 2387, loss: 0.072166, val_loss: 0.059145 ---\n",
      "--- epoch: 2388, loss: 0.072159, val_loss: 0.059136 ---\n",
      "--- epoch: 2389, loss: 0.072151, val_loss: 0.059127 ---\n",
      "--- epoch: 2390, loss: 0.072144, val_loss: 0.059118 ---\n",
      "--- epoch: 2391, loss: 0.072136, val_loss: 0.059109 ---\n",
      "--- epoch: 2392, loss: 0.072129, val_loss: 0.059100 ---\n",
      "--- epoch: 2393, loss: 0.072122, val_loss: 0.059091 ---\n",
      "--- epoch: 2394, loss: 0.072114, val_loss: 0.059082 ---\n",
      "--- epoch: 2395, loss: 0.072107, val_loss: 0.059073 ---\n",
      "--- epoch: 2396, loss: 0.072099, val_loss: 0.059064 ---\n",
      "--- epoch: 2397, loss: 0.072092, val_loss: 0.059055 ---\n",
      "--- epoch: 2398, loss: 0.072085, val_loss: 0.059046 ---\n",
      "--- epoch: 2399, loss: 0.072077, val_loss: 0.059037 ---\n",
      "--- epoch: 2400, loss: 0.072070, val_loss: 0.059028 ---\n",
      "--- epoch: 2401, loss: 0.072063, val_loss: 0.059019 ---\n",
      "--- epoch: 2402, loss: 0.072055, val_loss: 0.059010 ---\n",
      "--- epoch: 2403, loss: 0.072048, val_loss: 0.059001 ---\n",
      "--- epoch: 2404, loss: 0.072041, val_loss: 0.058993 ---\n",
      "--- epoch: 2405, loss: 0.072033, val_loss: 0.058984 ---\n",
      "--- epoch: 2406, loss: 0.072026, val_loss: 0.058975 ---\n",
      "--- epoch: 2407, loss: 0.072019, val_loss: 0.058966 ---\n",
      "--- epoch: 2408, loss: 0.072012, val_loss: 0.058957 ---\n",
      "--- epoch: 2409, loss: 0.072004, val_loss: 0.058948 ---\n",
      "--- epoch: 2410, loss: 0.071997, val_loss: 0.058939 ---\n",
      "--- epoch: 2411, loss: 0.071990, val_loss: 0.058930 ---\n",
      "--- epoch: 2412, loss: 0.071982, val_loss: 0.058921 ---\n",
      "--- epoch: 2413, loss: 0.071975, val_loss: 0.058912 ---\n",
      "--- epoch: 2414, loss: 0.071968, val_loss: 0.058904 ---\n",
      "--- epoch: 2415, loss: 0.071961, val_loss: 0.058895 ---\n",
      "--- epoch: 2416, loss: 0.071953, val_loss: 0.058886 ---\n",
      "--- epoch: 2417, loss: 0.071946, val_loss: 0.058877 ---\n",
      "--- epoch: 2418, loss: 0.071939, val_loss: 0.058868 ---\n",
      "--- epoch: 2419, loss: 0.071932, val_loss: 0.058859 ---\n",
      "--- epoch: 2420, loss: 0.071925, val_loss: 0.058850 ---\n",
      "--- epoch: 2421, loss: 0.071917, val_loss: 0.058842 ---\n",
      "--- epoch: 2422, loss: 0.071910, val_loss: 0.058833 ---\n",
      "--- epoch: 2423, loss: 0.071903, val_loss: 0.058824 ---\n",
      "--- epoch: 2424, loss: 0.071896, val_loss: 0.058815 ---\n",
      "--- epoch: 2425, loss: 0.071888, val_loss: 0.058806 ---\n",
      "--- epoch: 2426, loss: 0.071881, val_loss: 0.058797 ---\n",
      "--- epoch: 2427, loss: 0.071874, val_loss: 0.058789 ---\n",
      "--- epoch: 2428, loss: 0.071867, val_loss: 0.058780 ---\n",
      "--- epoch: 2429, loss: 0.071860, val_loss: 0.058771 ---\n",
      "--- epoch: 2430, loss: 0.071852, val_loss: 0.058762 ---\n",
      "--- epoch: 2431, loss: 0.071845, val_loss: 0.058754 ---\n",
      "--- epoch: 2432, loss: 0.071838, val_loss: 0.058745 ---\n",
      "--- epoch: 2433, loss: 0.071831, val_loss: 0.058736 ---\n",
      "--- epoch: 2434, loss: 0.071824, val_loss: 0.058727 ---\n",
      "--- epoch: 2435, loss: 0.071817, val_loss: 0.058718 ---\n",
      "--- epoch: 2436, loss: 0.071809, val_loss: 0.058710 ---\n",
      "--- epoch: 2437, loss: 0.071802, val_loss: 0.058701 ---\n",
      "--- epoch: 2438, loss: 0.071795, val_loss: 0.058692 ---\n",
      "--- epoch: 2439, loss: 0.071788, val_loss: 0.058683 ---\n",
      "--- epoch: 2440, loss: 0.071781, val_loss: 0.058675 ---\n",
      "--- epoch: 2441, loss: 0.071774, val_loss: 0.058666 ---\n",
      "--- epoch: 2442, loss: 0.071767, val_loss: 0.058657 ---\n",
      "--- epoch: 2443, loss: 0.071760, val_loss: 0.058649 ---\n",
      "--- epoch: 2444, loss: 0.071752, val_loss: 0.058640 ---\n",
      "--- epoch: 2445, loss: 0.071745, val_loss: 0.058631 ---\n",
      "--- epoch: 2446, loss: 0.071738, val_loss: 0.058623 ---\n",
      "--- epoch: 2447, loss: 0.071731, val_loss: 0.058614 ---\n",
      "--- epoch: 2448, loss: 0.071724, val_loss: 0.058605 ---\n",
      "--- epoch: 2449, loss: 0.071717, val_loss: 0.058596 ---\n",
      "--- epoch: 2450, loss: 0.071710, val_loss: 0.058588 ---\n",
      "--- epoch: 2451, loss: 0.071703, val_loss: 0.058579 ---\n",
      "--- epoch: 2452, loss: 0.071696, val_loss: 0.058570 ---\n",
      "--- epoch: 2453, loss: 0.071689, val_loss: 0.058562 ---\n",
      "--- epoch: 2454, loss: 0.071682, val_loss: 0.058553 ---\n",
      "--- epoch: 2455, loss: 0.071675, val_loss: 0.058545 ---\n",
      "--- epoch: 2456, loss: 0.071667, val_loss: 0.058536 ---\n",
      "--- epoch: 2457, loss: 0.071660, val_loss: 0.058527 ---\n",
      "--- epoch: 2458, loss: 0.071653, val_loss: 0.058519 ---\n",
      "--- epoch: 2459, loss: 0.071646, val_loss: 0.058510 ---\n",
      "--- epoch: 2460, loss: 0.071639, val_loss: 0.058501 ---\n",
      "--- epoch: 2461, loss: 0.071632, val_loss: 0.058493 ---\n",
      "--- epoch: 2462, loss: 0.071625, val_loss: 0.058484 ---\n",
      "--- epoch: 2463, loss: 0.071618, val_loss: 0.058476 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 2464, loss: 0.071611, val_loss: 0.058467 ---\n",
      "--- epoch: 2465, loss: 0.071604, val_loss: 0.058458 ---\n",
      "--- epoch: 2466, loss: 0.071597, val_loss: 0.058450 ---\n",
      "--- epoch: 2467, loss: 0.071590, val_loss: 0.058441 ---\n",
      "--- epoch: 2468, loss: 0.071583, val_loss: 0.058433 ---\n",
      "--- epoch: 2469, loss: 0.071576, val_loss: 0.058424 ---\n",
      "--- epoch: 2470, loss: 0.071569, val_loss: 0.058416 ---\n",
      "--- epoch: 2471, loss: 0.071562, val_loss: 0.058407 ---\n",
      "--- epoch: 2472, loss: 0.071555, val_loss: 0.058398 ---\n",
      "--- epoch: 2473, loss: 0.071548, val_loss: 0.058390 ---\n",
      "--- epoch: 2474, loss: 0.071541, val_loss: 0.058381 ---\n",
      "--- epoch: 2475, loss: 0.071534, val_loss: 0.058373 ---\n",
      "--- epoch: 2476, loss: 0.071528, val_loss: 0.058364 ---\n",
      "--- epoch: 2477, loss: 0.071521, val_loss: 0.058356 ---\n",
      "--- epoch: 2478, loss: 0.071514, val_loss: 0.058347 ---\n",
      "--- epoch: 2479, loss: 0.071507, val_loss: 0.058339 ---\n",
      "--- epoch: 2480, loss: 0.071500, val_loss: 0.058330 ---\n",
      "--- epoch: 2481, loss: 0.071493, val_loss: 0.058322 ---\n",
      "--- epoch: 2482, loss: 0.071486, val_loss: 0.058313 ---\n",
      "--- epoch: 2483, loss: 0.071479, val_loss: 0.058305 ---\n",
      "--- epoch: 2484, loss: 0.071472, val_loss: 0.058296 ---\n",
      "--- epoch: 2485, loss: 0.071465, val_loss: 0.058288 ---\n",
      "--- epoch: 2486, loss: 0.071458, val_loss: 0.058279 ---\n",
      "--- epoch: 2487, loss: 0.071451, val_loss: 0.058271 ---\n",
      "--- epoch: 2488, loss: 0.071444, val_loss: 0.058262 ---\n",
      "--- epoch: 2489, loss: 0.071438, val_loss: 0.058254 ---\n",
      "--- epoch: 2490, loss: 0.071431, val_loss: 0.058245 ---\n",
      "--- epoch: 2491, loss: 0.071424, val_loss: 0.058237 ---\n",
      "--- epoch: 2492, loss: 0.071417, val_loss: 0.058229 ---\n",
      "--- epoch: 2493, loss: 0.071410, val_loss: 0.058220 ---\n",
      "--- epoch: 2494, loss: 0.071403, val_loss: 0.058212 ---\n",
      "--- epoch: 2495, loss: 0.071396, val_loss: 0.058203 ---\n",
      "--- epoch: 2496, loss: 0.071389, val_loss: 0.058195 ---\n",
      "--- epoch: 2497, loss: 0.071383, val_loss: 0.058186 ---\n",
      "--- epoch: 2498, loss: 0.071376, val_loss: 0.058178 ---\n",
      "--- epoch: 2499, loss: 0.071369, val_loss: 0.058170 ---\n",
      "--- epoch: 2500, loss: 0.071362, val_loss: 0.058161 ---\n",
      "--- epoch: 2501, loss: 0.071355, val_loss: 0.058153 ---\n",
      "--- epoch: 2502, loss: 0.071348, val_loss: 0.058144 ---\n",
      "--- epoch: 2503, loss: 0.071342, val_loss: 0.058136 ---\n",
      "--- epoch: 2504, loss: 0.071335, val_loss: 0.058128 ---\n",
      "--- epoch: 2505, loss: 0.071328, val_loss: 0.058119 ---\n",
      "--- epoch: 2506, loss: 0.071321, val_loss: 0.058111 ---\n",
      "--- epoch: 2507, loss: 0.071314, val_loss: 0.058103 ---\n",
      "--- epoch: 2508, loss: 0.071308, val_loss: 0.058094 ---\n",
      "--- epoch: 2509, loss: 0.071301, val_loss: 0.058086 ---\n",
      "--- epoch: 2510, loss: 0.071294, val_loss: 0.058078 ---\n",
      "--- epoch: 2511, loss: 0.071287, val_loss: 0.058069 ---\n",
      "--- epoch: 2512, loss: 0.071280, val_loss: 0.058061 ---\n",
      "--- epoch: 2513, loss: 0.071274, val_loss: 0.058053 ---\n",
      "--- epoch: 2514, loss: 0.071267, val_loss: 0.058044 ---\n",
      "--- epoch: 2515, loss: 0.071260, val_loss: 0.058036 ---\n",
      "--- epoch: 2516, loss: 0.071253, val_loss: 0.058028 ---\n",
      "--- epoch: 2517, loss: 0.071247, val_loss: 0.058019 ---\n",
      "--- epoch: 2518, loss: 0.071240, val_loss: 0.058011 ---\n",
      "--- epoch: 2519, loss: 0.071233, val_loss: 0.058003 ---\n",
      "--- epoch: 2520, loss: 0.071226, val_loss: 0.057994 ---\n",
      "--- epoch: 2521, loss: 0.071220, val_loss: 0.057986 ---\n",
      "--- epoch: 2522, loss: 0.071213, val_loss: 0.057978 ---\n",
      "--- epoch: 2523, loss: 0.071206, val_loss: 0.057970 ---\n",
      "--- epoch: 2524, loss: 0.071199, val_loss: 0.057961 ---\n",
      "--- epoch: 2525, loss: 0.071193, val_loss: 0.057953 ---\n",
      "--- epoch: 2526, loss: 0.071186, val_loss: 0.057945 ---\n",
      "--- epoch: 2527, loss: 0.071179, val_loss: 0.057937 ---\n",
      "--- epoch: 2528, loss: 0.071173, val_loss: 0.057928 ---\n",
      "--- epoch: 2529, loss: 0.071166, val_loss: 0.057920 ---\n",
      "--- epoch: 2530, loss: 0.071159, val_loss: 0.057912 ---\n",
      "--- epoch: 2531, loss: 0.071152, val_loss: 0.057904 ---\n",
      "--- epoch: 2532, loss: 0.071146, val_loss: 0.057895 ---\n",
      "--- epoch: 2533, loss: 0.071139, val_loss: 0.057887 ---\n",
      "--- epoch: 2534, loss: 0.071132, val_loss: 0.057879 ---\n",
      "--- epoch: 2535, loss: 0.071126, val_loss: 0.057871 ---\n",
      "--- epoch: 2536, loss: 0.071119, val_loss: 0.057862 ---\n",
      "--- epoch: 2537, loss: 0.071112, val_loss: 0.057854 ---\n",
      "--- epoch: 2538, loss: 0.071106, val_loss: 0.057846 ---\n",
      "--- epoch: 2539, loss: 0.071099, val_loss: 0.057838 ---\n",
      "--- epoch: 2540, loss: 0.071092, val_loss: 0.057830 ---\n",
      "--- epoch: 2541, loss: 0.071086, val_loss: 0.057821 ---\n",
      "--- epoch: 2542, loss: 0.071079, val_loss: 0.057813 ---\n",
      "--- epoch: 2543, loss: 0.071072, val_loss: 0.057805 ---\n",
      "--- epoch: 2544, loss: 0.071066, val_loss: 0.057797 ---\n",
      "--- epoch: 2545, loss: 0.071059, val_loss: 0.057789 ---\n",
      "--- epoch: 2546, loss: 0.071053, val_loss: 0.057781 ---\n",
      "--- epoch: 2547, loss: 0.071046, val_loss: 0.057772 ---\n",
      "--- epoch: 2548, loss: 0.071039, val_loss: 0.057764 ---\n",
      "--- epoch: 2549, loss: 0.071033, val_loss: 0.057756 ---\n",
      "--- epoch: 2550, loss: 0.071026, val_loss: 0.057748 ---\n",
      "--- epoch: 2551, loss: 0.071020, val_loss: 0.057740 ---\n",
      "--- epoch: 2552, loss: 0.071013, val_loss: 0.057732 ---\n",
      "--- epoch: 2553, loss: 0.071006, val_loss: 0.057724 ---\n",
      "--- epoch: 2554, loss: 0.071000, val_loss: 0.057715 ---\n",
      "--- epoch: 2555, loss: 0.070993, val_loss: 0.057707 ---\n",
      "--- epoch: 2556, loss: 0.070987, val_loss: 0.057699 ---\n",
      "--- epoch: 2557, loss: 0.070980, val_loss: 0.057691 ---\n",
      "--- epoch: 2558, loss: 0.070973, val_loss: 0.057683 ---\n",
      "--- epoch: 2559, loss: 0.070967, val_loss: 0.057675 ---\n",
      "--- epoch: 2560, loss: 0.070960, val_loss: 0.057667 ---\n",
      "--- epoch: 2561, loss: 0.070954, val_loss: 0.057659 ---\n",
      "--- epoch: 2562, loss: 0.070947, val_loss: 0.057651 ---\n",
      "--- epoch: 2563, loss: 0.070941, val_loss: 0.057643 ---\n",
      "--- epoch: 2564, loss: 0.070934, val_loss: 0.057635 ---\n",
      "--- epoch: 2565, loss: 0.070928, val_loss: 0.057626 ---\n",
      "--- epoch: 2566, loss: 0.070921, val_loss: 0.057618 ---\n",
      "--- epoch: 2567, loss: 0.070914, val_loss: 0.057610 ---\n",
      "--- epoch: 2568, loss: 0.070908, val_loss: 0.057602 ---\n",
      "--- epoch: 2569, loss: 0.070901, val_loss: 0.057594 ---\n",
      "--- epoch: 2570, loss: 0.070895, val_loss: 0.057586 ---\n",
      "--- epoch: 2571, loss: 0.070888, val_loss: 0.057578 ---\n",
      "--- epoch: 2572, loss: 0.070882, val_loss: 0.057570 ---\n",
      "--- epoch: 2573, loss: 0.070875, val_loss: 0.057562 ---\n",
      "--- epoch: 2574, loss: 0.070869, val_loss: 0.057554 ---\n",
      "--- epoch: 2575, loss: 0.070862, val_loss: 0.057546 ---\n",
      "--- epoch: 2576, loss: 0.070856, val_loss: 0.057538 ---\n",
      "--- epoch: 2577, loss: 0.070849, val_loss: 0.057530 ---\n",
      "--- epoch: 2578, loss: 0.070843, val_loss: 0.057522 ---\n",
      "--- epoch: 2579, loss: 0.070836, val_loss: 0.057514 ---\n",
      "--- epoch: 2580, loss: 0.070830, val_loss: 0.057506 ---\n",
      "--- epoch: 2581, loss: 0.070824, val_loss: 0.057498 ---\n",
      "--- epoch: 2582, loss: 0.070817, val_loss: 0.057490 ---\n",
      "--- epoch: 2583, loss: 0.070811, val_loss: 0.057482 ---\n",
      "--- epoch: 2584, loss: 0.070804, val_loss: 0.057474 ---\n",
      "--- epoch: 2585, loss: 0.070798, val_loss: 0.057466 ---\n",
      "--- epoch: 2586, loss: 0.070791, val_loss: 0.057458 ---\n",
      "--- epoch: 2587, loss: 0.070785, val_loss: 0.057450 ---\n",
      "--- epoch: 2588, loss: 0.070778, val_loss: 0.057442 ---\n",
      "--- epoch: 2589, loss: 0.070772, val_loss: 0.057434 ---\n",
      "--- epoch: 2590, loss: 0.070765, val_loss: 0.057427 ---\n",
      "--- epoch: 2591, loss: 0.070759, val_loss: 0.057419 ---\n",
      "--- epoch: 2592, loss: 0.070753, val_loss: 0.057411 ---\n",
      "--- epoch: 2593, loss: 0.070746, val_loss: 0.057403 ---\n",
      "--- epoch: 2594, loss: 0.070740, val_loss: 0.057395 ---\n",
      "--- epoch: 2595, loss: 0.070733, val_loss: 0.057387 ---\n",
      "--- epoch: 2596, loss: 0.070727, val_loss: 0.057379 ---\n",
      "--- epoch: 2597, loss: 0.070721, val_loss: 0.057371 ---\n",
      "--- epoch: 2598, loss: 0.070714, val_loss: 0.057363 ---\n",
      "--- epoch: 2599, loss: 0.070708, val_loss: 0.057355 ---\n",
      "--- epoch: 2600, loss: 0.070701, val_loss: 0.057347 ---\n",
      "--- epoch: 2601, loss: 0.070695, val_loss: 0.057339 ---\n",
      "--- epoch: 2602, loss: 0.070689, val_loss: 0.057332 ---\n",
      "--- epoch: 2603, loss: 0.070682, val_loss: 0.057324 ---\n",
      "--- epoch: 2604, loss: 0.070676, val_loss: 0.057316 ---\n",
      "--- epoch: 2605, loss: 0.070670, val_loss: 0.057308 ---\n",
      "--- epoch: 2606, loss: 0.070663, val_loss: 0.057300 ---\n",
      "--- epoch: 2607, loss: 0.070657, val_loss: 0.057292 ---\n",
      "--- epoch: 2608, loss: 0.070650, val_loss: 0.057284 ---\n",
      "--- epoch: 2609, loss: 0.070644, val_loss: 0.057277 ---\n",
      "--- epoch: 2610, loss: 0.070638, val_loss: 0.057269 ---\n",
      "--- epoch: 2611, loss: 0.070631, val_loss: 0.057261 ---\n",
      "--- epoch: 2612, loss: 0.070625, val_loss: 0.057253 ---\n",
      "--- epoch: 2613, loss: 0.070619, val_loss: 0.057245 ---\n",
      "--- epoch: 2614, loss: 0.070612, val_loss: 0.057237 ---\n",
      "--- epoch: 2615, loss: 0.070606, val_loss: 0.057230 ---\n",
      "--- epoch: 2616, loss: 0.070600, val_loss: 0.057222 ---\n",
      "--- epoch: 2617, loss: 0.070593, val_loss: 0.057214 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 2618, loss: 0.070587, val_loss: 0.057206 ---\n",
      "--- epoch: 2619, loss: 0.070581, val_loss: 0.057198 ---\n",
      "--- epoch: 2620, loss: 0.070574, val_loss: 0.057190 ---\n",
      "--- epoch: 2621, loss: 0.070568, val_loss: 0.057183 ---\n",
      "--- epoch: 2622, loss: 0.070562, val_loss: 0.057175 ---\n",
      "--- epoch: 2623, loss: 0.070556, val_loss: 0.057167 ---\n",
      "--- epoch: 2624, loss: 0.070549, val_loss: 0.057159 ---\n",
      "--- epoch: 2625, loss: 0.070543, val_loss: 0.057152 ---\n",
      "--- epoch: 2626, loss: 0.070537, val_loss: 0.057144 ---\n",
      "--- epoch: 2627, loss: 0.070530, val_loss: 0.057136 ---\n",
      "--- epoch: 2628, loss: 0.070524, val_loss: 0.057128 ---\n",
      "--- epoch: 2629, loss: 0.070518, val_loss: 0.057120 ---\n",
      "--- epoch: 2630, loss: 0.070512, val_loss: 0.057113 ---\n",
      "--- epoch: 2631, loss: 0.070505, val_loss: 0.057105 ---\n",
      "--- epoch: 2632, loss: 0.070499, val_loss: 0.057097 ---\n",
      "--- epoch: 2633, loss: 0.070493, val_loss: 0.057089 ---\n",
      "--- epoch: 2634, loss: 0.070487, val_loss: 0.057082 ---\n",
      "--- epoch: 2635, loss: 0.070480, val_loss: 0.057074 ---\n",
      "--- epoch: 2636, loss: 0.070474, val_loss: 0.057066 ---\n",
      "--- epoch: 2637, loss: 0.070468, val_loss: 0.057059 ---\n",
      "--- epoch: 2638, loss: 0.070462, val_loss: 0.057051 ---\n",
      "--- epoch: 2639, loss: 0.070455, val_loss: 0.057043 ---\n",
      "--- epoch: 2640, loss: 0.070449, val_loss: 0.057035 ---\n",
      "--- epoch: 2641, loss: 0.070443, val_loss: 0.057028 ---\n",
      "--- epoch: 2642, loss: 0.070437, val_loss: 0.057020 ---\n",
      "--- epoch: 2643, loss: 0.070431, val_loss: 0.057012 ---\n",
      "--- epoch: 2644, loss: 0.070424, val_loss: 0.057005 ---\n",
      "--- epoch: 2645, loss: 0.070418, val_loss: 0.056997 ---\n",
      "--- epoch: 2646, loss: 0.070412, val_loss: 0.056989 ---\n",
      "--- epoch: 2647, loss: 0.070406, val_loss: 0.056982 ---\n",
      "--- epoch: 2648, loss: 0.070400, val_loss: 0.056974 ---\n",
      "--- epoch: 2649, loss: 0.070393, val_loss: 0.056966 ---\n",
      "--- epoch: 2650, loss: 0.070387, val_loss: 0.056959 ---\n",
      "--- epoch: 2651, loss: 0.070381, val_loss: 0.056951 ---\n",
      "--- epoch: 2652, loss: 0.070375, val_loss: 0.056943 ---\n",
      "--- epoch: 2653, loss: 0.070369, val_loss: 0.056936 ---\n",
      "--- epoch: 2654, loss: 0.070363, val_loss: 0.056928 ---\n",
      "--- epoch: 2655, loss: 0.070356, val_loss: 0.056920 ---\n",
      "--- epoch: 2656, loss: 0.070350, val_loss: 0.056913 ---\n",
      "--- epoch: 2657, loss: 0.070344, val_loss: 0.056905 ---\n",
      "--- epoch: 2658, loss: 0.070338, val_loss: 0.056898 ---\n",
      "--- epoch: 2659, loss: 0.070332, val_loss: 0.056890 ---\n",
      "--- epoch: 2660, loss: 0.070326, val_loss: 0.056882 ---\n",
      "--- epoch: 2661, loss: 0.070320, val_loss: 0.056875 ---\n",
      "--- epoch: 2662, loss: 0.070313, val_loss: 0.056867 ---\n",
      "--- epoch: 2663, loss: 0.070307, val_loss: 0.056860 ---\n",
      "--- epoch: 2664, loss: 0.070301, val_loss: 0.056852 ---\n",
      "--- epoch: 2665, loss: 0.070295, val_loss: 0.056844 ---\n",
      "--- epoch: 2666, loss: 0.070289, val_loss: 0.056837 ---\n",
      "--- epoch: 2667, loss: 0.070283, val_loss: 0.056829 ---\n",
      "--- epoch: 2668, loss: 0.070277, val_loss: 0.056822 ---\n",
      "--- epoch: 2669, loss: 0.070271, val_loss: 0.056814 ---\n",
      "--- epoch: 2670, loss: 0.070264, val_loss: 0.056806 ---\n",
      "--- epoch: 2671, loss: 0.070258, val_loss: 0.056799 ---\n",
      "--- epoch: 2672, loss: 0.070252, val_loss: 0.056791 ---\n",
      "--- epoch: 2673, loss: 0.070246, val_loss: 0.056784 ---\n",
      "--- epoch: 2674, loss: 0.070240, val_loss: 0.056776 ---\n",
      "--- epoch: 2675, loss: 0.070234, val_loss: 0.056769 ---\n",
      "--- epoch: 2676, loss: 0.070228, val_loss: 0.056761 ---\n",
      "--- epoch: 2677, loss: 0.070222, val_loss: 0.056754 ---\n",
      "--- epoch: 2678, loss: 0.070216, val_loss: 0.056746 ---\n",
      "--- epoch: 2679, loss: 0.070210, val_loss: 0.056739 ---\n",
      "--- epoch: 2680, loss: 0.070204, val_loss: 0.056731 ---\n",
      "--- epoch: 2681, loss: 0.070198, val_loss: 0.056723 ---\n",
      "--- epoch: 2682, loss: 0.070192, val_loss: 0.056716 ---\n",
      "--- epoch: 2683, loss: 0.070185, val_loss: 0.056708 ---\n",
      "--- epoch: 2684, loss: 0.070179, val_loss: 0.056701 ---\n",
      "--- epoch: 2685, loss: 0.070173, val_loss: 0.056693 ---\n",
      "--- epoch: 2686, loss: 0.070167, val_loss: 0.056686 ---\n",
      "--- epoch: 2687, loss: 0.070161, val_loss: 0.056678 ---\n",
      "--- epoch: 2688, loss: 0.070155, val_loss: 0.056671 ---\n",
      "--- epoch: 2689, loss: 0.070149, val_loss: 0.056663 ---\n",
      "--- epoch: 2690, loss: 0.070143, val_loss: 0.056656 ---\n",
      "--- epoch: 2691, loss: 0.070137, val_loss: 0.056649 ---\n",
      "--- epoch: 2692, loss: 0.070131, val_loss: 0.056641 ---\n",
      "--- epoch: 2693, loss: 0.070125, val_loss: 0.056634 ---\n",
      "--- epoch: 2694, loss: 0.070119, val_loss: 0.056626 ---\n",
      "--- epoch: 2695, loss: 0.070113, val_loss: 0.056619 ---\n",
      "--- epoch: 2696, loss: 0.070107, val_loss: 0.056611 ---\n",
      "--- epoch: 2697, loss: 0.070101, val_loss: 0.056604 ---\n",
      "--- epoch: 2698, loss: 0.070095, val_loss: 0.056596 ---\n",
      "--- epoch: 2699, loss: 0.070089, val_loss: 0.056589 ---\n",
      "--- epoch: 2700, loss: 0.070083, val_loss: 0.056582 ---\n",
      "--- epoch: 2701, loss: 0.070077, val_loss: 0.056574 ---\n",
      "--- epoch: 2702, loss: 0.070071, val_loss: 0.056567 ---\n",
      "--- epoch: 2703, loss: 0.070065, val_loss: 0.056559 ---\n",
      "--- epoch: 2704, loss: 0.070059, val_loss: 0.056552 ---\n",
      "--- epoch: 2705, loss: 0.070053, val_loss: 0.056544 ---\n",
      "--- epoch: 2706, loss: 0.070047, val_loss: 0.056537 ---\n",
      "--- epoch: 2707, loss: 0.070041, val_loss: 0.056530 ---\n",
      "--- epoch: 2708, loss: 0.070036, val_loss: 0.056522 ---\n",
      "--- epoch: 2709, loss: 0.070030, val_loss: 0.056515 ---\n",
      "--- epoch: 2710, loss: 0.070024, val_loss: 0.056507 ---\n",
      "--- epoch: 2711, loss: 0.070018, val_loss: 0.056500 ---\n",
      "--- epoch: 2712, loss: 0.070012, val_loss: 0.056493 ---\n",
      "--- epoch: 2713, loss: 0.070006, val_loss: 0.056485 ---\n",
      "--- epoch: 2714, loss: 0.070000, val_loss: 0.056478 ---\n",
      "--- epoch: 2715, loss: 0.069994, val_loss: 0.056470 ---\n",
      "--- epoch: 2716, loss: 0.069988, val_loss: 0.056463 ---\n",
      "--- epoch: 2717, loss: 0.069982, val_loss: 0.056456 ---\n",
      "--- epoch: 2718, loss: 0.069976, val_loss: 0.056448 ---\n",
      "--- epoch: 2719, loss: 0.069970, val_loss: 0.056441 ---\n",
      "--- epoch: 2720, loss: 0.069964, val_loss: 0.056434 ---\n",
      "--- epoch: 2721, loss: 0.069958, val_loss: 0.056426 ---\n",
      "--- epoch: 2722, loss: 0.069952, val_loss: 0.056419 ---\n",
      "--- epoch: 2723, loss: 0.069947, val_loss: 0.056412 ---\n",
      "--- epoch: 2724, loss: 0.069941, val_loss: 0.056404 ---\n",
      "--- epoch: 2725, loss: 0.069935, val_loss: 0.056397 ---\n",
      "--- epoch: 2726, loss: 0.069929, val_loss: 0.056390 ---\n",
      "--- epoch: 2727, loss: 0.069923, val_loss: 0.056382 ---\n",
      "--- epoch: 2728, loss: 0.069917, val_loss: 0.056375 ---\n",
      "--- epoch: 2729, loss: 0.069911, val_loss: 0.056368 ---\n",
      "--- epoch: 2730, loss: 0.069905, val_loss: 0.056360 ---\n",
      "--- epoch: 2731, loss: 0.069900, val_loss: 0.056353 ---\n",
      "--- epoch: 2732, loss: 0.069894, val_loss: 0.056346 ---\n",
      "--- epoch: 2733, loss: 0.069888, val_loss: 0.056338 ---\n",
      "--- epoch: 2734, loss: 0.069882, val_loss: 0.056331 ---\n",
      "--- epoch: 2735, loss: 0.069876, val_loss: 0.056324 ---\n",
      "--- epoch: 2736, loss: 0.069870, val_loss: 0.056317 ---\n",
      "--- epoch: 2737, loss: 0.069864, val_loss: 0.056309 ---\n",
      "--- epoch: 2738, loss: 0.069859, val_loss: 0.056302 ---\n",
      "--- epoch: 2739, loss: 0.069853, val_loss: 0.056295 ---\n",
      "--- epoch: 2740, loss: 0.069847, val_loss: 0.056287 ---\n",
      "--- epoch: 2741, loss: 0.069841, val_loss: 0.056280 ---\n",
      "--- epoch: 2742, loss: 0.069835, val_loss: 0.056273 ---\n",
      "--- epoch: 2743, loss: 0.069829, val_loss: 0.056266 ---\n",
      "--- epoch: 2744, loss: 0.069824, val_loss: 0.056258 ---\n",
      "--- epoch: 2745, loss: 0.069818, val_loss: 0.056251 ---\n",
      "--- epoch: 2746, loss: 0.069812, val_loss: 0.056244 ---\n",
      "--- epoch: 2747, loss: 0.069806, val_loss: 0.056237 ---\n",
      "--- epoch: 2748, loss: 0.069800, val_loss: 0.056230 ---\n",
      "--- epoch: 2749, loss: 0.069795, val_loss: 0.056222 ---\n",
      "--- epoch: 2750, loss: 0.069789, val_loss: 0.056215 ---\n",
      "--- epoch: 2751, loss: 0.069783, val_loss: 0.056208 ---\n",
      "--- epoch: 2752, loss: 0.069777, val_loss: 0.056201 ---\n",
      "--- epoch: 2753, loss: 0.069771, val_loss: 0.056193 ---\n",
      "--- epoch: 2754, loss: 0.069766, val_loss: 0.056186 ---\n",
      "--- epoch: 2755, loss: 0.069760, val_loss: 0.056179 ---\n",
      "--- epoch: 2756, loss: 0.069754, val_loss: 0.056172 ---\n",
      "--- epoch: 2757, loss: 0.069748, val_loss: 0.056165 ---\n",
      "--- epoch: 2758, loss: 0.069743, val_loss: 0.056157 ---\n",
      "--- epoch: 2759, loss: 0.069737, val_loss: 0.056150 ---\n",
      "--- epoch: 2760, loss: 0.069731, val_loss: 0.056143 ---\n",
      "--- epoch: 2761, loss: 0.069725, val_loss: 0.056136 ---\n",
      "--- epoch: 2762, loss: 0.069719, val_loss: 0.056129 ---\n",
      "--- epoch: 2763, loss: 0.069714, val_loss: 0.056122 ---\n",
      "--- epoch: 2764, loss: 0.069708, val_loss: 0.056114 ---\n",
      "--- epoch: 2765, loss: 0.069702, val_loss: 0.056107 ---\n",
      "--- epoch: 2766, loss: 0.069696, val_loss: 0.056100 ---\n",
      "--- epoch: 2767, loss: 0.069691, val_loss: 0.056093 ---\n",
      "--- epoch: 2768, loss: 0.069685, val_loss: 0.056086 ---\n",
      "--- epoch: 2769, loss: 0.069679, val_loss: 0.056079 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 2770, loss: 0.069674, val_loss: 0.056072 ---\n",
      "--- epoch: 2771, loss: 0.069668, val_loss: 0.056064 ---\n",
      "--- epoch: 2772, loss: 0.069662, val_loss: 0.056057 ---\n",
      "--- epoch: 2773, loss: 0.069656, val_loss: 0.056050 ---\n",
      "--- epoch: 2774, loss: 0.069651, val_loss: 0.056043 ---\n",
      "--- epoch: 2775, loss: 0.069645, val_loss: 0.056036 ---\n",
      "--- epoch: 2776, loss: 0.069639, val_loss: 0.056029 ---\n",
      "--- epoch: 2777, loss: 0.069634, val_loss: 0.056022 ---\n",
      "--- epoch: 2778, loss: 0.069628, val_loss: 0.056015 ---\n",
      "--- epoch: 2779, loss: 0.069622, val_loss: 0.056007 ---\n",
      "--- epoch: 2780, loss: 0.069617, val_loss: 0.056000 ---\n",
      "--- epoch: 2781, loss: 0.069611, val_loss: 0.055993 ---\n",
      "--- epoch: 2782, loss: 0.069605, val_loss: 0.055986 ---\n",
      "--- epoch: 2783, loss: 0.069599, val_loss: 0.055979 ---\n",
      "--- epoch: 2784, loss: 0.069594, val_loss: 0.055972 ---\n",
      "--- epoch: 2785, loss: 0.069588, val_loss: 0.055965 ---\n",
      "--- epoch: 2786, loss: 0.069582, val_loss: 0.055958 ---\n",
      "--- epoch: 2787, loss: 0.069577, val_loss: 0.055951 ---\n",
      "--- epoch: 2788, loss: 0.069571, val_loss: 0.055944 ---\n",
      "--- epoch: 2789, loss: 0.069565, val_loss: 0.055937 ---\n",
      "--- epoch: 2790, loss: 0.069560, val_loss: 0.055930 ---\n",
      "--- epoch: 2791, loss: 0.069554, val_loss: 0.055922 ---\n",
      "--- epoch: 2792, loss: 0.069548, val_loss: 0.055915 ---\n",
      "--- epoch: 2793, loss: 0.069543, val_loss: 0.055908 ---\n",
      "--- epoch: 2794, loss: 0.069537, val_loss: 0.055901 ---\n",
      "--- epoch: 2795, loss: 0.069532, val_loss: 0.055894 ---\n",
      "--- epoch: 2796, loss: 0.069526, val_loss: 0.055887 ---\n",
      "--- epoch: 2797, loss: 0.069520, val_loss: 0.055880 ---\n",
      "--- epoch: 2798, loss: 0.069515, val_loss: 0.055873 ---\n",
      "--- epoch: 2799, loss: 0.069509, val_loss: 0.055866 ---\n",
      "--- epoch: 2800, loss: 0.069503, val_loss: 0.055859 ---\n",
      "--- epoch: 2801, loss: 0.069498, val_loss: 0.055852 ---\n",
      "--- epoch: 2802, loss: 0.069492, val_loss: 0.055845 ---\n",
      "--- epoch: 2803, loss: 0.069487, val_loss: 0.055838 ---\n",
      "--- epoch: 2804, loss: 0.069481, val_loss: 0.055831 ---\n",
      "--- epoch: 2805, loss: 0.069475, val_loss: 0.055824 ---\n",
      "--- epoch: 2806, loss: 0.069470, val_loss: 0.055817 ---\n",
      "--- epoch: 2807, loss: 0.069464, val_loss: 0.055810 ---\n",
      "--- epoch: 2808, loss: 0.069459, val_loss: 0.055803 ---\n",
      "--- epoch: 2809, loss: 0.069453, val_loss: 0.055796 ---\n",
      "--- epoch: 2810, loss: 0.069448, val_loss: 0.055789 ---\n",
      "--- epoch: 2811, loss: 0.069442, val_loss: 0.055782 ---\n",
      "--- epoch: 2812, loss: 0.069436, val_loss: 0.055775 ---\n",
      "--- epoch: 2813, loss: 0.069431, val_loss: 0.055768 ---\n",
      "--- epoch: 2814, loss: 0.069425, val_loss: 0.055761 ---\n",
      "--- epoch: 2815, loss: 0.069420, val_loss: 0.055754 ---\n",
      "--- epoch: 2816, loss: 0.069414, val_loss: 0.055747 ---\n",
      "--- epoch: 2817, loss: 0.069409, val_loss: 0.055740 ---\n",
      "--- epoch: 2818, loss: 0.069403, val_loss: 0.055734 ---\n",
      "--- epoch: 2819, loss: 0.069397, val_loss: 0.055727 ---\n",
      "--- epoch: 2820, loss: 0.069392, val_loss: 0.055720 ---\n",
      "--- epoch: 2821, loss: 0.069386, val_loss: 0.055713 ---\n",
      "--- epoch: 2822, loss: 0.069381, val_loss: 0.055706 ---\n",
      "--- epoch: 2823, loss: 0.069375, val_loss: 0.055699 ---\n",
      "--- epoch: 2824, loss: 0.069370, val_loss: 0.055692 ---\n",
      "--- epoch: 2825, loss: 0.069364, val_loss: 0.055685 ---\n",
      "--- epoch: 2826, loss: 0.069359, val_loss: 0.055678 ---\n",
      "--- epoch: 2827, loss: 0.069353, val_loss: 0.055671 ---\n",
      "--- epoch: 2828, loss: 0.069348, val_loss: 0.055664 ---\n",
      "--- epoch: 2829, loss: 0.069342, val_loss: 0.055657 ---\n",
      "--- epoch: 2830, loss: 0.069336, val_loss: 0.055650 ---\n",
      "--- epoch: 2831, loss: 0.069331, val_loss: 0.055643 ---\n",
      "--- epoch: 2832, loss: 0.069325, val_loss: 0.055637 ---\n",
      "--- epoch: 2833, loss: 0.069320, val_loss: 0.055630 ---\n",
      "--- epoch: 2834, loss: 0.069314, val_loss: 0.055623 ---\n",
      "--- epoch: 2835, loss: 0.069309, val_loss: 0.055616 ---\n",
      "--- epoch: 2836, loss: 0.069303, val_loss: 0.055609 ---\n",
      "--- epoch: 2837, loss: 0.069298, val_loss: 0.055602 ---\n",
      "--- epoch: 2838, loss: 0.069292, val_loss: 0.055595 ---\n",
      "--- epoch: 2839, loss: 0.069287, val_loss: 0.055588 ---\n",
      "--- epoch: 2840, loss: 0.069281, val_loss: 0.055581 ---\n",
      "--- epoch: 2841, loss: 0.069276, val_loss: 0.055575 ---\n",
      "--- epoch: 2842, loss: 0.069270, val_loss: 0.055568 ---\n",
      "--- epoch: 2843, loss: 0.069265, val_loss: 0.055561 ---\n",
      "--- epoch: 2844, loss: 0.069260, val_loss: 0.055554 ---\n",
      "--- epoch: 2845, loss: 0.069254, val_loss: 0.055547 ---\n",
      "--- epoch: 2846, loss: 0.069249, val_loss: 0.055540 ---\n",
      "--- epoch: 2847, loss: 0.069243, val_loss: 0.055533 ---\n",
      "--- epoch: 2848, loss: 0.069238, val_loss: 0.055527 ---\n",
      "--- epoch: 2849, loss: 0.069232, val_loss: 0.055520 ---\n",
      "--- epoch: 2850, loss: 0.069227, val_loss: 0.055513 ---\n",
      "--- epoch: 2851, loss: 0.069221, val_loss: 0.055506 ---\n",
      "--- epoch: 2852, loss: 0.069216, val_loss: 0.055499 ---\n",
      "--- epoch: 2853, loss: 0.069210, val_loss: 0.055493 ---\n",
      "--- epoch: 2854, loss: 0.069205, val_loss: 0.055486 ---\n",
      "--- epoch: 2855, loss: 0.069200, val_loss: 0.055479 ---\n",
      "--- epoch: 2856, loss: 0.069194, val_loss: 0.055472 ---\n",
      "--- epoch: 2857, loss: 0.069189, val_loss: 0.055465 ---\n",
      "--- epoch: 2858, loss: 0.069183, val_loss: 0.055459 ---\n",
      "--- epoch: 2859, loss: 0.069178, val_loss: 0.055452 ---\n",
      "--- epoch: 2860, loss: 0.069173, val_loss: 0.055445 ---\n",
      "--- epoch: 2861, loss: 0.069167, val_loss: 0.055438 ---\n",
      "--- epoch: 2862, loss: 0.069162, val_loss: 0.055431 ---\n",
      "--- epoch: 2863, loss: 0.069156, val_loss: 0.055425 ---\n",
      "--- epoch: 2864, loss: 0.069151, val_loss: 0.055418 ---\n",
      "--- epoch: 2865, loss: 0.069145, val_loss: 0.055411 ---\n",
      "--- epoch: 2866, loss: 0.069140, val_loss: 0.055404 ---\n",
      "--- epoch: 2867, loss: 0.069135, val_loss: 0.055398 ---\n",
      "--- epoch: 2868, loss: 0.069129, val_loss: 0.055391 ---\n",
      "--- epoch: 2869, loss: 0.069124, val_loss: 0.055384 ---\n",
      "--- epoch: 2870, loss: 0.069119, val_loss: 0.055377 ---\n",
      "--- epoch: 2871, loss: 0.069113, val_loss: 0.055371 ---\n",
      "--- epoch: 2872, loss: 0.069108, val_loss: 0.055364 ---\n",
      "--- epoch: 2873, loss: 0.069102, val_loss: 0.055357 ---\n",
      "--- epoch: 2874, loss: 0.069097, val_loss: 0.055350 ---\n",
      "--- epoch: 2875, loss: 0.069092, val_loss: 0.055344 ---\n",
      "--- epoch: 2876, loss: 0.069086, val_loss: 0.055337 ---\n",
      "--- epoch: 2877, loss: 0.069081, val_loss: 0.055330 ---\n",
      "--- epoch: 2878, loss: 0.069076, val_loss: 0.055324 ---\n",
      "--- epoch: 2879, loss: 0.069070, val_loss: 0.055317 ---\n",
      "--- epoch: 2880, loss: 0.069065, val_loss: 0.055310 ---\n",
      "--- epoch: 2881, loss: 0.069060, val_loss: 0.055303 ---\n",
      "--- epoch: 2882, loss: 0.069054, val_loss: 0.055297 ---\n",
      "--- epoch: 2883, loss: 0.069049, val_loss: 0.055290 ---\n",
      "--- epoch: 2884, loss: 0.069044, val_loss: 0.055283 ---\n",
      "--- epoch: 2885, loss: 0.069038, val_loss: 0.055277 ---\n",
      "--- epoch: 2886, loss: 0.069033, val_loss: 0.055270 ---\n",
      "--- epoch: 2887, loss: 0.069028, val_loss: 0.055263 ---\n",
      "--- epoch: 2888, loss: 0.069022, val_loss: 0.055257 ---\n",
      "--- epoch: 2889, loss: 0.069017, val_loss: 0.055250 ---\n",
      "--- epoch: 2890, loss: 0.069012, val_loss: 0.055243 ---\n",
      "--- epoch: 2891, loss: 0.069006, val_loss: 0.055236 ---\n",
      "--- epoch: 2892, loss: 0.069001, val_loss: 0.055230 ---\n",
      "--- epoch: 2893, loss: 0.068996, val_loss: 0.055223 ---\n",
      "--- epoch: 2894, loss: 0.068990, val_loss: 0.055216 ---\n",
      "--- epoch: 2895, loss: 0.068985, val_loss: 0.055210 ---\n",
      "--- epoch: 2896, loss: 0.068980, val_loss: 0.055203 ---\n",
      "--- epoch: 2897, loss: 0.068974, val_loss: 0.055196 ---\n",
      "--- epoch: 2898, loss: 0.068969, val_loss: 0.055190 ---\n",
      "--- epoch: 2899, loss: 0.068964, val_loss: 0.055183 ---\n",
      "--- epoch: 2900, loss: 0.068959, val_loss: 0.055177 ---\n",
      "--- epoch: 2901, loss: 0.068953, val_loss: 0.055170 ---\n",
      "--- epoch: 2902, loss: 0.068948, val_loss: 0.055163 ---\n",
      "--- epoch: 2903, loss: 0.068943, val_loss: 0.055157 ---\n",
      "--- epoch: 2904, loss: 0.068937, val_loss: 0.055150 ---\n",
      "--- epoch: 2905, loss: 0.068932, val_loss: 0.055143 ---\n",
      "--- epoch: 2906, loss: 0.068927, val_loss: 0.055137 ---\n",
      "--- epoch: 2907, loss: 0.068922, val_loss: 0.055130 ---\n",
      "--- epoch: 2908, loss: 0.068916, val_loss: 0.055124 ---\n",
      "--- epoch: 2909, loss: 0.068911, val_loss: 0.055117 ---\n",
      "--- epoch: 2910, loss: 0.068906, val_loss: 0.055110 ---\n",
      "--- epoch: 2911, loss: 0.068901, val_loss: 0.055104 ---\n",
      "--- epoch: 2912, loss: 0.068895, val_loss: 0.055097 ---\n",
      "--- epoch: 2913, loss: 0.068890, val_loss: 0.055091 ---\n",
      "--- epoch: 2914, loss: 0.068885, val_loss: 0.055084 ---\n",
      "--- epoch: 2915, loss: 0.068880, val_loss: 0.055077 ---\n",
      "--- epoch: 2916, loss: 0.068874, val_loss: 0.055071 ---\n",
      "--- epoch: 2917, loss: 0.068869, val_loss: 0.055064 ---\n",
      "--- epoch: 2918, loss: 0.068864, val_loss: 0.055058 ---\n",
      "--- epoch: 2919, loss: 0.068859, val_loss: 0.055051 ---\n",
      "--- epoch: 2920, loss: 0.068853, val_loss: 0.055044 ---\n",
      "--- epoch: 2921, loss: 0.068848, val_loss: 0.055038 ---\n",
      "--- epoch: 2922, loss: 0.068843, val_loss: 0.055031 ---\n",
      "--- epoch: 2923, loss: 0.068838, val_loss: 0.055025 ---\n",
      "--- epoch: 2924, loss: 0.068833, val_loss: 0.055018 ---\n",
      "--- epoch: 2925, loss: 0.068827, val_loss: 0.055012 ---\n",
      "--- epoch: 2926, loss: 0.068822, val_loss: 0.055005 ---\n",
      "--- epoch: 2927, loss: 0.068817, val_loss: 0.054999 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 2928, loss: 0.068812, val_loss: 0.054992 ---\n",
      "--- epoch: 2929, loss: 0.068807, val_loss: 0.054986 ---\n",
      "--- epoch: 2930, loss: 0.068801, val_loss: 0.054979 ---\n",
      "--- epoch: 2931, loss: 0.068796, val_loss: 0.054972 ---\n",
      "--- epoch: 2932, loss: 0.068791, val_loss: 0.054966 ---\n",
      "--- epoch: 2933, loss: 0.068786, val_loss: 0.054959 ---\n",
      "--- epoch: 2934, loss: 0.068781, val_loss: 0.054953 ---\n",
      "--- epoch: 2935, loss: 0.068775, val_loss: 0.054946 ---\n",
      "--- epoch: 2936, loss: 0.068770, val_loss: 0.054940 ---\n",
      "--- epoch: 2937, loss: 0.068765, val_loss: 0.054933 ---\n",
      "--- epoch: 2938, loss: 0.068760, val_loss: 0.054927 ---\n",
      "--- epoch: 2939, loss: 0.068755, val_loss: 0.054920 ---\n",
      "--- epoch: 2940, loss: 0.068750, val_loss: 0.054914 ---\n",
      "--- epoch: 2941, loss: 0.068744, val_loss: 0.054907 ---\n",
      "--- epoch: 2942, loss: 0.068739, val_loss: 0.054901 ---\n",
      "--- epoch: 2943, loss: 0.068734, val_loss: 0.054894 ---\n",
      "--- epoch: 2944, loss: 0.068729, val_loss: 0.054888 ---\n",
      "--- epoch: 2945, loss: 0.068724, val_loss: 0.054881 ---\n",
      "--- epoch: 2946, loss: 0.068719, val_loss: 0.054875 ---\n",
      "--- epoch: 2947, loss: 0.068713, val_loss: 0.054868 ---\n",
      "--- epoch: 2948, loss: 0.068708, val_loss: 0.054862 ---\n",
      "--- epoch: 2949, loss: 0.068703, val_loss: 0.054855 ---\n",
      "--- epoch: 2950, loss: 0.068698, val_loss: 0.054849 ---\n",
      "--- epoch: 2951, loss: 0.068693, val_loss: 0.054843 ---\n",
      "--- epoch: 2952, loss: 0.068688, val_loss: 0.054836 ---\n",
      "--- epoch: 2953, loss: 0.068683, val_loss: 0.054830 ---\n",
      "--- epoch: 2954, loss: 0.068678, val_loss: 0.054823 ---\n",
      "--- epoch: 2955, loss: 0.068672, val_loss: 0.054817 ---\n",
      "--- epoch: 2956, loss: 0.068667, val_loss: 0.054810 ---\n",
      "--- epoch: 2957, loss: 0.068662, val_loss: 0.054804 ---\n",
      "--- epoch: 2958, loss: 0.068657, val_loss: 0.054797 ---\n",
      "--- epoch: 2959, loss: 0.068652, val_loss: 0.054791 ---\n",
      "--- epoch: 2960, loss: 0.068647, val_loss: 0.054784 ---\n",
      "--- epoch: 2961, loss: 0.068642, val_loss: 0.054778 ---\n",
      "--- epoch: 2962, loss: 0.068637, val_loss: 0.054772 ---\n",
      "--- epoch: 2963, loss: 0.068632, val_loss: 0.054765 ---\n",
      "--- epoch: 2964, loss: 0.068627, val_loss: 0.054759 ---\n",
      "--- epoch: 2965, loss: 0.068621, val_loss: 0.054752 ---\n",
      "--- epoch: 2966, loss: 0.068616, val_loss: 0.054746 ---\n",
      "--- epoch: 2967, loss: 0.068611, val_loss: 0.054740 ---\n",
      "--- epoch: 2968, loss: 0.068606, val_loss: 0.054733 ---\n",
      "--- epoch: 2969, loss: 0.068601, val_loss: 0.054727 ---\n",
      "--- epoch: 2970, loss: 0.068596, val_loss: 0.054720 ---\n",
      "--- epoch: 2971, loss: 0.068591, val_loss: 0.054714 ---\n",
      "--- epoch: 2972, loss: 0.068586, val_loss: 0.054708 ---\n",
      "--- epoch: 2973, loss: 0.068581, val_loss: 0.054701 ---\n",
      "--- epoch: 2974, loss: 0.068576, val_loss: 0.054695 ---\n",
      "--- epoch: 2975, loss: 0.068571, val_loss: 0.054689 ---\n",
      "--- epoch: 2976, loss: 0.068566, val_loss: 0.054682 ---\n",
      "--- epoch: 2977, loss: 0.068561, val_loss: 0.054676 ---\n",
      "--- epoch: 2978, loss: 0.068556, val_loss: 0.054669 ---\n",
      "--- epoch: 2979, loss: 0.068551, val_loss: 0.054663 ---\n",
      "--- epoch: 2980, loss: 0.068546, val_loss: 0.054657 ---\n",
      "--- epoch: 2981, loss: 0.068540, val_loss: 0.054650 ---\n",
      "--- epoch: 2982, loss: 0.068535, val_loss: 0.054644 ---\n",
      "--- epoch: 2983, loss: 0.068530, val_loss: 0.054638 ---\n",
      "--- epoch: 2984, loss: 0.068525, val_loss: 0.054631 ---\n",
      "--- epoch: 2985, loss: 0.068520, val_loss: 0.054625 ---\n",
      "--- epoch: 2986, loss: 0.068515, val_loss: 0.054619 ---\n",
      "--- epoch: 2987, loss: 0.068510, val_loss: 0.054612 ---\n",
      "--- epoch: 2988, loss: 0.068505, val_loss: 0.054606 ---\n",
      "--- epoch: 2989, loss: 0.068500, val_loss: 0.054600 ---\n",
      "--- epoch: 2990, loss: 0.068495, val_loss: 0.054593 ---\n",
      "--- epoch: 2991, loss: 0.068490, val_loss: 0.054587 ---\n",
      "--- epoch: 2992, loss: 0.068485, val_loss: 0.054581 ---\n",
      "--- epoch: 2993, loss: 0.068480, val_loss: 0.054574 ---\n",
      "--- epoch: 2994, loss: 0.068475, val_loss: 0.054568 ---\n",
      "--- epoch: 2995, loss: 0.068470, val_loss: 0.054562 ---\n",
      "--- epoch: 2996, loss: 0.068465, val_loss: 0.054555 ---\n",
      "--- epoch: 2997, loss: 0.068460, val_loss: 0.054549 ---\n",
      "--- epoch: 2998, loss: 0.068455, val_loss: 0.054543 ---\n",
      "--- epoch: 2999, loss: 0.068450, val_loss: 0.054537 ---\n",
      "--- epoch: 3000, loss: 0.068445, val_loss: 0.054530 ---\n",
      "--- epoch: 3001, loss: 0.068440, val_loss: 0.054524 ---\n",
      "--- epoch: 3002, loss: 0.068435, val_loss: 0.054518 ---\n",
      "--- epoch: 3003, loss: 0.068430, val_loss: 0.054511 ---\n",
      "--- epoch: 3004, loss: 0.068425, val_loss: 0.054505 ---\n",
      "--- epoch: 3005, loss: 0.068420, val_loss: 0.054499 ---\n",
      "--- epoch: 3006, loss: 0.068415, val_loss: 0.054492 ---\n",
      "--- epoch: 3007, loss: 0.068410, val_loss: 0.054486 ---\n",
      "--- epoch: 3008, loss: 0.068405, val_loss: 0.054480 ---\n",
      "--- epoch: 3009, loss: 0.068401, val_loss: 0.054474 ---\n",
      "--- epoch: 3010, loss: 0.068396, val_loss: 0.054467 ---\n",
      "--- epoch: 3011, loss: 0.068391, val_loss: 0.054461 ---\n",
      "--- epoch: 3012, loss: 0.068386, val_loss: 0.054455 ---\n",
      "--- epoch: 3013, loss: 0.068381, val_loss: 0.054449 ---\n",
      "--- epoch: 3014, loss: 0.068376, val_loss: 0.054442 ---\n",
      "--- epoch: 3015, loss: 0.068371, val_loss: 0.054436 ---\n",
      "--- epoch: 3016, loss: 0.068366, val_loss: 0.054430 ---\n",
      "--- epoch: 3017, loss: 0.068361, val_loss: 0.054424 ---\n",
      "--- epoch: 3018, loss: 0.068356, val_loss: 0.054417 ---\n",
      "--- epoch: 3019, loss: 0.068351, val_loss: 0.054411 ---\n",
      "--- epoch: 3020, loss: 0.068346, val_loss: 0.054405 ---\n",
      "--- epoch: 3021, loss: 0.068341, val_loss: 0.054399 ---\n",
      "--- epoch: 3022, loss: 0.068336, val_loss: 0.054393 ---\n",
      "--- epoch: 3023, loss: 0.068331, val_loss: 0.054386 ---\n",
      "--- epoch: 3024, loss: 0.068326, val_loss: 0.054380 ---\n",
      "--- epoch: 3025, loss: 0.068322, val_loss: 0.054374 ---\n",
      "--- epoch: 3026, loss: 0.068317, val_loss: 0.054368 ---\n",
      "--- epoch: 3027, loss: 0.068312, val_loss: 0.054361 ---\n",
      "--- epoch: 3028, loss: 0.068307, val_loss: 0.054355 ---\n",
      "--- epoch: 3029, loss: 0.068302, val_loss: 0.054349 ---\n",
      "--- epoch: 3030, loss: 0.068297, val_loss: 0.054343 ---\n",
      "--- epoch: 3031, loss: 0.068292, val_loss: 0.054337 ---\n",
      "--- epoch: 3032, loss: 0.068287, val_loss: 0.054331 ---\n",
      "--- epoch: 3033, loss: 0.068282, val_loss: 0.054324 ---\n",
      "--- epoch: 3034, loss: 0.068277, val_loss: 0.054318 ---\n",
      "--- epoch: 3035, loss: 0.068273, val_loss: 0.054312 ---\n",
      "--- epoch: 3036, loss: 0.068268, val_loss: 0.054306 ---\n",
      "--- epoch: 3037, loss: 0.068263, val_loss: 0.054300 ---\n",
      "--- epoch: 3038, loss: 0.068258, val_loss: 0.054293 ---\n",
      "--- epoch: 3039, loss: 0.068253, val_loss: 0.054287 ---\n",
      "--- epoch: 3040, loss: 0.068248, val_loss: 0.054281 ---\n",
      "--- epoch: 3041, loss: 0.068243, val_loss: 0.054275 ---\n",
      "--- epoch: 3042, loss: 0.068238, val_loss: 0.054269 ---\n",
      "--- epoch: 3043, loss: 0.068234, val_loss: 0.054263 ---\n",
      "--- epoch: 3044, loss: 0.068229, val_loss: 0.054257 ---\n",
      "--- epoch: 3045, loss: 0.068224, val_loss: 0.054250 ---\n",
      "--- epoch: 3046, loss: 0.068219, val_loss: 0.054244 ---\n",
      "--- epoch: 3047, loss: 0.068214, val_loss: 0.054238 ---\n",
      "--- epoch: 3048, loss: 0.068209, val_loss: 0.054232 ---\n",
      "--- epoch: 3049, loss: 0.068204, val_loss: 0.054226 ---\n",
      "--- epoch: 3050, loss: 0.068200, val_loss: 0.054220 ---\n",
      "--- epoch: 3051, loss: 0.068195, val_loss: 0.054213 ---\n",
      "--- epoch: 3052, loss: 0.068190, val_loss: 0.054207 ---\n",
      "--- epoch: 3053, loss: 0.068185, val_loss: 0.054201 ---\n",
      "--- epoch: 3054, loss: 0.068180, val_loss: 0.054195 ---\n",
      "--- epoch: 3055, loss: 0.068175, val_loss: 0.054189 ---\n",
      "--- epoch: 3056, loss: 0.068171, val_loss: 0.054183 ---\n",
      "--- epoch: 3057, loss: 0.068166, val_loss: 0.054177 ---\n",
      "--- epoch: 3058, loss: 0.068161, val_loss: 0.054171 ---\n",
      "--- epoch: 3059, loss: 0.068156, val_loss: 0.054165 ---\n",
      "--- epoch: 3060, loss: 0.068151, val_loss: 0.054158 ---\n",
      "--- epoch: 3061, loss: 0.068146, val_loss: 0.054152 ---\n",
      "--- epoch: 3062, loss: 0.068142, val_loss: 0.054146 ---\n",
      "--- epoch: 3063, loss: 0.068137, val_loss: 0.054140 ---\n",
      "--- epoch: 3064, loss: 0.068132, val_loss: 0.054134 ---\n",
      "--- epoch: 3065, loss: 0.068127, val_loss: 0.054128 ---\n",
      "--- epoch: 3066, loss: 0.068122, val_loss: 0.054122 ---\n",
      "--- epoch: 3067, loss: 0.068118, val_loss: 0.054116 ---\n",
      "--- epoch: 3068, loss: 0.068113, val_loss: 0.054110 ---\n",
      "--- epoch: 3069, loss: 0.068108, val_loss: 0.054104 ---\n",
      "--- epoch: 3070, loss: 0.068103, val_loss: 0.054098 ---\n",
      "--- epoch: 3071, loss: 0.068098, val_loss: 0.054092 ---\n",
      "--- epoch: 3072, loss: 0.068094, val_loss: 0.054085 ---\n",
      "--- epoch: 3073, loss: 0.068089, val_loss: 0.054079 ---\n",
      "--- epoch: 3074, loss: 0.068084, val_loss: 0.054073 ---\n",
      "--- epoch: 3075, loss: 0.068079, val_loss: 0.054067 ---\n",
      "--- epoch: 3076, loss: 0.068075, val_loss: 0.054061 ---\n",
      "--- epoch: 3077, loss: 0.068070, val_loss: 0.054055 ---\n",
      "--- epoch: 3078, loss: 0.068065, val_loss: 0.054049 ---\n",
      "--- epoch: 3079, loss: 0.068060, val_loss: 0.054043 ---\n",
      "--- epoch: 3080, loss: 0.068056, val_loss: 0.054037 ---\n",
      "--- epoch: 3081, loss: 0.068051, val_loss: 0.054031 ---\n",
      "--- epoch: 3082, loss: 0.068046, val_loss: 0.054025 ---\n",
      "--- epoch: 3083, loss: 0.068041, val_loss: 0.054019 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 3084, loss: 0.068037, val_loss: 0.054013 ---\n",
      "--- epoch: 3085, loss: 0.068032, val_loss: 0.054007 ---\n",
      "--- epoch: 3086, loss: 0.068027, val_loss: 0.054001 ---\n",
      "--- epoch: 3087, loss: 0.068022, val_loss: 0.053995 ---\n",
      "--- epoch: 3088, loss: 0.068018, val_loss: 0.053989 ---\n",
      "--- epoch: 3089, loss: 0.068013, val_loss: 0.053983 ---\n",
      "--- epoch: 3090, loss: 0.068008, val_loss: 0.053977 ---\n",
      "--- epoch: 3091, loss: 0.068003, val_loss: 0.053971 ---\n",
      "--- epoch: 3092, loss: 0.067999, val_loss: 0.053965 ---\n",
      "--- epoch: 3093, loss: 0.067994, val_loss: 0.053959 ---\n",
      "--- epoch: 3094, loss: 0.067989, val_loss: 0.053953 ---\n",
      "--- epoch: 3095, loss: 0.067984, val_loss: 0.053947 ---\n",
      "--- epoch: 3096, loss: 0.067980, val_loss: 0.053941 ---\n",
      "--- epoch: 3097, loss: 0.067975, val_loss: 0.053935 ---\n",
      "--- epoch: 3098, loss: 0.067970, val_loss: 0.053929 ---\n",
      "--- epoch: 3099, loss: 0.067966, val_loss: 0.053923 ---\n",
      "--- epoch: 3100, loss: 0.067961, val_loss: 0.053917 ---\n",
      "--- epoch: 3101, loss: 0.067956, val_loss: 0.053911 ---\n",
      "--- epoch: 3102, loss: 0.067952, val_loss: 0.053905 ---\n",
      "--- epoch: 3103, loss: 0.067947, val_loss: 0.053899 ---\n",
      "--- epoch: 3104, loss: 0.067942, val_loss: 0.053893 ---\n",
      "--- epoch: 3105, loss: 0.067937, val_loss: 0.053887 ---\n",
      "--- epoch: 3106, loss: 0.067933, val_loss: 0.053881 ---\n",
      "--- epoch: 3107, loss: 0.067928, val_loss: 0.053875 ---\n",
      "--- epoch: 3108, loss: 0.067923, val_loss: 0.053869 ---\n",
      "--- epoch: 3109, loss: 0.067919, val_loss: 0.053863 ---\n",
      "--- epoch: 3110, loss: 0.067914, val_loss: 0.053857 ---\n",
      "--- epoch: 3111, loss: 0.067909, val_loss: 0.053852 ---\n",
      "--- epoch: 3112, loss: 0.067905, val_loss: 0.053846 ---\n",
      "--- epoch: 3113, loss: 0.067900, val_loss: 0.053840 ---\n",
      "--- epoch: 3114, loss: 0.067895, val_loss: 0.053834 ---\n",
      "--- epoch: 3115, loss: 0.067891, val_loss: 0.053828 ---\n",
      "--- epoch: 3116, loss: 0.067886, val_loss: 0.053822 ---\n",
      "--- epoch: 3117, loss: 0.067881, val_loss: 0.053816 ---\n",
      "--- epoch: 3118, loss: 0.067877, val_loss: 0.053810 ---\n",
      "--- epoch: 3119, loss: 0.067872, val_loss: 0.053804 ---\n",
      "--- epoch: 3120, loss: 0.067867, val_loss: 0.053798 ---\n",
      "--- epoch: 3121, loss: 0.067863, val_loss: 0.053792 ---\n",
      "--- epoch: 3122, loss: 0.067858, val_loss: 0.053786 ---\n",
      "--- epoch: 3123, loss: 0.067853, val_loss: 0.053780 ---\n",
      "--- epoch: 3124, loss: 0.067849, val_loss: 0.053774 ---\n",
      "--- epoch: 3125, loss: 0.067844, val_loss: 0.053769 ---\n",
      "--- epoch: 3126, loss: 0.067839, val_loss: 0.053763 ---\n",
      "--- epoch: 3127, loss: 0.067835, val_loss: 0.053757 ---\n",
      "--- epoch: 3128, loss: 0.067830, val_loss: 0.053751 ---\n",
      "--- epoch: 3129, loss: 0.067825, val_loss: 0.053745 ---\n",
      "--- epoch: 3130, loss: 0.067821, val_loss: 0.053739 ---\n",
      "--- epoch: 3131, loss: 0.067816, val_loss: 0.053733 ---\n",
      "--- epoch: 3132, loss: 0.067812, val_loss: 0.053727 ---\n",
      "--- epoch: 3133, loss: 0.067807, val_loss: 0.053721 ---\n",
      "--- epoch: 3134, loss: 0.067802, val_loss: 0.053716 ---\n",
      "--- epoch: 3135, loss: 0.067798, val_loss: 0.053710 ---\n",
      "--- epoch: 3136, loss: 0.067793, val_loss: 0.053704 ---\n",
      "--- epoch: 3137, loss: 0.067788, val_loss: 0.053698 ---\n",
      "--- epoch: 3138, loss: 0.067784, val_loss: 0.053692 ---\n",
      "--- epoch: 3139, loss: 0.067779, val_loss: 0.053686 ---\n",
      "--- epoch: 3140, loss: 0.067775, val_loss: 0.053680 ---\n",
      "--- epoch: 3141, loss: 0.067770, val_loss: 0.053675 ---\n",
      "--- epoch: 3142, loss: 0.067765, val_loss: 0.053669 ---\n",
      "--- epoch: 3143, loss: 0.067761, val_loss: 0.053663 ---\n",
      "--- epoch: 3144, loss: 0.067756, val_loss: 0.053657 ---\n",
      "--- epoch: 3145, loss: 0.067752, val_loss: 0.053651 ---\n",
      "--- epoch: 3146, loss: 0.067747, val_loss: 0.053645 ---\n",
      "--- epoch: 3147, loss: 0.067743, val_loss: 0.053640 ---\n",
      "--- epoch: 3148, loss: 0.067738, val_loss: 0.053634 ---\n",
      "--- epoch: 3149, loss: 0.067733, val_loss: 0.053628 ---\n",
      "--- epoch: 3150, loss: 0.067729, val_loss: 0.053622 ---\n",
      "--- epoch: 3151, loss: 0.067724, val_loss: 0.053616 ---\n",
      "--- epoch: 3152, loss: 0.067720, val_loss: 0.053610 ---\n",
      "--- epoch: 3153, loss: 0.067715, val_loss: 0.053605 ---\n",
      "--- epoch: 3154, loss: 0.067710, val_loss: 0.053599 ---\n",
      "--- epoch: 3155, loss: 0.067706, val_loss: 0.053593 ---\n",
      "--- epoch: 3156, loss: 0.067701, val_loss: 0.053587 ---\n",
      "--- epoch: 3157, loss: 0.067697, val_loss: 0.053581 ---\n",
      "--- epoch: 3158, loss: 0.067692, val_loss: 0.053576 ---\n",
      "--- epoch: 3159, loss: 0.067688, val_loss: 0.053570 ---\n",
      "--- epoch: 3160, loss: 0.067683, val_loss: 0.053564 ---\n",
      "--- epoch: 3161, loss: 0.067679, val_loss: 0.053558 ---\n",
      "--- epoch: 3162, loss: 0.067674, val_loss: 0.053552 ---\n",
      "--- epoch: 3163, loss: 0.067669, val_loss: 0.053547 ---\n",
      "--- epoch: 3164, loss: 0.067665, val_loss: 0.053541 ---\n",
      "--- epoch: 3165, loss: 0.067660, val_loss: 0.053535 ---\n",
      "--- epoch: 3166, loss: 0.067656, val_loss: 0.053529 ---\n",
      "--- epoch: 3167, loss: 0.067651, val_loss: 0.053523 ---\n",
      "--- epoch: 3168, loss: 0.067647, val_loss: 0.053518 ---\n",
      "--- epoch: 3169, loss: 0.067642, val_loss: 0.053512 ---\n",
      "--- epoch: 3170, loss: 0.067638, val_loss: 0.053506 ---\n",
      "--- epoch: 3171, loss: 0.067633, val_loss: 0.053500 ---\n",
      "--- epoch: 3172, loss: 0.067629, val_loss: 0.053495 ---\n",
      "--- epoch: 3173, loss: 0.067624, val_loss: 0.053489 ---\n",
      "--- epoch: 3174, loss: 0.067620, val_loss: 0.053483 ---\n",
      "--- epoch: 3175, loss: 0.067615, val_loss: 0.053477 ---\n",
      "--- epoch: 3176, loss: 0.067611, val_loss: 0.053472 ---\n",
      "--- epoch: 3177, loss: 0.067606, val_loss: 0.053466 ---\n",
      "--- epoch: 3178, loss: 0.067602, val_loss: 0.053460 ---\n",
      "--- epoch: 3179, loss: 0.067597, val_loss: 0.053454 ---\n",
      "--- epoch: 3180, loss: 0.067593, val_loss: 0.053449 ---\n",
      "--- epoch: 3181, loss: 0.067588, val_loss: 0.053443 ---\n",
      "--- epoch: 3182, loss: 0.067584, val_loss: 0.053437 ---\n",
      "--- epoch: 3183, loss: 0.067579, val_loss: 0.053431 ---\n",
      "--- epoch: 3184, loss: 0.067575, val_loss: 0.053426 ---\n",
      "--- epoch: 3185, loss: 0.067570, val_loss: 0.053420 ---\n",
      "--- epoch: 3186, loss: 0.067566, val_loss: 0.053414 ---\n",
      "--- epoch: 3187, loss: 0.067561, val_loss: 0.053408 ---\n",
      "--- epoch: 3188, loss: 0.067557, val_loss: 0.053403 ---\n",
      "--- epoch: 3189, loss: 0.067552, val_loss: 0.053397 ---\n",
      "--- epoch: 3190, loss: 0.067548, val_loss: 0.053391 ---\n",
      "--- epoch: 3191, loss: 0.067543, val_loss: 0.053386 ---\n",
      "--- epoch: 3192, loss: 0.067539, val_loss: 0.053380 ---\n",
      "--- epoch: 3193, loss: 0.067534, val_loss: 0.053374 ---\n",
      "--- epoch: 3194, loss: 0.067530, val_loss: 0.053369 ---\n",
      "--- epoch: 3195, loss: 0.067525, val_loss: 0.053363 ---\n",
      "--- epoch: 3196, loss: 0.067521, val_loss: 0.053357 ---\n",
      "--- epoch: 3197, loss: 0.067516, val_loss: 0.053351 ---\n",
      "--- epoch: 3198, loss: 0.067512, val_loss: 0.053346 ---\n",
      "--- epoch: 3199, loss: 0.067507, val_loss: 0.053340 ---\n",
      "--- epoch: 3200, loss: 0.067503, val_loss: 0.053334 ---\n",
      "--- epoch: 3201, loss: 0.067498, val_loss: 0.053329 ---\n",
      "--- epoch: 3202, loss: 0.067494, val_loss: 0.053323 ---\n",
      "--- epoch: 3203, loss: 0.067490, val_loss: 0.053317 ---\n",
      "--- epoch: 3204, loss: 0.067485, val_loss: 0.053312 ---\n",
      "--- epoch: 3205, loss: 0.067481, val_loss: 0.053306 ---\n",
      "--- epoch: 3206, loss: 0.067476, val_loss: 0.053300 ---\n",
      "--- epoch: 3207, loss: 0.067472, val_loss: 0.053295 ---\n",
      "--- epoch: 3208, loss: 0.067467, val_loss: 0.053289 ---\n",
      "--- epoch: 3209, loss: 0.067463, val_loss: 0.053283 ---\n",
      "--- epoch: 3210, loss: 0.067458, val_loss: 0.053278 ---\n",
      "--- epoch: 3211, loss: 0.067454, val_loss: 0.053272 ---\n",
      "--- epoch: 3212, loss: 0.067450, val_loss: 0.053266 ---\n",
      "--- epoch: 3213, loss: 0.067445, val_loss: 0.053261 ---\n",
      "--- epoch: 3214, loss: 0.067441, val_loss: 0.053255 ---\n",
      "--- epoch: 3215, loss: 0.067436, val_loss: 0.053249 ---\n",
      "--- epoch: 3216, loss: 0.067432, val_loss: 0.053244 ---\n",
      "--- epoch: 3217, loss: 0.067427, val_loss: 0.053238 ---\n",
      "--- epoch: 3218, loss: 0.067423, val_loss: 0.053232 ---\n",
      "--- epoch: 3219, loss: 0.067419, val_loss: 0.053227 ---\n",
      "--- epoch: 3220, loss: 0.067414, val_loss: 0.053221 ---\n",
      "--- epoch: 3221, loss: 0.067410, val_loss: 0.053216 ---\n",
      "--- epoch: 3222, loss: 0.067405, val_loss: 0.053210 ---\n",
      "--- epoch: 3223, loss: 0.067401, val_loss: 0.053204 ---\n",
      "--- epoch: 3224, loss: 0.067397, val_loss: 0.053199 ---\n",
      "--- epoch: 3225, loss: 0.067392, val_loss: 0.053193 ---\n",
      "--- epoch: 3226, loss: 0.067388, val_loss: 0.053188 ---\n",
      "--- epoch: 3227, loss: 0.067383, val_loss: 0.053182 ---\n",
      "--- epoch: 3228, loss: 0.067379, val_loss: 0.053176 ---\n",
      "--- epoch: 3229, loss: 0.067375, val_loss: 0.053171 ---\n",
      "--- epoch: 3230, loss: 0.067370, val_loss: 0.053165 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 3231, loss: 0.067366, val_loss: 0.053160 ---\n",
      "--- epoch: 3232, loss: 0.067362, val_loss: 0.053154 ---\n",
      "--- epoch: 3233, loss: 0.067357, val_loss: 0.053148 ---\n",
      "--- epoch: 3234, loss: 0.067353, val_loss: 0.053143 ---\n",
      "--- epoch: 3235, loss: 0.067348, val_loss: 0.053137 ---\n",
      "--- epoch: 3236, loss: 0.067344, val_loss: 0.053132 ---\n",
      "--- epoch: 3237, loss: 0.067340, val_loss: 0.053126 ---\n",
      "--- epoch: 3238, loss: 0.067335, val_loss: 0.053120 ---\n",
      "--- epoch: 3239, loss: 0.067331, val_loss: 0.053115 ---\n",
      "--- epoch: 3240, loss: 0.067327, val_loss: 0.053109 ---\n",
      "--- epoch: 3241, loss: 0.067322, val_loss: 0.053104 ---\n",
      "--- epoch: 3242, loss: 0.067318, val_loss: 0.053098 ---\n",
      "--- epoch: 3243, loss: 0.067314, val_loss: 0.053093 ---\n",
      "--- epoch: 3244, loss: 0.067309, val_loss: 0.053087 ---\n",
      "--- epoch: 3245, loss: 0.067305, val_loss: 0.053082 ---\n",
      "--- epoch: 3246, loss: 0.067301, val_loss: 0.053076 ---\n",
      "--- epoch: 3247, loss: 0.067296, val_loss: 0.053070 ---\n",
      "--- epoch: 3248, loss: 0.067292, val_loss: 0.053065 ---\n",
      "--- epoch: 3249, loss: 0.067288, val_loss: 0.053059 ---\n",
      "--- epoch: 3250, loss: 0.067283, val_loss: 0.053054 ---\n",
      "--- epoch: 3251, loss: 0.067279, val_loss: 0.053048 ---\n",
      "--- epoch: 3252, loss: 0.067275, val_loss: 0.053043 ---\n",
      "--- epoch: 3253, loss: 0.067270, val_loss: 0.053037 ---\n",
      "--- epoch: 3254, loss: 0.067266, val_loss: 0.053032 ---\n",
      "--- epoch: 3255, loss: 0.067262, val_loss: 0.053026 ---\n",
      "--- epoch: 3256, loss: 0.067257, val_loss: 0.053021 ---\n",
      "--- epoch: 3257, loss: 0.067253, val_loss: 0.053015 ---\n",
      "--- epoch: 3258, loss: 0.067249, val_loss: 0.053010 ---\n",
      "--- epoch: 3259, loss: 0.067244, val_loss: 0.053004 ---\n",
      "--- epoch: 3260, loss: 0.067240, val_loss: 0.052999 ---\n",
      "--- epoch: 3261, loss: 0.067236, val_loss: 0.052993 ---\n",
      "--- epoch: 3262, loss: 0.067231, val_loss: 0.052988 ---\n",
      "--- epoch: 3263, loss: 0.067227, val_loss: 0.052982 ---\n",
      "--- epoch: 3264, loss: 0.067223, val_loss: 0.052977 ---\n",
      "--- epoch: 3265, loss: 0.067219, val_loss: 0.052971 ---\n",
      "--- epoch: 3266, loss: 0.067214, val_loss: 0.052966 ---\n",
      "--- epoch: 3267, loss: 0.067210, val_loss: 0.052960 ---\n",
      "--- epoch: 3268, loss: 0.067206, val_loss: 0.052955 ---\n",
      "--- epoch: 3269, loss: 0.067201, val_loss: 0.052949 ---\n",
      "--- epoch: 3270, loss: 0.067197, val_loss: 0.052944 ---\n",
      "--- epoch: 3271, loss: 0.067193, val_loss: 0.052938 ---\n",
      "--- epoch: 3272, loss: 0.067188, val_loss: 0.052933 ---\n",
      "--- epoch: 3273, loss: 0.067184, val_loss: 0.052927 ---\n",
      "--- epoch: 3274, loss: 0.067180, val_loss: 0.052922 ---\n",
      "--- epoch: 3275, loss: 0.067176, val_loss: 0.052916 ---\n",
      "--- epoch: 3276, loss: 0.067171, val_loss: 0.052911 ---\n",
      "--- epoch: 3277, loss: 0.067167, val_loss: 0.052905 ---\n",
      "--- epoch: 3278, loss: 0.067163, val_loss: 0.052900 ---\n",
      "--- epoch: 3279, loss: 0.067159, val_loss: 0.052894 ---\n",
      "--- epoch: 3280, loss: 0.067154, val_loss: 0.052889 ---\n",
      "--- epoch: 3281, loss: 0.067150, val_loss: 0.052883 ---\n",
      "--- epoch: 3282, loss: 0.067146, val_loss: 0.052878 ---\n",
      "--- epoch: 3283, loss: 0.067141, val_loss: 0.052872 ---\n",
      "--- epoch: 3284, loss: 0.067137, val_loss: 0.052867 ---\n",
      "--- epoch: 3285, loss: 0.067133, val_loss: 0.052861 ---\n",
      "--- epoch: 3286, loss: 0.067129, val_loss: 0.052856 ---\n",
      "--- epoch: 3287, loss: 0.067124, val_loss: 0.052851 ---\n",
      "--- epoch: 3288, loss: 0.067120, val_loss: 0.052845 ---\n",
      "--- epoch: 3289, loss: 0.067116, val_loss: 0.052840 ---\n",
      "--- epoch: 3290, loss: 0.067112, val_loss: 0.052834 ---\n",
      "--- epoch: 3291, loss: 0.067107, val_loss: 0.052829 ---\n",
      "--- epoch: 3292, loss: 0.067103, val_loss: 0.052823 ---\n",
      "--- epoch: 3293, loss: 0.067099, val_loss: 0.052818 ---\n",
      "--- epoch: 3294, loss: 0.067095, val_loss: 0.052812 ---\n",
      "--- epoch: 3295, loss: 0.067090, val_loss: 0.052807 ---\n",
      "--- epoch: 3296, loss: 0.067086, val_loss: 0.052802 ---\n",
      "--- epoch: 3297, loss: 0.067082, val_loss: 0.052796 ---\n",
      "--- epoch: 3298, loss: 0.067078, val_loss: 0.052791 ---\n",
      "--- epoch: 3299, loss: 0.067074, val_loss: 0.052785 ---\n",
      "--- epoch: 3300, loss: 0.067069, val_loss: 0.052780 ---\n",
      "--- epoch: 3301, loss: 0.067065, val_loss: 0.052774 ---\n",
      "--- epoch: 3302, loss: 0.067061, val_loss: 0.052769 ---\n",
      "--- epoch: 3303, loss: 0.067057, val_loss: 0.052764 ---\n",
      "--- epoch: 3304, loss: 0.067052, val_loss: 0.052758 ---\n",
      "--- epoch: 3305, loss: 0.067048, val_loss: 0.052753 ---\n",
      "--- epoch: 3306, loss: 0.067044, val_loss: 0.052747 ---\n",
      "--- epoch: 3307, loss: 0.067040, val_loss: 0.052742 ---\n",
      "--- epoch: 3308, loss: 0.067036, val_loss: 0.052737 ---\n",
      "--- epoch: 3309, loss: 0.067031, val_loss: 0.052731 ---\n",
      "--- epoch: 3310, loss: 0.067027, val_loss: 0.052726 ---\n",
      "--- epoch: 3311, loss: 0.067023, val_loss: 0.052720 ---\n",
      "--- epoch: 3312, loss: 0.067019, val_loss: 0.052715 ---\n",
      "--- epoch: 3313, loss: 0.067015, val_loss: 0.052710 ---\n",
      "--- epoch: 3314, loss: 0.067010, val_loss: 0.052704 ---\n",
      "--- epoch: 3315, loss: 0.067006, val_loss: 0.052699 ---\n",
      "--- epoch: 3316, loss: 0.067002, val_loss: 0.052694 ---\n",
      "--- epoch: 3317, loss: 0.066998, val_loss: 0.052688 ---\n",
      "--- epoch: 3318, loss: 0.066994, val_loss: 0.052683 ---\n",
      "--- epoch: 3319, loss: 0.066989, val_loss: 0.052677 ---\n",
      "--- epoch: 3320, loss: 0.066985, val_loss: 0.052672 ---\n",
      "--- epoch: 3321, loss: 0.066981, val_loss: 0.052667 ---\n",
      "--- epoch: 3322, loss: 0.066977, val_loss: 0.052661 ---\n",
      "--- epoch: 3323, loss: 0.066973, val_loss: 0.052656 ---\n",
      "--- epoch: 3324, loss: 0.066969, val_loss: 0.052651 ---\n",
      "--- epoch: 3325, loss: 0.066964, val_loss: 0.052645 ---\n",
      "--- epoch: 3326, loss: 0.066960, val_loss: 0.052640 ---\n",
      "--- epoch: 3327, loss: 0.066956, val_loss: 0.052635 ---\n",
      "--- epoch: 3328, loss: 0.066952, val_loss: 0.052629 ---\n",
      "--- epoch: 3329, loss: 0.066948, val_loss: 0.052624 ---\n",
      "--- epoch: 3330, loss: 0.066944, val_loss: 0.052619 ---\n",
      "--- epoch: 3331, loss: 0.066939, val_loss: 0.052613 ---\n",
      "--- epoch: 3332, loss: 0.066935, val_loss: 0.052608 ---\n",
      "--- epoch: 3333, loss: 0.066931, val_loss: 0.052603 ---\n",
      "--- epoch: 3334, loss: 0.066927, val_loss: 0.052597 ---\n",
      "--- epoch: 3335, loss: 0.066923, val_loss: 0.052592 ---\n",
      "--- epoch: 3336, loss: 0.066919, val_loss: 0.052587 ---\n",
      "--- epoch: 3337, loss: 0.066915, val_loss: 0.052581 ---\n",
      "--- epoch: 3338, loss: 0.066910, val_loss: 0.052576 ---\n",
      "--- epoch: 3339, loss: 0.066906, val_loss: 0.052571 ---\n",
      "--- epoch: 3340, loss: 0.066902, val_loss: 0.052566 ---\n",
      "--- epoch: 3341, loss: 0.066898, val_loss: 0.052560 ---\n",
      "--- epoch: 3342, loss: 0.066894, val_loss: 0.052555 ---\n",
      "--- epoch: 3343, loss: 0.066890, val_loss: 0.052550 ---\n",
      "--- epoch: 3344, loss: 0.066886, val_loss: 0.052544 ---\n",
      "--- epoch: 3345, loss: 0.066882, val_loss: 0.052539 ---\n",
      "--- epoch: 3346, loss: 0.066877, val_loss: 0.052534 ---\n",
      "--- epoch: 3347, loss: 0.066873, val_loss: 0.052528 ---\n",
      "--- epoch: 3348, loss: 0.066869, val_loss: 0.052523 ---\n",
      "--- epoch: 3349, loss: 0.066865, val_loss: 0.052518 ---\n",
      "--- epoch: 3350, loss: 0.066861, val_loss: 0.052513 ---\n",
      "--- epoch: 3351, loss: 0.066857, val_loss: 0.052507 ---\n",
      "--- epoch: 3352, loss: 0.066853, val_loss: 0.052502 ---\n",
      "--- epoch: 3353, loss: 0.066849, val_loss: 0.052497 ---\n",
      "--- epoch: 3354, loss: 0.066844, val_loss: 0.052491 ---\n",
      "--- epoch: 3355, loss: 0.066840, val_loss: 0.052486 ---\n",
      "--- epoch: 3356, loss: 0.066836, val_loss: 0.052481 ---\n",
      "--- epoch: 3357, loss: 0.066832, val_loss: 0.052476 ---\n",
      "--- epoch: 3358, loss: 0.066828, val_loss: 0.052470 ---\n",
      "--- epoch: 3359, loss: 0.066824, val_loss: 0.052465 ---\n",
      "--- epoch: 3360, loss: 0.066820, val_loss: 0.052460 ---\n",
      "--- epoch: 3361, loss: 0.066816, val_loss: 0.052455 ---\n",
      "--- epoch: 3362, loss: 0.066812, val_loss: 0.052449 ---\n",
      "--- epoch: 3363, loss: 0.066808, val_loss: 0.052444 ---\n",
      "--- epoch: 3364, loss: 0.066804, val_loss: 0.052439 ---\n",
      "--- epoch: 3365, loss: 0.066799, val_loss: 0.052434 ---\n",
      "--- epoch: 3366, loss: 0.066795, val_loss: 0.052428 ---\n",
      "--- epoch: 3367, loss: 0.066791, val_loss: 0.052423 ---\n",
      "--- epoch: 3368, loss: 0.066787, val_loss: 0.052418 ---\n",
      "--- epoch: 3369, loss: 0.066783, val_loss: 0.052413 ---\n",
      "--- epoch: 3370, loss: 0.066779, val_loss: 0.052407 ---\n",
      "--- epoch: 3371, loss: 0.066775, val_loss: 0.052402 ---\n",
      "--- epoch: 3372, loss: 0.066771, val_loss: 0.052397 ---\n",
      "--- epoch: 3373, loss: 0.066767, val_loss: 0.052392 ---\n",
      "--- epoch: 3374, loss: 0.066763, val_loss: 0.052386 ---\n",
      "--- epoch: 3375, loss: 0.066759, val_loss: 0.052381 ---\n",
      "--- epoch: 3376, loss: 0.066755, val_loss: 0.052376 ---\n",
      "--- epoch: 3377, loss: 0.066751, val_loss: 0.052371 ---\n",
      "--- epoch: 3378, loss: 0.066747, val_loss: 0.052366 ---\n",
      "--- epoch: 3379, loss: 0.066743, val_loss: 0.052360 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 3380, loss: 0.066739, val_loss: 0.052355 ---\n",
      "--- epoch: 3381, loss: 0.066734, val_loss: 0.052350 ---\n",
      "--- epoch: 3382, loss: 0.066730, val_loss: 0.052345 ---\n",
      "--- epoch: 3383, loss: 0.066726, val_loss: 0.052339 ---\n",
      "--- epoch: 3384, loss: 0.066722, val_loss: 0.052334 ---\n",
      "--- epoch: 3385, loss: 0.066718, val_loss: 0.052329 ---\n",
      "--- epoch: 3386, loss: 0.066714, val_loss: 0.052324 ---\n",
      "--- epoch: 3387, loss: 0.066710, val_loss: 0.052319 ---\n",
      "--- epoch: 3388, loss: 0.066706, val_loss: 0.052314 ---\n",
      "--- epoch: 3389, loss: 0.066702, val_loss: 0.052308 ---\n",
      "--- epoch: 3390, loss: 0.066698, val_loss: 0.052303 ---\n",
      "--- epoch: 3391, loss: 0.066694, val_loss: 0.052298 ---\n",
      "--- epoch: 3392, loss: 0.066690, val_loss: 0.052293 ---\n",
      "--- epoch: 3393, loss: 0.066686, val_loss: 0.052288 ---\n",
      "--- epoch: 3394, loss: 0.066682, val_loss: 0.052282 ---\n",
      "--- epoch: 3395, loss: 0.066678, val_loss: 0.052277 ---\n",
      "--- epoch: 3396, loss: 0.066674, val_loss: 0.052272 ---\n",
      "--- epoch: 3397, loss: 0.066670, val_loss: 0.052267 ---\n",
      "--- epoch: 3398, loss: 0.066666, val_loss: 0.052262 ---\n",
      "--- epoch: 3399, loss: 0.066662, val_loss: 0.052257 ---\n",
      "--- epoch: 3400, loss: 0.066658, val_loss: 0.052251 ---\n",
      "--- epoch: 3401, loss: 0.066654, val_loss: 0.052246 ---\n",
      "--- epoch: 3402, loss: 0.066650, val_loss: 0.052241 ---\n",
      "--- epoch: 3403, loss: 0.066646, val_loss: 0.052236 ---\n",
      "--- epoch: 3404, loss: 0.066642, val_loss: 0.052231 ---\n",
      "--- epoch: 3405, loss: 0.066638, val_loss: 0.052226 ---\n",
      "--- epoch: 3406, loss: 0.066634, val_loss: 0.052220 ---\n",
      "--- epoch: 3407, loss: 0.066630, val_loss: 0.052215 ---\n",
      "--- epoch: 3408, loss: 0.066626, val_loss: 0.052210 ---\n",
      "--- epoch: 3409, loss: 0.066622, val_loss: 0.052205 ---\n",
      "--- epoch: 3410, loss: 0.066618, val_loss: 0.052200 ---\n",
      "--- epoch: 3411, loss: 0.066614, val_loss: 0.052195 ---\n",
      "--- epoch: 3412, loss: 0.066610, val_loss: 0.052190 ---\n",
      "--- epoch: 3413, loss: 0.066606, val_loss: 0.052185 ---\n",
      "--- epoch: 3414, loss: 0.066602, val_loss: 0.052179 ---\n",
      "--- epoch: 3415, loss: 0.066598, val_loss: 0.052174 ---\n",
      "--- epoch: 3416, loss: 0.066594, val_loss: 0.052169 ---\n",
      "--- epoch: 3417, loss: 0.066590, val_loss: 0.052164 ---\n",
      "--- epoch: 3418, loss: 0.066586, val_loss: 0.052159 ---\n",
      "--- epoch: 3419, loss: 0.066582, val_loss: 0.052154 ---\n",
      "--- epoch: 3420, loss: 0.066578, val_loss: 0.052149 ---\n",
      "--- epoch: 3421, loss: 0.066574, val_loss: 0.052144 ---\n",
      "--- epoch: 3422, loss: 0.066570, val_loss: 0.052138 ---\n",
      "--- epoch: 3423, loss: 0.066566, val_loss: 0.052133 ---\n",
      "--- epoch: 3424, loss: 0.066562, val_loss: 0.052128 ---\n",
      "--- epoch: 3425, loss: 0.066558, val_loss: 0.052123 ---\n",
      "--- epoch: 3426, loss: 0.066554, val_loss: 0.052118 ---\n",
      "--- epoch: 3427, loss: 0.066550, val_loss: 0.052113 ---\n",
      "--- epoch: 3428, loss: 0.066547, val_loss: 0.052108 ---\n",
      "--- epoch: 3429, loss: 0.066543, val_loss: 0.052103 ---\n",
      "--- epoch: 3430, loss: 0.066539, val_loss: 0.052098 ---\n",
      "--- epoch: 3431, loss: 0.066535, val_loss: 0.052093 ---\n",
      "--- epoch: 3432, loss: 0.066531, val_loss: 0.052087 ---\n",
      "--- epoch: 3433, loss: 0.066527, val_loss: 0.052082 ---\n",
      "--- epoch: 3434, loss: 0.066523, val_loss: 0.052077 ---\n",
      "--- epoch: 3435, loss: 0.066519, val_loss: 0.052072 ---\n",
      "--- epoch: 3436, loss: 0.066515, val_loss: 0.052067 ---\n",
      "--- epoch: 3437, loss: 0.066511, val_loss: 0.052062 ---\n",
      "--- epoch: 3438, loss: 0.066507, val_loss: 0.052057 ---\n",
      "--- epoch: 3439, loss: 0.066503, val_loss: 0.052052 ---\n",
      "--- epoch: 3440, loss: 0.066499, val_loss: 0.052047 ---\n",
      "--- epoch: 3441, loss: 0.066495, val_loss: 0.052042 ---\n",
      "--- epoch: 3442, loss: 0.066491, val_loss: 0.052037 ---\n",
      "--- epoch: 3443, loss: 0.066488, val_loss: 0.052032 ---\n",
      "--- epoch: 3444, loss: 0.066484, val_loss: 0.052027 ---\n",
      "--- epoch: 3445, loss: 0.066480, val_loss: 0.052022 ---\n",
      "--- epoch: 3446, loss: 0.066476, val_loss: 0.052017 ---\n",
      "--- epoch: 3447, loss: 0.066472, val_loss: 0.052011 ---\n",
      "--- epoch: 3448, loss: 0.066468, val_loss: 0.052006 ---\n",
      "--- epoch: 3449, loss: 0.066464, val_loss: 0.052001 ---\n",
      "--- epoch: 3450, loss: 0.066460, val_loss: 0.051996 ---\n",
      "--- epoch: 3451, loss: 0.066456, val_loss: 0.051991 ---\n",
      "--- epoch: 3452, loss: 0.066452, val_loss: 0.051986 ---\n",
      "--- epoch: 3453, loss: 0.066448, val_loss: 0.051981 ---\n",
      "--- epoch: 3454, loss: 0.066445, val_loss: 0.051976 ---\n",
      "--- epoch: 3455, loss: 0.066441, val_loss: 0.051971 ---\n",
      "--- epoch: 3456, loss: 0.066437, val_loss: 0.051966 ---\n",
      "--- epoch: 3457, loss: 0.066433, val_loss: 0.051961 ---\n",
      "--- epoch: 3458, loss: 0.066429, val_loss: 0.051956 ---\n",
      "--- epoch: 3459, loss: 0.066425, val_loss: 0.051951 ---\n",
      "--- epoch: 3460, loss: 0.066421, val_loss: 0.051946 ---\n",
      "--- epoch: 3461, loss: 0.066417, val_loss: 0.051941 ---\n",
      "--- epoch: 3462, loss: 0.066413, val_loss: 0.051936 ---\n",
      "--- epoch: 3463, loss: 0.066409, val_loss: 0.051931 ---\n",
      "--- epoch: 3464, loss: 0.066406, val_loss: 0.051926 ---\n",
      "--- epoch: 3465, loss: 0.066402, val_loss: 0.051921 ---\n",
      "--- epoch: 3466, loss: 0.066398, val_loss: 0.051916 ---\n",
      "--- epoch: 3467, loss: 0.066394, val_loss: 0.051911 ---\n",
      "--- epoch: 3468, loss: 0.066390, val_loss: 0.051906 ---\n",
      "--- epoch: 3469, loss: 0.066386, val_loss: 0.051901 ---\n",
      "--- epoch: 3470, loss: 0.066382, val_loss: 0.051896 ---\n",
      "--- epoch: 3471, loss: 0.066378, val_loss: 0.051891 ---\n",
      "--- epoch: 3472, loss: 0.066375, val_loss: 0.051886 ---\n",
      "--- epoch: 3473, loss: 0.066371, val_loss: 0.051881 ---\n",
      "--- epoch: 3474, loss: 0.066367, val_loss: 0.051876 ---\n",
      "--- epoch: 3475, loss: 0.066363, val_loss: 0.051871 ---\n",
      "--- epoch: 3476, loss: 0.066359, val_loss: 0.051866 ---\n",
      "--- epoch: 3477, loss: 0.066355, val_loss: 0.051861 ---\n",
      "--- epoch: 3478, loss: 0.066351, val_loss: 0.051856 ---\n",
      "--- epoch: 3479, loss: 0.066348, val_loss: 0.051851 ---\n",
      "--- epoch: 3480, loss: 0.066344, val_loss: 0.051846 ---\n",
      "--- epoch: 3481, loss: 0.066340, val_loss: 0.051841 ---\n",
      "--- epoch: 3482, loss: 0.066336, val_loss: 0.051836 ---\n",
      "--- epoch: 3483, loss: 0.066332, val_loss: 0.051831 ---\n",
      "--- epoch: 3484, loss: 0.066328, val_loss: 0.051826 ---\n",
      "--- epoch: 3485, loss: 0.066325, val_loss: 0.051821 ---\n",
      "--- epoch: 3486, loss: 0.066321, val_loss: 0.051816 ---\n",
      "--- epoch: 3487, loss: 0.066317, val_loss: 0.051811 ---\n",
      "--- epoch: 3488, loss: 0.066313, val_loss: 0.051806 ---\n",
      "--- epoch: 3489, loss: 0.066309, val_loss: 0.051801 ---\n",
      "--- epoch: 3490, loss: 0.066305, val_loss: 0.051796 ---\n",
      "--- epoch: 3491, loss: 0.066301, val_loss: 0.051791 ---\n",
      "--- epoch: 3492, loss: 0.066298, val_loss: 0.051786 ---\n",
      "--- epoch: 3493, loss: 0.066294, val_loss: 0.051781 ---\n",
      "--- epoch: 3494, loss: 0.066290, val_loss: 0.051776 ---\n",
      "--- epoch: 3495, loss: 0.066286, val_loss: 0.051772 ---\n",
      "--- epoch: 3496, loss: 0.066282, val_loss: 0.051767 ---\n",
      "--- epoch: 3497, loss: 0.066279, val_loss: 0.051762 ---\n",
      "--- epoch: 3498, loss: 0.066275, val_loss: 0.051757 ---\n",
      "--- epoch: 3499, loss: 0.066271, val_loss: 0.051752 ---\n",
      "--- epoch: 3500, loss: 0.066267, val_loss: 0.051747 ---\n",
      "--- epoch: 3501, loss: 0.066263, val_loss: 0.051742 ---\n",
      "--- epoch: 3502, loss: 0.066259, val_loss: 0.051737 ---\n",
      "--- epoch: 3503, loss: 0.066256, val_loss: 0.051732 ---\n",
      "--- epoch: 3504, loss: 0.066252, val_loss: 0.051727 ---\n",
      "--- epoch: 3505, loss: 0.066248, val_loss: 0.051722 ---\n",
      "--- epoch: 3506, loss: 0.066244, val_loss: 0.051717 ---\n",
      "--- epoch: 3507, loss: 0.066241, val_loss: 0.051712 ---\n",
      "--- epoch: 3508, loss: 0.066237, val_loss: 0.051708 ---\n",
      "--- epoch: 3509, loss: 0.066233, val_loss: 0.051703 ---\n",
      "--- epoch: 3510, loss: 0.066229, val_loss: 0.051698 ---\n",
      "--- epoch: 3511, loss: 0.066225, val_loss: 0.051693 ---\n",
      "--- epoch: 3512, loss: 0.066222, val_loss: 0.051688 ---\n",
      "--- epoch: 3513, loss: 0.066218, val_loss: 0.051683 ---\n",
      "--- epoch: 3514, loss: 0.066214, val_loss: 0.051678 ---\n",
      "--- epoch: 3515, loss: 0.066210, val_loss: 0.051673 ---\n",
      "--- epoch: 3516, loss: 0.066206, val_loss: 0.051668 ---\n",
      "--- epoch: 3517, loss: 0.066203, val_loss: 0.051663 ---\n",
      "--- epoch: 3518, loss: 0.066199, val_loss: 0.051659 ---\n",
      "--- epoch: 3519, loss: 0.066195, val_loss: 0.051654 ---\n",
      "--- epoch: 3520, loss: 0.066191, val_loss: 0.051649 ---\n",
      "--- epoch: 3521, loss: 0.066188, val_loss: 0.051644 ---\n",
      "--- epoch: 3522, loss: 0.066184, val_loss: 0.051639 ---\n",
      "--- epoch: 3523, loss: 0.066180, val_loss: 0.051634 ---\n",
      "--- epoch: 3524, loss: 0.066176, val_loss: 0.051629 ---\n",
      "--- epoch: 3525, loss: 0.066173, val_loss: 0.051624 ---\n",
      "--- epoch: 3526, loss: 0.066169, val_loss: 0.051620 ---\n",
      "--- epoch: 3527, loss: 0.066165, val_loss: 0.051615 ---\n",
      "--- epoch: 3528, loss: 0.066161, val_loss: 0.051610 ---\n",
      "--- epoch: 3529, loss: 0.066158, val_loss: 0.051605 ---\n",
      "--- epoch: 3530, loss: 0.066154, val_loss: 0.051600 ---\n",
      "--- epoch: 3531, loss: 0.066150, val_loss: 0.051595 ---\n",
      "--- epoch: 3532, loss: 0.066146, val_loss: 0.051590 ---\n",
      "--- epoch: 3533, loss: 0.066143, val_loss: 0.051585 ---\n",
      "--- epoch: 3534, loss: 0.066139, val_loss: 0.051581 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 3535, loss: 0.066135, val_loss: 0.051576 ---\n",
      "--- epoch: 3536, loss: 0.066131, val_loss: 0.051571 ---\n",
      "--- epoch: 3537, loss: 0.066128, val_loss: 0.051566 ---\n",
      "--- epoch: 3538, loss: 0.066124, val_loss: 0.051561 ---\n",
      "--- epoch: 3539, loss: 0.066120, val_loss: 0.051556 ---\n",
      "--- epoch: 3540, loss: 0.066116, val_loss: 0.051552 ---\n",
      "--- epoch: 3541, loss: 0.066113, val_loss: 0.051547 ---\n",
      "--- epoch: 3542, loss: 0.066109, val_loss: 0.051542 ---\n",
      "--- epoch: 3543, loss: 0.066105, val_loss: 0.051537 ---\n",
      "--- epoch: 3544, loss: 0.066101, val_loss: 0.051532 ---\n",
      "--- epoch: 3545, loss: 0.066098, val_loss: 0.051527 ---\n",
      "--- epoch: 3546, loss: 0.066094, val_loss: 0.051523 ---\n",
      "--- epoch: 3547, loss: 0.066090, val_loss: 0.051518 ---\n",
      "--- epoch: 3548, loss: 0.066087, val_loss: 0.051513 ---\n",
      "--- epoch: 3549, loss: 0.066083, val_loss: 0.051508 ---\n",
      "--- epoch: 3550, loss: 0.066079, val_loss: 0.051503 ---\n",
      "--- epoch: 3551, loss: 0.066075, val_loss: 0.051498 ---\n",
      "--- epoch: 3552, loss: 0.066072, val_loss: 0.051494 ---\n",
      "--- epoch: 3553, loss: 0.066068, val_loss: 0.051489 ---\n",
      "--- epoch: 3554, loss: 0.066064, val_loss: 0.051484 ---\n",
      "--- epoch: 3555, loss: 0.066061, val_loss: 0.051479 ---\n",
      "--- epoch: 3556, loss: 0.066057, val_loss: 0.051474 ---\n",
      "--- epoch: 3557, loss: 0.066053, val_loss: 0.051470 ---\n",
      "--- epoch: 3558, loss: 0.066049, val_loss: 0.051465 ---\n",
      "--- epoch: 3559, loss: 0.066046, val_loss: 0.051460 ---\n",
      "--- epoch: 3560, loss: 0.066042, val_loss: 0.051455 ---\n",
      "--- epoch: 3561, loss: 0.066038, val_loss: 0.051450 ---\n",
      "--- epoch: 3562, loss: 0.066035, val_loss: 0.051446 ---\n",
      "--- epoch: 3563, loss: 0.066031, val_loss: 0.051441 ---\n",
      "--- epoch: 3564, loss: 0.066027, val_loss: 0.051436 ---\n",
      "--- epoch: 3565, loss: 0.066024, val_loss: 0.051431 ---\n",
      "--- epoch: 3566, loss: 0.066020, val_loss: 0.051426 ---\n",
      "--- epoch: 3567, loss: 0.066016, val_loss: 0.051422 ---\n",
      "--- epoch: 3568, loss: 0.066013, val_loss: 0.051417 ---\n",
      "--- epoch: 3569, loss: 0.066009, val_loss: 0.051412 ---\n",
      "--- epoch: 3570, loss: 0.066005, val_loss: 0.051407 ---\n",
      "--- epoch: 3571, loss: 0.066001, val_loss: 0.051402 ---\n",
      "--- epoch: 3572, loss: 0.065998, val_loss: 0.051398 ---\n",
      "--- epoch: 3573, loss: 0.065994, val_loss: 0.051393 ---\n",
      "--- epoch: 3574, loss: 0.065990, val_loss: 0.051388 ---\n",
      "--- epoch: 3575, loss: 0.065987, val_loss: 0.051383 ---\n",
      "--- epoch: 3576, loss: 0.065983, val_loss: 0.051379 ---\n",
      "--- epoch: 3577, loss: 0.065979, val_loss: 0.051374 ---\n",
      "--- epoch: 3578, loss: 0.065976, val_loss: 0.051369 ---\n",
      "--- epoch: 3579, loss: 0.065972, val_loss: 0.051364 ---\n",
      "--- epoch: 3580, loss: 0.065968, val_loss: 0.051360 ---\n",
      "--- epoch: 3581, loss: 0.065965, val_loss: 0.051355 ---\n",
      "--- epoch: 3582, loss: 0.065961, val_loss: 0.051350 ---\n",
      "--- epoch: 3583, loss: 0.065957, val_loss: 0.051345 ---\n",
      "--- epoch: 3584, loss: 0.065954, val_loss: 0.051341 ---\n",
      "--- epoch: 3585, loss: 0.065950, val_loss: 0.051336 ---\n",
      "--- epoch: 3586, loss: 0.065946, val_loss: 0.051331 ---\n",
      "--- epoch: 3587, loss: 0.065943, val_loss: 0.051326 ---\n",
      "--- epoch: 3588, loss: 0.065939, val_loss: 0.051322 ---\n",
      "--- epoch: 3589, loss: 0.065936, val_loss: 0.051317 ---\n",
      "--- epoch: 3590, loss: 0.065932, val_loss: 0.051312 ---\n",
      "--- epoch: 3591, loss: 0.065928, val_loss: 0.051307 ---\n",
      "--- epoch: 3592, loss: 0.065925, val_loss: 0.051303 ---\n",
      "--- epoch: 3593, loss: 0.065921, val_loss: 0.051298 ---\n",
      "--- epoch: 3594, loss: 0.065917, val_loss: 0.051293 ---\n",
      "--- epoch: 3595, loss: 0.065914, val_loss: 0.051289 ---\n",
      "--- epoch: 3596, loss: 0.065910, val_loss: 0.051284 ---\n",
      "--- epoch: 3597, loss: 0.065906, val_loss: 0.051279 ---\n",
      "--- epoch: 3598, loss: 0.065903, val_loss: 0.051274 ---\n",
      "--- epoch: 3599, loss: 0.065899, val_loss: 0.051270 ---\n",
      "--- epoch: 3600, loss: 0.065896, val_loss: 0.051265 ---\n",
      "--- epoch: 3601, loss: 0.065892, val_loss: 0.051260 ---\n",
      "--- epoch: 3602, loss: 0.065888, val_loss: 0.051255 ---\n",
      "--- epoch: 3603, loss: 0.065885, val_loss: 0.051251 ---\n",
      "--- epoch: 3604, loss: 0.065881, val_loss: 0.051246 ---\n",
      "--- epoch: 3605, loss: 0.065877, val_loss: 0.051241 ---\n",
      "--- epoch: 3606, loss: 0.065874, val_loss: 0.051237 ---\n",
      "--- epoch: 3607, loss: 0.065870, val_loss: 0.051232 ---\n",
      "--- epoch: 3608, loss: 0.065867, val_loss: 0.051227 ---\n",
      "--- epoch: 3609, loss: 0.065863, val_loss: 0.051223 ---\n",
      "--- epoch: 3610, loss: 0.065859, val_loss: 0.051218 ---\n",
      "--- epoch: 3611, loss: 0.065856, val_loss: 0.051213 ---\n",
      "--- epoch: 3612, loss: 0.065852, val_loss: 0.051208 ---\n",
      "--- epoch: 3613, loss: 0.065849, val_loss: 0.051204 ---\n",
      "--- epoch: 3614, loss: 0.065845, val_loss: 0.051199 ---\n",
      "--- epoch: 3615, loss: 0.065841, val_loss: 0.051194 ---\n",
      "--- epoch: 3616, loss: 0.065838, val_loss: 0.051190 ---\n",
      "--- epoch: 3617, loss: 0.065834, val_loss: 0.051185 ---\n",
      "--- epoch: 3618, loss: 0.065831, val_loss: 0.051180 ---\n",
      "--- epoch: 3619, loss: 0.065827, val_loss: 0.051176 ---\n",
      "--- epoch: 3620, loss: 0.065823, val_loss: 0.051171 ---\n",
      "--- epoch: 3621, loss: 0.065820, val_loss: 0.051166 ---\n",
      "--- epoch: 3622, loss: 0.065816, val_loss: 0.051162 ---\n",
      "--- epoch: 3623, loss: 0.065813, val_loss: 0.051157 ---\n",
      "--- epoch: 3624, loss: 0.065809, val_loss: 0.051152 ---\n",
      "--- epoch: 3625, loss: 0.065805, val_loss: 0.051148 ---\n",
      "--- epoch: 3626, loss: 0.065802, val_loss: 0.051143 ---\n",
      "--- epoch: 3627, loss: 0.065798, val_loss: 0.051138 ---\n",
      "--- epoch: 3628, loss: 0.065795, val_loss: 0.051134 ---\n",
      "--- epoch: 3629, loss: 0.065791, val_loss: 0.051129 ---\n",
      "--- epoch: 3630, loss: 0.065788, val_loss: 0.051124 ---\n",
      "--- epoch: 3631, loss: 0.065784, val_loss: 0.051120 ---\n",
      "--- epoch: 3632, loss: 0.065780, val_loss: 0.051115 ---\n",
      "--- epoch: 3633, loss: 0.065777, val_loss: 0.051110 ---\n",
      "--- epoch: 3634, loss: 0.065773, val_loss: 0.051106 ---\n",
      "--- epoch: 3635, loss: 0.065770, val_loss: 0.051101 ---\n",
      "--- epoch: 3636, loss: 0.065766, val_loss: 0.051096 ---\n",
      "--- epoch: 3637, loss: 0.065763, val_loss: 0.051092 ---\n",
      "--- epoch: 3638, loss: 0.065759, val_loss: 0.051087 ---\n",
      "--- epoch: 3639, loss: 0.065755, val_loss: 0.051083 ---\n",
      "--- epoch: 3640, loss: 0.065752, val_loss: 0.051078 ---\n",
      "--- epoch: 3641, loss: 0.065748, val_loss: 0.051073 ---\n",
      "--- epoch: 3642, loss: 0.065745, val_loss: 0.051069 ---\n",
      "--- epoch: 3643, loss: 0.065741, val_loss: 0.051064 ---\n",
      "--- epoch: 3644, loss: 0.065738, val_loss: 0.051059 ---\n",
      "--- epoch: 3645, loss: 0.065734, val_loss: 0.051055 ---\n",
      "--- epoch: 3646, loss: 0.065731, val_loss: 0.051050 ---\n",
      "--- epoch: 3647, loss: 0.065727, val_loss: 0.051046 ---\n",
      "--- epoch: 3648, loss: 0.065723, val_loss: 0.051041 ---\n",
      "--- epoch: 3649, loss: 0.065720, val_loss: 0.051036 ---\n",
      "--- epoch: 3650, loss: 0.065716, val_loss: 0.051032 ---\n",
      "--- epoch: 3651, loss: 0.065713, val_loss: 0.051027 ---\n",
      "--- epoch: 3652, loss: 0.065709, val_loss: 0.051022 ---\n",
      "--- epoch: 3653, loss: 0.065706, val_loss: 0.051018 ---\n",
      "--- epoch: 3654, loss: 0.065702, val_loss: 0.051013 ---\n",
      "--- epoch: 3655, loss: 0.065699, val_loss: 0.051009 ---\n",
      "--- epoch: 3656, loss: 0.065695, val_loss: 0.051004 ---\n",
      "--- epoch: 3657, loss: 0.065692, val_loss: 0.050999 ---\n",
      "--- epoch: 3658, loss: 0.065688, val_loss: 0.050995 ---\n",
      "--- epoch: 3659, loss: 0.065685, val_loss: 0.050990 ---\n",
      "--- epoch: 3660, loss: 0.065681, val_loss: 0.050986 ---\n",
      "--- epoch: 3661, loss: 0.065677, val_loss: 0.050981 ---\n",
      "--- epoch: 3662, loss: 0.065674, val_loss: 0.050976 ---\n",
      "--- epoch: 3663, loss: 0.065670, val_loss: 0.050972 ---\n",
      "--- epoch: 3664, loss: 0.065667, val_loss: 0.050967 ---\n",
      "--- epoch: 3665, loss: 0.065663, val_loss: 0.050963 ---\n",
      "--- epoch: 3666, loss: 0.065660, val_loss: 0.050958 ---\n",
      "--- epoch: 3667, loss: 0.065656, val_loss: 0.050954 ---\n",
      "--- epoch: 3668, loss: 0.065653, val_loss: 0.050949 ---\n",
      "--- epoch: 3669, loss: 0.065649, val_loss: 0.050944 ---\n",
      "--- epoch: 3670, loss: 0.065646, val_loss: 0.050940 ---\n",
      "--- epoch: 3671, loss: 0.065642, val_loss: 0.050935 ---\n",
      "--- epoch: 3672, loss: 0.065639, val_loss: 0.050931 ---\n",
      "--- epoch: 3673, loss: 0.065635, val_loss: 0.050926 ---\n",
      "--- epoch: 3674, loss: 0.065632, val_loss: 0.050922 ---\n",
      "--- epoch: 3675, loss: 0.065628, val_loss: 0.050917 ---\n",
      "--- epoch: 3676, loss: 0.065625, val_loss: 0.050912 ---\n",
      "--- epoch: 3677, loss: 0.065621, val_loss: 0.050908 ---\n",
      "--- epoch: 3678, loss: 0.065618, val_loss: 0.050903 ---\n",
      "--- epoch: 3679, loss: 0.065614, val_loss: 0.050899 ---\n",
      "--- epoch: 3680, loss: 0.065611, val_loss: 0.050894 ---\n",
      "--- epoch: 3681, loss: 0.065607, val_loss: 0.050890 ---\n",
      "--- epoch: 3682, loss: 0.065604, val_loss: 0.050885 ---\n",
      "--- epoch: 3683, loss: 0.065600, val_loss: 0.050881 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 3684, loss: 0.065597, val_loss: 0.050876 ---\n",
      "--- epoch: 3685, loss: 0.065593, val_loss: 0.050871 ---\n",
      "--- epoch: 3686, loss: 0.065590, val_loss: 0.050867 ---\n",
      "--- epoch: 3687, loss: 0.065587, val_loss: 0.050862 ---\n",
      "--- epoch: 3688, loss: 0.065583, val_loss: 0.050858 ---\n",
      "--- epoch: 3689, loss: 0.065580, val_loss: 0.050853 ---\n",
      "--- epoch: 3690, loss: 0.065576, val_loss: 0.050849 ---\n",
      "--- epoch: 3691, loss: 0.065573, val_loss: 0.050844 ---\n",
      "--- epoch: 3692, loss: 0.065569, val_loss: 0.050840 ---\n",
      "--- epoch: 3693, loss: 0.065566, val_loss: 0.050835 ---\n",
      "--- epoch: 3694, loss: 0.065562, val_loss: 0.050831 ---\n",
      "--- epoch: 3695, loss: 0.065559, val_loss: 0.050826 ---\n",
      "--- epoch: 3696, loss: 0.065555, val_loss: 0.050822 ---\n",
      "--- epoch: 3697, loss: 0.065552, val_loss: 0.050817 ---\n",
      "--- epoch: 3698, loss: 0.065548, val_loss: 0.050813 ---\n",
      "--- epoch: 3699, loss: 0.065545, val_loss: 0.050808 ---\n",
      "--- epoch: 3700, loss: 0.065541, val_loss: 0.050804 ---\n",
      "--- epoch: 3701, loss: 0.065538, val_loss: 0.050799 ---\n",
      "--- epoch: 3702, loss: 0.065535, val_loss: 0.050795 ---\n",
      "--- epoch: 3703, loss: 0.065531, val_loss: 0.050790 ---\n",
      "--- epoch: 3704, loss: 0.065528, val_loss: 0.050786 ---\n",
      "--- epoch: 3705, loss: 0.065524, val_loss: 0.050781 ---\n",
      "--- epoch: 3706, loss: 0.065521, val_loss: 0.050777 ---\n",
      "--- epoch: 3707, loss: 0.065517, val_loss: 0.050772 ---\n",
      "--- epoch: 3708, loss: 0.065514, val_loss: 0.050768 ---\n",
      "--- epoch: 3709, loss: 0.065510, val_loss: 0.050763 ---\n",
      "--- epoch: 3710, loss: 0.065507, val_loss: 0.050759 ---\n",
      "--- epoch: 3711, loss: 0.065504, val_loss: 0.050754 ---\n",
      "--- epoch: 3712, loss: 0.065500, val_loss: 0.050750 ---\n",
      "--- epoch: 3713, loss: 0.065497, val_loss: 0.050745 ---\n",
      "--- epoch: 3714, loss: 0.065493, val_loss: 0.050741 ---\n",
      "--- epoch: 3715, loss: 0.065490, val_loss: 0.050736 ---\n",
      "--- epoch: 3716, loss: 0.065486, val_loss: 0.050732 ---\n",
      "--- epoch: 3717, loss: 0.065483, val_loss: 0.050727 ---\n",
      "--- epoch: 3718, loss: 0.065480, val_loss: 0.050723 ---\n",
      "--- epoch: 3719, loss: 0.065476, val_loss: 0.050718 ---\n",
      "--- epoch: 3720, loss: 0.065473, val_loss: 0.050714 ---\n",
      "--- epoch: 3721, loss: 0.065469, val_loss: 0.050709 ---\n",
      "--- epoch: 3722, loss: 0.065466, val_loss: 0.050705 ---\n",
      "--- epoch: 3723, loss: 0.065462, val_loss: 0.050700 ---\n",
      "--- epoch: 3724, loss: 0.065459, val_loss: 0.050696 ---\n",
      "--- epoch: 3725, loss: 0.065456, val_loss: 0.050691 ---\n",
      "--- epoch: 3726, loss: 0.065452, val_loss: 0.050687 ---\n",
      "--- epoch: 3727, loss: 0.065449, val_loss: 0.050682 ---\n",
      "--- epoch: 3728, loss: 0.065445, val_loss: 0.050678 ---\n",
      "--- epoch: 3729, loss: 0.065442, val_loss: 0.050674 ---\n",
      "--- epoch: 3730, loss: 0.065439, val_loss: 0.050669 ---\n",
      "--- epoch: 3731, loss: 0.065435, val_loss: 0.050665 ---\n",
      "--- epoch: 3732, loss: 0.065432, val_loss: 0.050660 ---\n",
      "--- epoch: 3733, loss: 0.065428, val_loss: 0.050656 ---\n",
      "--- epoch: 3734, loss: 0.065425, val_loss: 0.050651 ---\n",
      "--- epoch: 3735, loss: 0.065422, val_loss: 0.050647 ---\n",
      "--- epoch: 3736, loss: 0.065418, val_loss: 0.050642 ---\n",
      "--- epoch: 3737, loss: 0.065415, val_loss: 0.050638 ---\n",
      "--- epoch: 3738, loss: 0.065411, val_loss: 0.050633 ---\n",
      "--- epoch: 3739, loss: 0.065408, val_loss: 0.050629 ---\n",
      "--- epoch: 3740, loss: 0.065405, val_loss: 0.050625 ---\n",
      "--- epoch: 3741, loss: 0.065401, val_loss: 0.050620 ---\n",
      "--- epoch: 3742, loss: 0.065398, val_loss: 0.050616 ---\n",
      "--- epoch: 3743, loss: 0.065394, val_loss: 0.050611 ---\n",
      "--- epoch: 3744, loss: 0.065391, val_loss: 0.050607 ---\n",
      "--- epoch: 3745, loss: 0.065388, val_loss: 0.050602 ---\n",
      "--- epoch: 3746, loss: 0.065384, val_loss: 0.050598 ---\n",
      "--- epoch: 3747, loss: 0.065381, val_loss: 0.050594 ---\n",
      "--- epoch: 3748, loss: 0.065377, val_loss: 0.050589 ---\n",
      "--- epoch: 3749, loss: 0.065374, val_loss: 0.050585 ---\n",
      "--- epoch: 3750, loss: 0.065371, val_loss: 0.050580 ---\n",
      "--- epoch: 3751, loss: 0.065367, val_loss: 0.050576 ---\n",
      "--- epoch: 3752, loss: 0.065364, val_loss: 0.050572 ---\n",
      "--- epoch: 3753, loss: 0.065361, val_loss: 0.050567 ---\n",
      "--- epoch: 3754, loss: 0.065357, val_loss: 0.050563 ---\n",
      "--- epoch: 3755, loss: 0.065354, val_loss: 0.050558 ---\n",
      "--- epoch: 3756, loss: 0.065350, val_loss: 0.050554 ---\n",
      "--- epoch: 3757, loss: 0.065347, val_loss: 0.050549 ---\n",
      "--- epoch: 3758, loss: 0.065344, val_loss: 0.050545 ---\n",
      "--- epoch: 3759, loss: 0.065340, val_loss: 0.050541 ---\n",
      "--- epoch: 3760, loss: 0.065337, val_loss: 0.050536 ---\n",
      "--- epoch: 3761, loss: 0.065334, val_loss: 0.050532 ---\n",
      "--- epoch: 3762, loss: 0.065330, val_loss: 0.050527 ---\n",
      "--- epoch: 3763, loss: 0.065327, val_loss: 0.050523 ---\n",
      "--- epoch: 3764, loss: 0.065324, val_loss: 0.050519 ---\n",
      "--- epoch: 3765, loss: 0.065320, val_loss: 0.050514 ---\n",
      "--- epoch: 3766, loss: 0.065317, val_loss: 0.050510 ---\n",
      "--- epoch: 3767, loss: 0.065314, val_loss: 0.050505 ---\n",
      "--- epoch: 3768, loss: 0.065310, val_loss: 0.050501 ---\n",
      "--- epoch: 3769, loss: 0.065307, val_loss: 0.050497 ---\n",
      "--- epoch: 3770, loss: 0.065303, val_loss: 0.050492 ---\n",
      "--- epoch: 3771, loss: 0.065300, val_loss: 0.050488 ---\n",
      "--- epoch: 3772, loss: 0.065297, val_loss: 0.050484 ---\n",
      "--- epoch: 3773, loss: 0.065293, val_loss: 0.050479 ---\n",
      "--- epoch: 3774, loss: 0.065290, val_loss: 0.050475 ---\n",
      "--- epoch: 3775, loss: 0.065287, val_loss: 0.050470 ---\n",
      "--- epoch: 3776, loss: 0.065283, val_loss: 0.050466 ---\n",
      "--- epoch: 3777, loss: 0.065280, val_loss: 0.050462 ---\n",
      "--- epoch: 3778, loss: 0.065277, val_loss: 0.050457 ---\n",
      "--- epoch: 3779, loss: 0.065273, val_loss: 0.050453 ---\n",
      "--- epoch: 3780, loss: 0.065270, val_loss: 0.050449 ---\n",
      "--- epoch: 3781, loss: 0.065267, val_loss: 0.050444 ---\n",
      "--- epoch: 3782, loss: 0.065263, val_loss: 0.050440 ---\n",
      "--- epoch: 3783, loss: 0.065260, val_loss: 0.050435 ---\n",
      "--- epoch: 3784, loss: 0.065257, val_loss: 0.050431 ---\n",
      "--- epoch: 3785, loss: 0.065253, val_loss: 0.050427 ---\n",
      "--- epoch: 3786, loss: 0.065250, val_loss: 0.050422 ---\n",
      "--- epoch: 3787, loss: 0.065247, val_loss: 0.050418 ---\n",
      "--- epoch: 3788, loss: 0.065243, val_loss: 0.050414 ---\n",
      "--- epoch: 3789, loss: 0.065240, val_loss: 0.050409 ---\n",
      "--- epoch: 3790, loss: 0.065237, val_loss: 0.050405 ---\n",
      "--- epoch: 3791, loss: 0.065234, val_loss: 0.050401 ---\n",
      "--- epoch: 3792, loss: 0.065230, val_loss: 0.050396 ---\n",
      "--- epoch: 3793, loss: 0.065227, val_loss: 0.050392 ---\n",
      "--- epoch: 3794, loss: 0.065224, val_loss: 0.050388 ---\n",
      "--- epoch: 3795, loss: 0.065220, val_loss: 0.050383 ---\n",
      "--- epoch: 3796, loss: 0.065217, val_loss: 0.050379 ---\n",
      "--- epoch: 3797, loss: 0.065214, val_loss: 0.050375 ---\n",
      "--- epoch: 3798, loss: 0.065210, val_loss: 0.050370 ---\n",
      "--- epoch: 3799, loss: 0.065207, val_loss: 0.050366 ---\n",
      "--- epoch: 3800, loss: 0.065204, val_loss: 0.050362 ---\n",
      "--- epoch: 3801, loss: 0.065200, val_loss: 0.050357 ---\n",
      "--- epoch: 3802, loss: 0.065197, val_loss: 0.050353 ---\n",
      "--- epoch: 3803, loss: 0.065194, val_loss: 0.050349 ---\n",
      "--- epoch: 3804, loss: 0.065191, val_loss: 0.050344 ---\n",
      "--- epoch: 3805, loss: 0.065187, val_loss: 0.050340 ---\n",
      "--- epoch: 3806, loss: 0.065184, val_loss: 0.050336 ---\n",
      "--- epoch: 3807, loss: 0.065181, val_loss: 0.050331 ---\n",
      "--- epoch: 3808, loss: 0.065177, val_loss: 0.050327 ---\n",
      "--- epoch: 3809, loss: 0.065174, val_loss: 0.050323 ---\n",
      "--- epoch: 3810, loss: 0.065171, val_loss: 0.050318 ---\n",
      "--- epoch: 3811, loss: 0.065168, val_loss: 0.050314 ---\n",
      "--- epoch: 3812, loss: 0.065164, val_loss: 0.050310 ---\n",
      "--- epoch: 3813, loss: 0.065161, val_loss: 0.050305 ---\n",
      "--- epoch: 3814, loss: 0.065158, val_loss: 0.050301 ---\n",
      "--- epoch: 3815, loss: 0.065154, val_loss: 0.050297 ---\n",
      "--- epoch: 3816, loss: 0.065151, val_loss: 0.050293 ---\n",
      "--- epoch: 3817, loss: 0.065148, val_loss: 0.050288 ---\n",
      "--- epoch: 3818, loss: 0.065145, val_loss: 0.050284 ---\n",
      "--- epoch: 3819, loss: 0.065141, val_loss: 0.050280 ---\n",
      "--- epoch: 3820, loss: 0.065138, val_loss: 0.050275 ---\n",
      "--- epoch: 3821, loss: 0.065135, val_loss: 0.050271 ---\n",
      "--- epoch: 3822, loss: 0.065132, val_loss: 0.050267 ---\n",
      "--- epoch: 3823, loss: 0.065128, val_loss: 0.050263 ---\n",
      "--- epoch: 3824, loss: 0.065125, val_loss: 0.050258 ---\n",
      "--- epoch: 3825, loss: 0.065122, val_loss: 0.050254 ---\n",
      "--- epoch: 3826, loss: 0.065119, val_loss: 0.050250 ---\n",
      "--- epoch: 3827, loss: 0.065115, val_loss: 0.050245 ---\n",
      "--- epoch: 3828, loss: 0.065112, val_loss: 0.050241 ---\n",
      "--- epoch: 3829, loss: 0.065109, val_loss: 0.050237 ---\n",
      "--- epoch: 3830, loss: 0.065105, val_loss: 0.050233 ---\n",
      "--- epoch: 3831, loss: 0.065102, val_loss: 0.050228 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 3832, loss: 0.065099, val_loss: 0.050224 ---\n",
      "--- epoch: 3833, loss: 0.065096, val_loss: 0.050220 ---\n",
      "--- epoch: 3834, loss: 0.065092, val_loss: 0.050216 ---\n",
      "--- epoch: 3835, loss: 0.065089, val_loss: 0.050211 ---\n",
      "--- epoch: 3836, loss: 0.065086, val_loss: 0.050207 ---\n",
      "--- epoch: 3837, loss: 0.065083, val_loss: 0.050203 ---\n",
      "--- epoch: 3838, loss: 0.065080, val_loss: 0.050198 ---\n",
      "--- epoch: 3839, loss: 0.065076, val_loss: 0.050194 ---\n",
      "--- epoch: 3840, loss: 0.065073, val_loss: 0.050190 ---\n",
      "--- epoch: 3841, loss: 0.065070, val_loss: 0.050186 ---\n",
      "--- epoch: 3842, loss: 0.065067, val_loss: 0.050181 ---\n",
      "--- epoch: 3843, loss: 0.065063, val_loss: 0.050177 ---\n",
      "--- epoch: 3844, loss: 0.065060, val_loss: 0.050173 ---\n",
      "--- epoch: 3845, loss: 0.065057, val_loss: 0.050169 ---\n",
      "--- epoch: 3846, loss: 0.065054, val_loss: 0.050165 ---\n",
      "--- epoch: 3847, loss: 0.065050, val_loss: 0.050160 ---\n",
      "--- epoch: 3848, loss: 0.065047, val_loss: 0.050156 ---\n",
      "--- epoch: 3849, loss: 0.065044, val_loss: 0.050152 ---\n",
      "--- epoch: 3850, loss: 0.065041, val_loss: 0.050148 ---\n",
      "--- epoch: 3851, loss: 0.065038, val_loss: 0.050143 ---\n",
      "--- epoch: 3852, loss: 0.065034, val_loss: 0.050139 ---\n",
      "--- epoch: 3853, loss: 0.065031, val_loss: 0.050135 ---\n",
      "--- epoch: 3854, loss: 0.065028, val_loss: 0.050131 ---\n",
      "--- epoch: 3855, loss: 0.065025, val_loss: 0.050126 ---\n",
      "--- epoch: 3856, loss: 0.065021, val_loss: 0.050122 ---\n",
      "--- epoch: 3857, loss: 0.065018, val_loss: 0.050118 ---\n",
      "--- epoch: 3858, loss: 0.065015, val_loss: 0.050114 ---\n",
      "--- epoch: 3859, loss: 0.065012, val_loss: 0.050109 ---\n",
      "--- epoch: 3860, loss: 0.065009, val_loss: 0.050105 ---\n",
      "--- epoch: 3861, loss: 0.065005, val_loss: 0.050101 ---\n",
      "--- epoch: 3862, loss: 0.065002, val_loss: 0.050097 ---\n",
      "--- epoch: 3863, loss: 0.064999, val_loss: 0.050093 ---\n",
      "--- epoch: 3864, loss: 0.064996, val_loss: 0.050088 ---\n",
      "--- epoch: 3865, loss: 0.064993, val_loss: 0.050084 ---\n",
      "--- epoch: 3866, loss: 0.064989, val_loss: 0.050080 ---\n",
      "--- epoch: 3867, loss: 0.064986, val_loss: 0.050076 ---\n",
      "--- epoch: 3868, loss: 0.064983, val_loss: 0.050072 ---\n",
      "--- epoch: 3869, loss: 0.064980, val_loss: 0.050067 ---\n",
      "--- epoch: 3870, loss: 0.064977, val_loss: 0.050063 ---\n",
      "--- epoch: 3871, loss: 0.064973, val_loss: 0.050059 ---\n",
      "--- epoch: 3872, loss: 0.064970, val_loss: 0.050055 ---\n",
      "--- epoch: 3873, loss: 0.064967, val_loss: 0.050051 ---\n",
      "--- epoch: 3874, loss: 0.064964, val_loss: 0.050046 ---\n",
      "--- epoch: 3875, loss: 0.064961, val_loss: 0.050042 ---\n",
      "--- epoch: 3876, loss: 0.064957, val_loss: 0.050038 ---\n",
      "--- epoch: 3877, loss: 0.064954, val_loss: 0.050034 ---\n",
      "--- epoch: 3878, loss: 0.064951, val_loss: 0.050030 ---\n",
      "--- epoch: 3879, loss: 0.064948, val_loss: 0.050025 ---\n",
      "--- epoch: 3880, loss: 0.064945, val_loss: 0.050021 ---\n",
      "--- epoch: 3881, loss: 0.064942, val_loss: 0.050017 ---\n",
      "--- epoch: 3882, loss: 0.064938, val_loss: 0.050013 ---\n",
      "--- epoch: 3883, loss: 0.064935, val_loss: 0.050009 ---\n",
      "--- epoch: 3884, loss: 0.064932, val_loss: 0.050004 ---\n",
      "--- epoch: 3885, loss: 0.064929, val_loss: 0.050000 ---\n",
      "--- epoch: 3886, loss: 0.064926, val_loss: 0.049996 ---\n",
      "--- epoch: 3887, loss: 0.064922, val_loss: 0.049992 ---\n",
      "--- epoch: 3888, loss: 0.064919, val_loss: 0.049988 ---\n",
      "--- epoch: 3889, loss: 0.064916, val_loss: 0.049984 ---\n",
      "--- epoch: 3890, loss: 0.064913, val_loss: 0.049979 ---\n",
      "--- epoch: 3891, loss: 0.064910, val_loss: 0.049975 ---\n",
      "--- epoch: 3892, loss: 0.064907, val_loss: 0.049971 ---\n",
      "--- epoch: 3893, loss: 0.064903, val_loss: 0.049967 ---\n",
      "--- epoch: 3894, loss: 0.064900, val_loss: 0.049963 ---\n",
      "--- epoch: 3895, loss: 0.064897, val_loss: 0.049959 ---\n",
      "--- epoch: 3896, loss: 0.064894, val_loss: 0.049954 ---\n",
      "--- epoch: 3897, loss: 0.064891, val_loss: 0.049950 ---\n",
      "--- epoch: 3898, loss: 0.064888, val_loss: 0.049946 ---\n",
      "--- epoch: 3899, loss: 0.064884, val_loss: 0.049942 ---\n",
      "--- epoch: 3900, loss: 0.064881, val_loss: 0.049938 ---\n",
      "--- epoch: 3901, loss: 0.064878, val_loss: 0.049934 ---\n",
      "--- epoch: 3902, loss: 0.064875, val_loss: 0.049929 ---\n",
      "--- epoch: 3903, loss: 0.064872, val_loss: 0.049925 ---\n",
      "--- epoch: 3904, loss: 0.064869, val_loss: 0.049921 ---\n",
      "--- epoch: 3905, loss: 0.064866, val_loss: 0.049917 ---\n",
      "--- epoch: 3906, loss: 0.064862, val_loss: 0.049913 ---\n",
      "--- epoch: 3907, loss: 0.064859, val_loss: 0.049909 ---\n",
      "--- epoch: 3908, loss: 0.064856, val_loss: 0.049905 ---\n",
      "--- epoch: 3909, loss: 0.064853, val_loss: 0.049900 ---\n",
      "--- epoch: 3910, loss: 0.064850, val_loss: 0.049896 ---\n",
      "--- epoch: 3911, loss: 0.064847, val_loss: 0.049892 ---\n",
      "--- epoch: 3912, loss: 0.064844, val_loss: 0.049888 ---\n",
      "--- epoch: 3913, loss: 0.064840, val_loss: 0.049884 ---\n",
      "--- epoch: 3914, loss: 0.064837, val_loss: 0.049880 ---\n",
      "--- epoch: 3915, loss: 0.064834, val_loss: 0.049876 ---\n",
      "--- epoch: 3916, loss: 0.064831, val_loss: 0.049871 ---\n",
      "--- epoch: 3917, loss: 0.064828, val_loss: 0.049867 ---\n",
      "--- epoch: 3918, loss: 0.064825, val_loss: 0.049863 ---\n",
      "--- epoch: 3919, loss: 0.064822, val_loss: 0.049859 ---\n",
      "--- epoch: 3920, loss: 0.064819, val_loss: 0.049855 ---\n",
      "--- epoch: 3921, loss: 0.064815, val_loss: 0.049851 ---\n",
      "--- epoch: 3922, loss: 0.064812, val_loss: 0.049847 ---\n",
      "--- epoch: 3923, loss: 0.064809, val_loss: 0.049843 ---\n",
      "--- epoch: 3924, loss: 0.064806, val_loss: 0.049839 ---\n",
      "--- epoch: 3925, loss: 0.064803, val_loss: 0.049834 ---\n",
      "--- epoch: 3926, loss: 0.064800, val_loss: 0.049830 ---\n",
      "--- epoch: 3927, loss: 0.064797, val_loss: 0.049826 ---\n",
      "--- epoch: 3928, loss: 0.064794, val_loss: 0.049822 ---\n",
      "--- epoch: 3929, loss: 0.064791, val_loss: 0.049818 ---\n",
      "--- epoch: 3930, loss: 0.064787, val_loss: 0.049814 ---\n",
      "--- epoch: 3931, loss: 0.064784, val_loss: 0.049810 ---\n",
      "--- epoch: 3932, loss: 0.064781, val_loss: 0.049806 ---\n",
      "--- epoch: 3933, loss: 0.064778, val_loss: 0.049802 ---\n",
      "--- epoch: 3934, loss: 0.064775, val_loss: 0.049798 ---\n",
      "--- epoch: 3935, loss: 0.064772, val_loss: 0.049793 ---\n",
      "--- epoch: 3936, loss: 0.064769, val_loss: 0.049789 ---\n",
      "--- epoch: 3937, loss: 0.064766, val_loss: 0.049785 ---\n",
      "--- epoch: 3938, loss: 0.064763, val_loss: 0.049781 ---\n",
      "--- epoch: 3939, loss: 0.064759, val_loss: 0.049777 ---\n",
      "--- epoch: 3940, loss: 0.064756, val_loss: 0.049773 ---\n",
      "--- epoch: 3941, loss: 0.064753, val_loss: 0.049769 ---\n",
      "--- epoch: 3942, loss: 0.064750, val_loss: 0.049765 ---\n",
      "--- epoch: 3943, loss: 0.064747, val_loss: 0.049761 ---\n",
      "--- epoch: 3944, loss: 0.064744, val_loss: 0.049757 ---\n",
      "--- epoch: 3945, loss: 0.064741, val_loss: 0.049753 ---\n",
      "--- epoch: 3946, loss: 0.064738, val_loss: 0.049749 ---\n",
      "--- epoch: 3947, loss: 0.064735, val_loss: 0.049744 ---\n",
      "--- epoch: 3948, loss: 0.064732, val_loss: 0.049740 ---\n",
      "--- epoch: 3949, loss: 0.064729, val_loss: 0.049736 ---\n",
      "--- epoch: 3950, loss: 0.064726, val_loss: 0.049732 ---\n",
      "--- epoch: 3951, loss: 0.064722, val_loss: 0.049728 ---\n",
      "--- epoch: 3952, loss: 0.064719, val_loss: 0.049724 ---\n",
      "--- epoch: 3953, loss: 0.064716, val_loss: 0.049720 ---\n",
      "--- epoch: 3954, loss: 0.064713, val_loss: 0.049716 ---\n",
      "--- epoch: 3955, loss: 0.064710, val_loss: 0.049712 ---\n",
      "--- epoch: 3956, loss: 0.064707, val_loss: 0.049708 ---\n",
      "--- epoch: 3957, loss: 0.064704, val_loss: 0.049704 ---\n",
      "--- epoch: 3958, loss: 0.064701, val_loss: 0.049700 ---\n",
      "--- epoch: 3959, loss: 0.064698, val_loss: 0.049696 ---\n",
      "--- epoch: 3960, loss: 0.064695, val_loss: 0.049692 ---\n",
      "--- epoch: 3961, loss: 0.064692, val_loss: 0.049688 ---\n",
      "--- epoch: 3962, loss: 0.064689, val_loss: 0.049684 ---\n",
      "--- epoch: 3963, loss: 0.064686, val_loss: 0.049680 ---\n",
      "--- epoch: 3964, loss: 0.064683, val_loss: 0.049676 ---\n",
      "--- epoch: 3965, loss: 0.064679, val_loss: 0.049671 ---\n",
      "--- epoch: 3966, loss: 0.064676, val_loss: 0.049667 ---\n",
      "--- epoch: 3967, loss: 0.064673, val_loss: 0.049663 ---\n",
      "--- epoch: 3968, loss: 0.064670, val_loss: 0.049659 ---\n",
      "--- epoch: 3969, loss: 0.064667, val_loss: 0.049655 ---\n",
      "--- epoch: 3970, loss: 0.064664, val_loss: 0.049651 ---\n",
      "--- epoch: 3971, loss: 0.064661, val_loss: 0.049647 ---\n",
      "--- epoch: 3972, loss: 0.064658, val_loss: 0.049643 ---\n",
      "--- epoch: 3973, loss: 0.064655, val_loss: 0.049639 ---\n",
      "--- epoch: 3974, loss: 0.064652, val_loss: 0.049635 ---\n",
      "--- epoch: 3975, loss: 0.064649, val_loss: 0.049631 ---\n",
      "--- epoch: 3976, loss: 0.064646, val_loss: 0.049627 ---\n",
      "--- epoch: 3977, loss: 0.064643, val_loss: 0.049623 ---\n",
      "--- epoch: 3978, loss: 0.064640, val_loss: 0.049619 ---\n",
      "--- epoch: 3979, loss: 0.064637, val_loss: 0.049615 ---\n",
      "--- epoch: 3980, loss: 0.064634, val_loss: 0.049611 ---\n",
      "--- epoch: 3981, loss: 0.064631, val_loss: 0.049607 ---\n",
      "--- epoch: 3982, loss: 0.064628, val_loss: 0.049603 ---\n",
      "--- epoch: 3983, loss: 0.064625, val_loss: 0.049599 ---\n",
      "--- epoch: 3984, loss: 0.064622, val_loss: 0.049595 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 3985, loss: 0.064618, val_loss: 0.049591 ---\n",
      "--- epoch: 3986, loss: 0.064615, val_loss: 0.049587 ---\n",
      "--- epoch: 3987, loss: 0.064612, val_loss: 0.049583 ---\n",
      "--- epoch: 3988, loss: 0.064609, val_loss: 0.049579 ---\n",
      "--- epoch: 3989, loss: 0.064606, val_loss: 0.049575 ---\n",
      "--- epoch: 3990, loss: 0.064603, val_loss: 0.049571 ---\n",
      "--- epoch: 3991, loss: 0.064600, val_loss: 0.049567 ---\n",
      "--- epoch: 3992, loss: 0.064597, val_loss: 0.049563 ---\n",
      "--- epoch: 3993, loss: 0.064594, val_loss: 0.049559 ---\n",
      "--- epoch: 3994, loss: 0.064591, val_loss: 0.049555 ---\n",
      "--- epoch: 3995, loss: 0.064588, val_loss: 0.049551 ---\n",
      "--- epoch: 3996, loss: 0.064585, val_loss: 0.049547 ---\n",
      "--- epoch: 3997, loss: 0.064582, val_loss: 0.049543 ---\n",
      "--- epoch: 3998, loss: 0.064579, val_loss: 0.049539 ---\n",
      "--- epoch: 3999, loss: 0.064576, val_loss: 0.049535 ---\n",
      "--- epoch: 4000, loss: 0.064573, val_loss: 0.049531 ---\n",
      "--- epoch: 4001, loss: 0.064570, val_loss: 0.049527 ---\n",
      "--- epoch: 4002, loss: 0.064567, val_loss: 0.049523 ---\n",
      "--- epoch: 4003, loss: 0.064564, val_loss: 0.049519 ---\n",
      "--- epoch: 4004, loss: 0.064561, val_loss: 0.049515 ---\n",
      "--- epoch: 4005, loss: 0.064558, val_loss: 0.049511 ---\n",
      "--- epoch: 4006, loss: 0.064555, val_loss: 0.049507 ---\n",
      "--- epoch: 4007, loss: 0.064552, val_loss: 0.049503 ---\n",
      "--- epoch: 4008, loss: 0.064549, val_loss: 0.049499 ---\n",
      "--- epoch: 4009, loss: 0.064546, val_loss: 0.049495 ---\n",
      "--- epoch: 4010, loss: 0.064543, val_loss: 0.049491 ---\n",
      "--- epoch: 4011, loss: 0.064540, val_loss: 0.049487 ---\n",
      "--- epoch: 4012, loss: 0.064537, val_loss: 0.049483 ---\n",
      "--- epoch: 4013, loss: 0.064534, val_loss: 0.049479 ---\n",
      "--- epoch: 4014, loss: 0.064531, val_loss: 0.049475 ---\n",
      "--- epoch: 4015, loss: 0.064528, val_loss: 0.049471 ---\n",
      "--- epoch: 4016, loss: 0.064525, val_loss: 0.049467 ---\n",
      "--- epoch: 4017, loss: 0.064522, val_loss: 0.049463 ---\n",
      "--- epoch: 4018, loss: 0.064519, val_loss: 0.049459 ---\n",
      "--- epoch: 4019, loss: 0.064516, val_loss: 0.049455 ---\n",
      "--- epoch: 4020, loss: 0.064513, val_loss: 0.049451 ---\n",
      "--- epoch: 4021, loss: 0.064510, val_loss: 0.049447 ---\n",
      "--- epoch: 4022, loss: 0.064507, val_loss: 0.049443 ---\n",
      "--- epoch: 4023, loss: 0.064504, val_loss: 0.049439 ---\n",
      "--- epoch: 4024, loss: 0.064501, val_loss: 0.049436 ---\n",
      "--- epoch: 4025, loss: 0.064498, val_loss: 0.049432 ---\n",
      "--- epoch: 4026, loss: 0.064495, val_loss: 0.049428 ---\n",
      "--- epoch: 4027, loss: 0.064492, val_loss: 0.049424 ---\n",
      "--- epoch: 4028, loss: 0.064489, val_loss: 0.049420 ---\n",
      "--- epoch: 4029, loss: 0.064486, val_loss: 0.049416 ---\n",
      "--- epoch: 4030, loss: 0.064483, val_loss: 0.049412 ---\n",
      "--- epoch: 4031, loss: 0.064480, val_loss: 0.049408 ---\n",
      "--- epoch: 4032, loss: 0.064477, val_loss: 0.049404 ---\n",
      "--- epoch: 4033, loss: 0.064474, val_loss: 0.049400 ---\n",
      "--- epoch: 4034, loss: 0.064471, val_loss: 0.049396 ---\n",
      "--- epoch: 4035, loss: 0.064468, val_loss: 0.049392 ---\n",
      "--- epoch: 4036, loss: 0.064465, val_loss: 0.049388 ---\n",
      "--- epoch: 4037, loss: 0.064463, val_loss: 0.049384 ---\n",
      "--- epoch: 4038, loss: 0.064460, val_loss: 0.049380 ---\n",
      "--- epoch: 4039, loss: 0.064457, val_loss: 0.049377 ---\n",
      "--- epoch: 4040, loss: 0.064454, val_loss: 0.049373 ---\n",
      "--- epoch: 4041, loss: 0.064451, val_loss: 0.049369 ---\n",
      "--- epoch: 4042, loss: 0.064448, val_loss: 0.049365 ---\n",
      "--- epoch: 4043, loss: 0.064445, val_loss: 0.049361 ---\n",
      "--- epoch: 4044, loss: 0.064442, val_loss: 0.049357 ---\n",
      "--- epoch: 4045, loss: 0.064439, val_loss: 0.049353 ---\n",
      "--- epoch: 4046, loss: 0.064436, val_loss: 0.049349 ---\n",
      "--- epoch: 4047, loss: 0.064433, val_loss: 0.049345 ---\n",
      "--- epoch: 4048, loss: 0.064430, val_loss: 0.049341 ---\n",
      "--- epoch: 4049, loss: 0.064427, val_loss: 0.049337 ---\n",
      "--- epoch: 4050, loss: 0.064424, val_loss: 0.049333 ---\n",
      "--- epoch: 4051, loss: 0.064421, val_loss: 0.049330 ---\n",
      "--- epoch: 4052, loss: 0.064418, val_loss: 0.049326 ---\n",
      "--- epoch: 4053, loss: 0.064415, val_loss: 0.049322 ---\n",
      "--- epoch: 4054, loss: 0.064412, val_loss: 0.049318 ---\n",
      "--- epoch: 4055, loss: 0.064409, val_loss: 0.049314 ---\n",
      "--- epoch: 4056, loss: 0.064406, val_loss: 0.049310 ---\n",
      "--- epoch: 4057, loss: 0.064404, val_loss: 0.049306 ---\n",
      "--- epoch: 4058, loss: 0.064401, val_loss: 0.049302 ---\n",
      "--- epoch: 4059, loss: 0.064398, val_loss: 0.049298 ---\n",
      "--- epoch: 4060, loss: 0.064395, val_loss: 0.049294 ---\n",
      "--- epoch: 4061, loss: 0.064392, val_loss: 0.049291 ---\n",
      "--- epoch: 4062, loss: 0.064389, val_loss: 0.049287 ---\n",
      "--- epoch: 4063, loss: 0.064386, val_loss: 0.049283 ---\n",
      "--- epoch: 4064, loss: 0.064383, val_loss: 0.049279 ---\n",
      "--- epoch: 4065, loss: 0.064380, val_loss: 0.049275 ---\n",
      "--- epoch: 4066, loss: 0.064377, val_loss: 0.049271 ---\n",
      "--- epoch: 4067, loss: 0.064374, val_loss: 0.049267 ---\n",
      "--- epoch: 4068, loss: 0.064371, val_loss: 0.049263 ---\n",
      "--- epoch: 4069, loss: 0.064368, val_loss: 0.049259 ---\n",
      "--- epoch: 4070, loss: 0.064365, val_loss: 0.049256 ---\n",
      "--- epoch: 4071, loss: 0.064362, val_loss: 0.049252 ---\n",
      "--- epoch: 4072, loss: 0.064360, val_loss: 0.049248 ---\n",
      "--- epoch: 4073, loss: 0.064357, val_loss: 0.049244 ---\n",
      "--- epoch: 4074, loss: 0.064354, val_loss: 0.049240 ---\n",
      "--- epoch: 4075, loss: 0.064351, val_loss: 0.049236 ---\n",
      "--- epoch: 4076, loss: 0.064348, val_loss: 0.049232 ---\n",
      "--- epoch: 4077, loss: 0.064345, val_loss: 0.049228 ---\n",
      "--- epoch: 4078, loss: 0.064342, val_loss: 0.049225 ---\n",
      "--- epoch: 4079, loss: 0.064339, val_loss: 0.049221 ---\n",
      "--- epoch: 4080, loss: 0.064336, val_loss: 0.049217 ---\n",
      "--- epoch: 4081, loss: 0.064333, val_loss: 0.049213 ---\n",
      "--- epoch: 4082, loss: 0.064330, val_loss: 0.049209 ---\n",
      "--- epoch: 4083, loss: 0.064327, val_loss: 0.049205 ---\n",
      "--- epoch: 4084, loss: 0.064325, val_loss: 0.049201 ---\n",
      "--- epoch: 4085, loss: 0.064322, val_loss: 0.049198 ---\n",
      "--- epoch: 4086, loss: 0.064319, val_loss: 0.049194 ---\n",
      "--- epoch: 4087, loss: 0.064316, val_loss: 0.049190 ---\n",
      "--- epoch: 4088, loss: 0.064313, val_loss: 0.049186 ---\n",
      "--- epoch: 4089, loss: 0.064310, val_loss: 0.049182 ---\n",
      "--- epoch: 4090, loss: 0.064307, val_loss: 0.049178 ---\n",
      "--- epoch: 4091, loss: 0.064304, val_loss: 0.049174 ---\n",
      "--- epoch: 4092, loss: 0.064301, val_loss: 0.049171 ---\n",
      "--- epoch: 4093, loss: 0.064298, val_loss: 0.049167 ---\n",
      "--- epoch: 4094, loss: 0.064296, val_loss: 0.049163 ---\n",
      "--- epoch: 4095, loss: 0.064293, val_loss: 0.049159 ---\n",
      "--- epoch: 4096, loss: 0.064290, val_loss: 0.049155 ---\n",
      "--- epoch: 4097, loss: 0.064287, val_loss: 0.049151 ---\n",
      "--- epoch: 4098, loss: 0.064284, val_loss: 0.049147 ---\n",
      "--- epoch: 4099, loss: 0.064281, val_loss: 0.049144 ---\n",
      "--- epoch: 4100, loss: 0.064278, val_loss: 0.049140 ---\n",
      "--- epoch: 4101, loss: 0.064275, val_loss: 0.049136 ---\n",
      "--- epoch: 4102, loss: 0.064272, val_loss: 0.049132 ---\n",
      "--- epoch: 4103, loss: 0.064270, val_loss: 0.049128 ---\n",
      "--- epoch: 4104, loss: 0.064267, val_loss: 0.049124 ---\n",
      "--- epoch: 4105, loss: 0.064264, val_loss: 0.049121 ---\n",
      "--- epoch: 4106, loss: 0.064261, val_loss: 0.049117 ---\n",
      "--- epoch: 4107, loss: 0.064258, val_loss: 0.049113 ---\n",
      "--- epoch: 4108, loss: 0.064255, val_loss: 0.049109 ---\n",
      "--- epoch: 4109, loss: 0.064252, val_loss: 0.049105 ---\n",
      "--- epoch: 4110, loss: 0.064249, val_loss: 0.049101 ---\n",
      "--- epoch: 4111, loss: 0.064246, val_loss: 0.049098 ---\n",
      "--- epoch: 4112, loss: 0.064244, val_loss: 0.049094 ---\n",
      "--- epoch: 4113, loss: 0.064241, val_loss: 0.049090 ---\n",
      "--- epoch: 4114, loss: 0.064238, val_loss: 0.049086 ---\n",
      "--- epoch: 4115, loss: 0.064235, val_loss: 0.049082 ---\n",
      "--- epoch: 4116, loss: 0.064232, val_loss: 0.049079 ---\n",
      "--- epoch: 4117, loss: 0.064229, val_loss: 0.049075 ---\n",
      "--- epoch: 4118, loss: 0.064226, val_loss: 0.049071 ---\n",
      "--- epoch: 4119, loss: 0.064223, val_loss: 0.049067 ---\n",
      "--- epoch: 4120, loss: 0.064221, val_loss: 0.049063 ---\n",
      "--- epoch: 4121, loss: 0.064218, val_loss: 0.049059 ---\n",
      "--- epoch: 4122, loss: 0.064215, val_loss: 0.049056 ---\n",
      "--- epoch: 4123, loss: 0.064212, val_loss: 0.049052 ---\n",
      "--- epoch: 4124, loss: 0.064209, val_loss: 0.049048 ---\n",
      "--- epoch: 4125, loss: 0.064206, val_loss: 0.049044 ---\n",
      "--- epoch: 4126, loss: 0.064203, val_loss: 0.049041 ---\n",
      "--- epoch: 4127, loss: 0.064201, val_loss: 0.049037 ---\n",
      "--- epoch: 4128, loss: 0.064198, val_loss: 0.049033 ---\n",
      "--- epoch: 4129, loss: 0.064195, val_loss: 0.049029 ---\n",
      "--- epoch: 4130, loss: 0.064192, val_loss: 0.049025 ---\n",
      "--- epoch: 4131, loss: 0.064189, val_loss: 0.049022 ---\n",
      "--- epoch: 4132, loss: 0.064186, val_loss: 0.049018 ---\n",
      "--- epoch: 4133, loss: 0.064184, val_loss: 0.049014 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 4134, loss: 0.064181, val_loss: 0.049010 ---\n",
      "--- epoch: 4135, loss: 0.064178, val_loss: 0.049006 ---\n",
      "--- epoch: 4136, loss: 0.064175, val_loss: 0.049003 ---\n",
      "--- epoch: 4137, loss: 0.064172, val_loss: 0.048999 ---\n",
      "--- epoch: 4138, loss: 0.064169, val_loss: 0.048995 ---\n",
      "--- epoch: 4139, loss: 0.064167, val_loss: 0.048991 ---\n",
      "--- epoch: 4140, loss: 0.064164, val_loss: 0.048988 ---\n",
      "--- epoch: 4141, loss: 0.064161, val_loss: 0.048984 ---\n",
      "--- epoch: 4142, loss: 0.064158, val_loss: 0.048980 ---\n",
      "--- epoch: 4143, loss: 0.064155, val_loss: 0.048976 ---\n",
      "--- epoch: 4144, loss: 0.064152, val_loss: 0.048973 ---\n",
      "--- epoch: 4145, loss: 0.064150, val_loss: 0.048969 ---\n",
      "--- epoch: 4146, loss: 0.064147, val_loss: 0.048965 ---\n",
      "--- epoch: 4147, loss: 0.064144, val_loss: 0.048961 ---\n",
      "--- epoch: 4148, loss: 0.064141, val_loss: 0.048957 ---\n",
      "--- epoch: 4149, loss: 0.064138, val_loss: 0.048954 ---\n",
      "--- epoch: 4150, loss: 0.064135, val_loss: 0.048950 ---\n",
      "--- epoch: 4151, loss: 0.064133, val_loss: 0.048946 ---\n",
      "--- epoch: 4152, loss: 0.064130, val_loss: 0.048942 ---\n",
      "--- epoch: 4153, loss: 0.064127, val_loss: 0.048939 ---\n",
      "--- epoch: 4154, loss: 0.064124, val_loss: 0.048935 ---\n",
      "--- epoch: 4155, loss: 0.064121, val_loss: 0.048931 ---\n",
      "--- epoch: 4156, loss: 0.064118, val_loss: 0.048927 ---\n",
      "--- epoch: 4157, loss: 0.064116, val_loss: 0.048924 ---\n",
      "--- epoch: 4158, loss: 0.064113, val_loss: 0.048920 ---\n",
      "--- epoch: 4159, loss: 0.064110, val_loss: 0.048916 ---\n",
      "--- epoch: 4160, loss: 0.064107, val_loss: 0.048912 ---\n",
      "--- epoch: 4161, loss: 0.064104, val_loss: 0.048909 ---\n",
      "--- epoch: 4162, loss: 0.064102, val_loss: 0.048905 ---\n",
      "--- epoch: 4163, loss: 0.064099, val_loss: 0.048901 ---\n",
      "--- epoch: 4164, loss: 0.064096, val_loss: 0.048897 ---\n",
      "--- epoch: 4165, loss: 0.064093, val_loss: 0.048894 ---\n",
      "--- epoch: 4166, loss: 0.064090, val_loss: 0.048890 ---\n",
      "--- epoch: 4167, loss: 0.064088, val_loss: 0.048886 ---\n",
      "--- epoch: 4168, loss: 0.064085, val_loss: 0.048882 ---\n",
      "--- epoch: 4169, loss: 0.064082, val_loss: 0.048879 ---\n",
      "--- epoch: 4170, loss: 0.064079, val_loss: 0.048875 ---\n",
      "--- epoch: 4171, loss: 0.064076, val_loss: 0.048871 ---\n",
      "--- epoch: 4172, loss: 0.064074, val_loss: 0.048868 ---\n",
      "--- epoch: 4173, loss: 0.064071, val_loss: 0.048864 ---\n",
      "--- epoch: 4174, loss: 0.064068, val_loss: 0.048860 ---\n",
      "--- epoch: 4175, loss: 0.064065, val_loss: 0.048856 ---\n",
      "--- epoch: 4176, loss: 0.064062, val_loss: 0.048853 ---\n",
      "--- epoch: 4177, loss: 0.064060, val_loss: 0.048849 ---\n",
      "--- epoch: 4178, loss: 0.064057, val_loss: 0.048845 ---\n",
      "--- epoch: 4179, loss: 0.064054, val_loss: 0.048841 ---\n",
      "--- epoch: 4180, loss: 0.064051, val_loss: 0.048838 ---\n",
      "--- epoch: 4181, loss: 0.064048, val_loss: 0.048834 ---\n",
      "--- epoch: 4182, loss: 0.064046, val_loss: 0.048830 ---\n",
      "--- epoch: 4183, loss: 0.064043, val_loss: 0.048827 ---\n",
      "--- epoch: 4184, loss: 0.064040, val_loss: 0.048823 ---\n",
      "--- epoch: 4185, loss: 0.064037, val_loss: 0.048819 ---\n",
      "--- epoch: 4186, loss: 0.064035, val_loss: 0.048815 ---\n",
      "--- epoch: 4187, loss: 0.064032, val_loss: 0.048812 ---\n",
      "--- epoch: 4188, loss: 0.064029, val_loss: 0.048808 ---\n",
      "--- epoch: 4189, loss: 0.064026, val_loss: 0.048804 ---\n",
      "--- epoch: 4190, loss: 0.064023, val_loss: 0.048801 ---\n",
      "--- epoch: 4191, loss: 0.064021, val_loss: 0.048797 ---\n",
      "--- epoch: 4192, loss: 0.064018, val_loss: 0.048793 ---\n",
      "--- epoch: 4193, loss: 0.064015, val_loss: 0.048790 ---\n",
      "--- epoch: 4194, loss: 0.064012, val_loss: 0.048786 ---\n",
      "--- epoch: 4195, loss: 0.064009, val_loss: 0.048782 ---\n",
      "--- epoch: 4196, loss: 0.064007, val_loss: 0.048778 ---\n",
      "--- epoch: 4197, loss: 0.064004, val_loss: 0.048775 ---\n",
      "--- epoch: 4198, loss: 0.064001, val_loss: 0.048771 ---\n",
      "--- epoch: 4199, loss: 0.063998, val_loss: 0.048767 ---\n",
      "--- epoch: 4200, loss: 0.063996, val_loss: 0.048764 ---\n",
      "--- epoch: 4201, loss: 0.063993, val_loss: 0.048760 ---\n",
      "--- epoch: 4202, loss: 0.063990, val_loss: 0.048756 ---\n",
      "--- epoch: 4203, loss: 0.063987, val_loss: 0.048753 ---\n",
      "--- epoch: 4204, loss: 0.063985, val_loss: 0.048749 ---\n",
      "--- epoch: 4205, loss: 0.063982, val_loss: 0.048745 ---\n",
      "--- epoch: 4206, loss: 0.063979, val_loss: 0.048741 ---\n",
      "--- epoch: 4207, loss: 0.063976, val_loss: 0.048738 ---\n",
      "--- epoch: 4208, loss: 0.063974, val_loss: 0.048734 ---\n",
      "--- epoch: 4209, loss: 0.063971, val_loss: 0.048730 ---\n",
      "--- epoch: 4210, loss: 0.063968, val_loss: 0.048727 ---\n",
      "--- epoch: 4211, loss: 0.063965, val_loss: 0.048723 ---\n",
      "--- epoch: 4212, loss: 0.063962, val_loss: 0.048719 ---\n",
      "--- epoch: 4213, loss: 0.063960, val_loss: 0.048716 ---\n",
      "--- epoch: 4214, loss: 0.063957, val_loss: 0.048712 ---\n",
      "--- epoch: 4215, loss: 0.063954, val_loss: 0.048708 ---\n",
      "--- epoch: 4216, loss: 0.063951, val_loss: 0.048705 ---\n",
      "--- epoch: 4217, loss: 0.063949, val_loss: 0.048701 ---\n",
      "--- epoch: 4218, loss: 0.063946, val_loss: 0.048697 ---\n",
      "--- epoch: 4219, loss: 0.063943, val_loss: 0.048694 ---\n",
      "--- epoch: 4220, loss: 0.063940, val_loss: 0.048690 ---\n",
      "--- epoch: 4221, loss: 0.063938, val_loss: 0.048686 ---\n",
      "--- epoch: 4222, loss: 0.063935, val_loss: 0.048683 ---\n",
      "--- epoch: 4223, loss: 0.063932, val_loss: 0.048679 ---\n",
      "--- epoch: 4224, loss: 0.063930, val_loss: 0.048675 ---\n",
      "--- epoch: 4225, loss: 0.063927, val_loss: 0.048672 ---\n",
      "--- epoch: 4226, loss: 0.063924, val_loss: 0.048668 ---\n",
      "--- epoch: 4227, loss: 0.063921, val_loss: 0.048664 ---\n",
      "--- epoch: 4228, loss: 0.063919, val_loss: 0.048661 ---\n",
      "--- epoch: 4229, loss: 0.063916, val_loss: 0.048657 ---\n",
      "--- epoch: 4230, loss: 0.063913, val_loss: 0.048653 ---\n",
      "--- epoch: 4231, loss: 0.063910, val_loss: 0.048650 ---\n",
      "--- epoch: 4232, loss: 0.063908, val_loss: 0.048646 ---\n",
      "--- epoch: 4233, loss: 0.063905, val_loss: 0.048643 ---\n",
      "--- epoch: 4234, loss: 0.063902, val_loss: 0.048639 ---\n",
      "--- epoch: 4235, loss: 0.063899, val_loss: 0.048635 ---\n",
      "--- epoch: 4236, loss: 0.063897, val_loss: 0.048632 ---\n",
      "--- epoch: 4237, loss: 0.063894, val_loss: 0.048628 ---\n",
      "--- epoch: 4238, loss: 0.063891, val_loss: 0.048624 ---\n",
      "--- epoch: 4239, loss: 0.063889, val_loss: 0.048621 ---\n",
      "--- epoch: 4240, loss: 0.063886, val_loss: 0.048617 ---\n",
      "--- epoch: 4241, loss: 0.063883, val_loss: 0.048613 ---\n",
      "--- epoch: 4242, loss: 0.063880, val_loss: 0.048610 ---\n",
      "--- epoch: 4243, loss: 0.063878, val_loss: 0.048606 ---\n",
      "--- epoch: 4244, loss: 0.063875, val_loss: 0.048602 ---\n",
      "--- epoch: 4245, loss: 0.063872, val_loss: 0.048599 ---\n",
      "--- epoch: 4246, loss: 0.063869, val_loss: 0.048595 ---\n",
      "--- epoch: 4247, loss: 0.063867, val_loss: 0.048592 ---\n",
      "--- epoch: 4248, loss: 0.063864, val_loss: 0.048588 ---\n",
      "--- epoch: 4249, loss: 0.063861, val_loss: 0.048584 ---\n",
      "--- epoch: 4250, loss: 0.063859, val_loss: 0.048581 ---\n",
      "--- epoch: 4251, loss: 0.063856, val_loss: 0.048577 ---\n",
      "--- epoch: 4252, loss: 0.063853, val_loss: 0.048573 ---\n",
      "--- epoch: 4253, loss: 0.063851, val_loss: 0.048570 ---\n",
      "--- epoch: 4254, loss: 0.063848, val_loss: 0.048566 ---\n",
      "--- epoch: 4255, loss: 0.063845, val_loss: 0.048563 ---\n",
      "--- epoch: 4256, loss: 0.063842, val_loss: 0.048559 ---\n",
      "--- epoch: 4257, loss: 0.063840, val_loss: 0.048555 ---\n",
      "--- epoch: 4258, loss: 0.063837, val_loss: 0.048552 ---\n",
      "--- epoch: 4259, loss: 0.063834, val_loss: 0.048548 ---\n",
      "--- epoch: 4260, loss: 0.063832, val_loss: 0.048545 ---\n",
      "--- epoch: 4261, loss: 0.063829, val_loss: 0.048541 ---\n",
      "--- epoch: 4262, loss: 0.063826, val_loss: 0.048537 ---\n",
      "--- epoch: 4263, loss: 0.063824, val_loss: 0.048534 ---\n",
      "--- epoch: 4264, loss: 0.063821, val_loss: 0.048530 ---\n",
      "--- epoch: 4265, loss: 0.063818, val_loss: 0.048527 ---\n",
      "--- epoch: 4266, loss: 0.063815, val_loss: 0.048523 ---\n",
      "--- epoch: 4267, loss: 0.063813, val_loss: 0.048519 ---\n",
      "--- epoch: 4268, loss: 0.063810, val_loss: 0.048516 ---\n",
      "--- epoch: 4269, loss: 0.063807, val_loss: 0.048512 ---\n",
      "--- epoch: 4270, loss: 0.063805, val_loss: 0.048509 ---\n",
      "--- epoch: 4271, loss: 0.063802, val_loss: 0.048505 ---\n",
      "--- epoch: 4272, loss: 0.063799, val_loss: 0.048501 ---\n",
      "--- epoch: 4273, loss: 0.063797, val_loss: 0.048498 ---\n",
      "--- epoch: 4274, loss: 0.063794, val_loss: 0.048494 ---\n",
      "--- epoch: 4275, loss: 0.063791, val_loss: 0.048491 ---\n",
      "--- epoch: 4276, loss: 0.063789, val_loss: 0.048487 ---\n",
      "--- epoch: 4277, loss: 0.063786, val_loss: 0.048483 ---\n",
      "--- epoch: 4278, loss: 0.063783, val_loss: 0.048480 ---\n",
      "--- epoch: 4279, loss: 0.063781, val_loss: 0.048476 ---\n",
      "--- epoch: 4280, loss: 0.063778, val_loss: 0.048473 ---\n",
      "--- epoch: 4281, loss: 0.063775, val_loss: 0.048469 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 4282, loss: 0.063773, val_loss: 0.048466 ---\n",
      "--- epoch: 4283, loss: 0.063770, val_loss: 0.048462 ---\n",
      "--- epoch: 4284, loss: 0.063767, val_loss: 0.048458 ---\n",
      "--- epoch: 4285, loss: 0.063765, val_loss: 0.048455 ---\n",
      "--- epoch: 4286, loss: 0.063762, val_loss: 0.048451 ---\n",
      "--- epoch: 4287, loss: 0.063759, val_loss: 0.048448 ---\n",
      "--- epoch: 4288, loss: 0.063757, val_loss: 0.048444 ---\n",
      "--- epoch: 4289, loss: 0.063754, val_loss: 0.048441 ---\n",
      "--- epoch: 4290, loss: 0.063751, val_loss: 0.048437 ---\n",
      "--- epoch: 4291, loss: 0.063749, val_loss: 0.048433 ---\n",
      "--- epoch: 4292, loss: 0.063746, val_loss: 0.048430 ---\n",
      "--- epoch: 4293, loss: 0.063743, val_loss: 0.048426 ---\n",
      "--- epoch: 4294, loss: 0.063741, val_loss: 0.048423 ---\n",
      "--- epoch: 4295, loss: 0.063738, val_loss: 0.048419 ---\n",
      "--- epoch: 4296, loss: 0.063735, val_loss: 0.048416 ---\n",
      "--- epoch: 4297, loss: 0.063733, val_loss: 0.048412 ---\n",
      "--- epoch: 4298, loss: 0.063730, val_loss: 0.048408 ---\n",
      "--- epoch: 4299, loss: 0.063727, val_loss: 0.048405 ---\n",
      "--- epoch: 4300, loss: 0.063725, val_loss: 0.048401 ---\n",
      "--- epoch: 4301, loss: 0.063722, val_loss: 0.048398 ---\n",
      "--- epoch: 4302, loss: 0.063719, val_loss: 0.048394 ---\n",
      "--- epoch: 4303, loss: 0.063717, val_loss: 0.048391 ---\n",
      "--- epoch: 4304, loss: 0.063714, val_loss: 0.048387 ---\n",
      "--- epoch: 4305, loss: 0.063711, val_loss: 0.048384 ---\n",
      "--- epoch: 4306, loss: 0.063709, val_loss: 0.048380 ---\n",
      "--- epoch: 4307, loss: 0.063706, val_loss: 0.048377 ---\n",
      "--- epoch: 4308, loss: 0.063703, val_loss: 0.048373 ---\n",
      "--- epoch: 4309, loss: 0.063701, val_loss: 0.048369 ---\n",
      "--- epoch: 4310, loss: 0.063698, val_loss: 0.048366 ---\n",
      "--- epoch: 4311, loss: 0.063696, val_loss: 0.048362 ---\n",
      "--- epoch: 4312, loss: 0.063693, val_loss: 0.048359 ---\n",
      "--- epoch: 4313, loss: 0.063690, val_loss: 0.048355 ---\n",
      "--- epoch: 4314, loss: 0.063688, val_loss: 0.048352 ---\n",
      "--- epoch: 4315, loss: 0.063685, val_loss: 0.048348 ---\n",
      "--- epoch: 4316, loss: 0.063682, val_loss: 0.048345 ---\n",
      "--- epoch: 4317, loss: 0.063680, val_loss: 0.048341 ---\n",
      "--- epoch: 4318, loss: 0.063677, val_loss: 0.048338 ---\n",
      "--- epoch: 4319, loss: 0.063674, val_loss: 0.048334 ---\n",
      "--- epoch: 4320, loss: 0.063672, val_loss: 0.048331 ---\n",
      "--- epoch: 4321, loss: 0.063669, val_loss: 0.048327 ---\n",
      "--- epoch: 4322, loss: 0.063667, val_loss: 0.048323 ---\n",
      "--- epoch: 4323, loss: 0.063664, val_loss: 0.048320 ---\n",
      "--- epoch: 4324, loss: 0.063661, val_loss: 0.048316 ---\n",
      "--- epoch: 4325, loss: 0.063659, val_loss: 0.048313 ---\n",
      "--- epoch: 4326, loss: 0.063656, val_loss: 0.048309 ---\n",
      "--- epoch: 4327, loss: 0.063653, val_loss: 0.048306 ---\n",
      "--- epoch: 4328, loss: 0.063651, val_loss: 0.048302 ---\n",
      "--- epoch: 4329, loss: 0.063648, val_loss: 0.048299 ---\n",
      "--- epoch: 4330, loss: 0.063646, val_loss: 0.048295 ---\n",
      "--- epoch: 4331, loss: 0.063643, val_loss: 0.048292 ---\n",
      "--- epoch: 4332, loss: 0.063640, val_loss: 0.048288 ---\n",
      "--- epoch: 4333, loss: 0.063638, val_loss: 0.048285 ---\n",
      "--- epoch: 4334, loss: 0.063635, val_loss: 0.048281 ---\n",
      "--- epoch: 4335, loss: 0.063632, val_loss: 0.048278 ---\n",
      "--- epoch: 4336, loss: 0.063630, val_loss: 0.048274 ---\n",
      "--- epoch: 4337, loss: 0.063627, val_loss: 0.048271 ---\n",
      "--- epoch: 4338, loss: 0.063625, val_loss: 0.048267 ---\n",
      "--- epoch: 4339, loss: 0.063622, val_loss: 0.048264 ---\n",
      "--- epoch: 4340, loss: 0.063619, val_loss: 0.048260 ---\n",
      "--- epoch: 4341, loss: 0.063617, val_loss: 0.048257 ---\n",
      "--- epoch: 4342, loss: 0.063614, val_loss: 0.048253 ---\n",
      "--- epoch: 4343, loss: 0.063612, val_loss: 0.048250 ---\n",
      "--- epoch: 4344, loss: 0.063609, val_loss: 0.048246 ---\n",
      "--- epoch: 4345, loss: 0.063606, val_loss: 0.048243 ---\n",
      "--- epoch: 4346, loss: 0.063604, val_loss: 0.048239 ---\n",
      "--- epoch: 4347, loss: 0.063601, val_loss: 0.048236 ---\n",
      "--- epoch: 4348, loss: 0.063598, val_loss: 0.048232 ---\n",
      "--- epoch: 4349, loss: 0.063596, val_loss: 0.048229 ---\n",
      "--- epoch: 4350, loss: 0.063593, val_loss: 0.048225 ---\n",
      "--- epoch: 4351, loss: 0.063591, val_loss: 0.048222 ---\n",
      "--- epoch: 4352, loss: 0.063588, val_loss: 0.048218 ---\n",
      "--- epoch: 4353, loss: 0.063585, val_loss: 0.048215 ---\n",
      "--- epoch: 4354, loss: 0.063583, val_loss: 0.048211 ---\n",
      "--- epoch: 4355, loss: 0.063580, val_loss: 0.048208 ---\n",
      "--- epoch: 4356, loss: 0.063578, val_loss: 0.048204 ---\n",
      "--- epoch: 4357, loss: 0.063575, val_loss: 0.048201 ---\n",
      "--- epoch: 4358, loss: 0.063573, val_loss: 0.048197 ---\n",
      "--- epoch: 4359, loss: 0.063570, val_loss: 0.048194 ---\n",
      "--- epoch: 4360, loss: 0.063567, val_loss: 0.048190 ---\n",
      "--- epoch: 4361, loss: 0.063565, val_loss: 0.048187 ---\n",
      "--- epoch: 4362, loss: 0.063562, val_loss: 0.048183 ---\n",
      "--- epoch: 4363, loss: 0.063560, val_loss: 0.048180 ---\n",
      "--- epoch: 4364, loss: 0.063557, val_loss: 0.048177 ---\n",
      "--- epoch: 4365, loss: 0.063554, val_loss: 0.048173 ---\n",
      "--- epoch: 4366, loss: 0.063552, val_loss: 0.048170 ---\n",
      "--- epoch: 4367, loss: 0.063549, val_loss: 0.048166 ---\n",
      "--- epoch: 4368, loss: 0.063547, val_loss: 0.048163 ---\n",
      "--- epoch: 4369, loss: 0.063544, val_loss: 0.048159 ---\n",
      "--- epoch: 4370, loss: 0.063541, val_loss: 0.048156 ---\n",
      "--- epoch: 4371, loss: 0.063539, val_loss: 0.048152 ---\n",
      "--- epoch: 4372, loss: 0.063536, val_loss: 0.048149 ---\n",
      "--- epoch: 4373, loss: 0.063534, val_loss: 0.048145 ---\n",
      "--- epoch: 4374, loss: 0.063531, val_loss: 0.048142 ---\n",
      "--- epoch: 4375, loss: 0.063529, val_loss: 0.048138 ---\n",
      "--- epoch: 4376, loss: 0.063526, val_loss: 0.048135 ---\n",
      "--- epoch: 4377, loss: 0.063523, val_loss: 0.048131 ---\n",
      "--- epoch: 4378, loss: 0.063521, val_loss: 0.048128 ---\n",
      "--- epoch: 4379, loss: 0.063518, val_loss: 0.048125 ---\n",
      "--- epoch: 4380, loss: 0.063516, val_loss: 0.048121 ---\n",
      "--- epoch: 4381, loss: 0.063513, val_loss: 0.048118 ---\n",
      "--- epoch: 4382, loss: 0.063511, val_loss: 0.048114 ---\n",
      "--- epoch: 4383, loss: 0.063508, val_loss: 0.048111 ---\n",
      "--- epoch: 4384, loss: 0.063505, val_loss: 0.048107 ---\n",
      "--- epoch: 4385, loss: 0.063503, val_loss: 0.048104 ---\n",
      "--- epoch: 4386, loss: 0.063500, val_loss: 0.048100 ---\n",
      "--- epoch: 4387, loss: 0.063498, val_loss: 0.048097 ---\n",
      "--- epoch: 4388, loss: 0.063495, val_loss: 0.048094 ---\n",
      "--- epoch: 4389, loss: 0.063493, val_loss: 0.048090 ---\n",
      "--- epoch: 4390, loss: 0.063490, val_loss: 0.048087 ---\n",
      "--- epoch: 4391, loss: 0.063488, val_loss: 0.048083 ---\n",
      "--- epoch: 4392, loss: 0.063485, val_loss: 0.048080 ---\n",
      "--- epoch: 4393, loss: 0.063482, val_loss: 0.048076 ---\n",
      "--- epoch: 4394, loss: 0.063480, val_loss: 0.048073 ---\n",
      "--- epoch: 4395, loss: 0.063477, val_loss: 0.048069 ---\n",
      "--- epoch: 4396, loss: 0.063475, val_loss: 0.048066 ---\n",
      "--- epoch: 4397, loss: 0.063472, val_loss: 0.048063 ---\n",
      "--- epoch: 4398, loss: 0.063470, val_loss: 0.048059 ---\n",
      "--- epoch: 4399, loss: 0.063467, val_loss: 0.048056 ---\n",
      "--- epoch: 4400, loss: 0.063465, val_loss: 0.048052 ---\n",
      "--- epoch: 4401, loss: 0.063462, val_loss: 0.048049 ---\n",
      "--- epoch: 4402, loss: 0.063459, val_loss: 0.048045 ---\n",
      "--- epoch: 4403, loss: 0.063457, val_loss: 0.048042 ---\n",
      "--- epoch: 4404, loss: 0.063454, val_loss: 0.048039 ---\n",
      "--- epoch: 4405, loss: 0.063452, val_loss: 0.048035 ---\n",
      "--- epoch: 4406, loss: 0.063449, val_loss: 0.048032 ---\n",
      "--- epoch: 4407, loss: 0.063447, val_loss: 0.048028 ---\n",
      "--- epoch: 4408, loss: 0.063444, val_loss: 0.048025 ---\n",
      "--- epoch: 4409, loss: 0.063442, val_loss: 0.048022 ---\n",
      "--- epoch: 4410, loss: 0.063439, val_loss: 0.048018 ---\n",
      "--- epoch: 4411, loss: 0.063437, val_loss: 0.048015 ---\n",
      "--- epoch: 4412, loss: 0.063434, val_loss: 0.048011 ---\n",
      "--- epoch: 4413, loss: 0.063432, val_loss: 0.048008 ---\n",
      "--- epoch: 4414, loss: 0.063429, val_loss: 0.048004 ---\n",
      "--- epoch: 4415, loss: 0.063426, val_loss: 0.048001 ---\n",
      "--- epoch: 4416, loss: 0.063424, val_loss: 0.047998 ---\n",
      "--- epoch: 4417, loss: 0.063421, val_loss: 0.047994 ---\n",
      "--- epoch: 4418, loss: 0.063419, val_loss: 0.047991 ---\n",
      "--- epoch: 4419, loss: 0.063416, val_loss: 0.047987 ---\n",
      "--- epoch: 4420, loss: 0.063414, val_loss: 0.047984 ---\n",
      "--- epoch: 4421, loss: 0.063411, val_loss: 0.047981 ---\n",
      "--- epoch: 4422, loss: 0.063409, val_loss: 0.047977 ---\n",
      "--- epoch: 4423, loss: 0.063406, val_loss: 0.047974 ---\n",
      "--- epoch: 4424, loss: 0.063404, val_loss: 0.047970 ---\n",
      "--- epoch: 4425, loss: 0.063401, val_loss: 0.047967 ---\n",
      "--- epoch: 4426, loss: 0.063399, val_loss: 0.047964 ---\n",
      "--- epoch: 4427, loss: 0.063396, val_loss: 0.047960 ---\n",
      "--- epoch: 4428, loss: 0.063394, val_loss: 0.047957 ---\n",
      "--- epoch: 4429, loss: 0.063391, val_loss: 0.047954 ---\n",
      "--- epoch: 4430, loss: 0.063389, val_loss: 0.047950 ---\n",
      "--- epoch: 4431, loss: 0.063386, val_loss: 0.047947 ---\n",
      "--- epoch: 4432, loss: 0.063384, val_loss: 0.047943 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 4433, loss: 0.063381, val_loss: 0.047940 ---\n",
      "--- epoch: 4434, loss: 0.063379, val_loss: 0.047937 ---\n",
      "--- epoch: 4435, loss: 0.063376, val_loss: 0.047933 ---\n",
      "--- epoch: 4436, loss: 0.063374, val_loss: 0.047930 ---\n",
      "--- epoch: 4437, loss: 0.063371, val_loss: 0.047926 ---\n",
      "--- epoch: 4438, loss: 0.063369, val_loss: 0.047923 ---\n",
      "--- epoch: 4439, loss: 0.063366, val_loss: 0.047920 ---\n",
      "--- epoch: 4440, loss: 0.063364, val_loss: 0.047916 ---\n",
      "--- epoch: 4441, loss: 0.063361, val_loss: 0.047913 ---\n",
      "--- epoch: 4442, loss: 0.063359, val_loss: 0.047910 ---\n",
      "--- epoch: 4443, loss: 0.063356, val_loss: 0.047906 ---\n",
      "--- epoch: 4444, loss: 0.063354, val_loss: 0.047903 ---\n",
      "--- epoch: 4445, loss: 0.063351, val_loss: 0.047899 ---\n",
      "--- epoch: 4446, loss: 0.063349, val_loss: 0.047896 ---\n",
      "--- epoch: 4447, loss: 0.063346, val_loss: 0.047893 ---\n",
      "--- epoch: 4448, loss: 0.063344, val_loss: 0.047889 ---\n",
      "--- epoch: 4449, loss: 0.063341, val_loss: 0.047886 ---\n",
      "--- epoch: 4450, loss: 0.063339, val_loss: 0.047883 ---\n",
      "--- epoch: 4451, loss: 0.063336, val_loss: 0.047879 ---\n",
      "--- epoch: 4452, loss: 0.063334, val_loss: 0.047876 ---\n",
      "--- epoch: 4453, loss: 0.063331, val_loss: 0.047873 ---\n",
      "--- epoch: 4454, loss: 0.063329, val_loss: 0.047869 ---\n",
      "--- epoch: 4455, loss: 0.063326, val_loss: 0.047866 ---\n",
      "--- epoch: 4456, loss: 0.063324, val_loss: 0.047862 ---\n",
      "--- epoch: 4457, loss: 0.063321, val_loss: 0.047859 ---\n",
      "--- epoch: 4458, loss: 0.063319, val_loss: 0.047856 ---\n",
      "--- epoch: 4459, loss: 0.063316, val_loss: 0.047852 ---\n",
      "--- epoch: 4460, loss: 0.063314, val_loss: 0.047849 ---\n",
      "--- epoch: 4461, loss: 0.063311, val_loss: 0.047846 ---\n",
      "--- epoch: 4462, loss: 0.063309, val_loss: 0.047842 ---\n",
      "--- epoch: 4463, loss: 0.063306, val_loss: 0.047839 ---\n",
      "--- epoch: 4464, loss: 0.063304, val_loss: 0.047836 ---\n",
      "--- epoch: 4465, loss: 0.063301, val_loss: 0.047832 ---\n",
      "--- epoch: 4466, loss: 0.063299, val_loss: 0.047829 ---\n",
      "--- epoch: 4467, loss: 0.063296, val_loss: 0.047826 ---\n",
      "--- epoch: 4468, loss: 0.063294, val_loss: 0.047822 ---\n",
      "--- epoch: 4469, loss: 0.063291, val_loss: 0.047819 ---\n",
      "--- epoch: 4470, loss: 0.063289, val_loss: 0.047816 ---\n",
      "--- epoch: 4471, loss: 0.063286, val_loss: 0.047812 ---\n",
      "--- epoch: 4472, loss: 0.063284, val_loss: 0.047809 ---\n",
      "--- epoch: 4473, loss: 0.063281, val_loss: 0.047805 ---\n",
      "--- epoch: 4474, loss: 0.063279, val_loss: 0.047802 ---\n",
      "--- epoch: 4475, loss: 0.063276, val_loss: 0.047799 ---\n",
      "--- epoch: 4476, loss: 0.063274, val_loss: 0.047795 ---\n",
      "--- epoch: 4477, loss: 0.063271, val_loss: 0.047792 ---\n",
      "--- epoch: 4478, loss: 0.063269, val_loss: 0.047789 ---\n",
      "--- epoch: 4479, loss: 0.063266, val_loss: 0.047785 ---\n",
      "--- epoch: 4480, loss: 0.063264, val_loss: 0.047782 ---\n",
      "--- epoch: 4481, loss: 0.063261, val_loss: 0.047779 ---\n",
      "--- epoch: 4482, loss: 0.063259, val_loss: 0.047775 ---\n",
      "--- epoch: 4483, loss: 0.063257, val_loss: 0.047772 ---\n",
      "--- epoch: 4484, loss: 0.063254, val_loss: 0.047769 ---\n",
      "--- epoch: 4485, loss: 0.063252, val_loss: 0.047765 ---\n",
      "--- epoch: 4486, loss: 0.063249, val_loss: 0.047762 ---\n",
      "--- epoch: 4487, loss: 0.063247, val_loss: 0.047759 ---\n",
      "--- epoch: 4488, loss: 0.063244, val_loss: 0.047755 ---\n",
      "--- epoch: 4489, loss: 0.063242, val_loss: 0.047752 ---\n",
      "--- epoch: 4490, loss: 0.063239, val_loss: 0.047749 ---\n",
      "--- epoch: 4491, loss: 0.063237, val_loss: 0.047746 ---\n",
      "--- epoch: 4492, loss: 0.063234, val_loss: 0.047742 ---\n",
      "--- epoch: 4493, loss: 0.063232, val_loss: 0.047739 ---\n",
      "--- epoch: 4494, loss: 0.063229, val_loss: 0.047736 ---\n",
      "--- epoch: 4495, loss: 0.063227, val_loss: 0.047732 ---\n",
      "--- epoch: 4496, loss: 0.063225, val_loss: 0.047729 ---\n",
      "--- epoch: 4497, loss: 0.063222, val_loss: 0.047726 ---\n",
      "--- epoch: 4498, loss: 0.063220, val_loss: 0.047722 ---\n",
      "--- epoch: 4499, loss: 0.063217, val_loss: 0.047719 ---\n",
      "--- epoch: 4500, loss: 0.063215, val_loss: 0.047716 ---\n",
      "--- epoch: 4501, loss: 0.063212, val_loss: 0.047712 ---\n",
      "--- epoch: 4502, loss: 0.063210, val_loss: 0.047709 ---\n",
      "--- epoch: 4503, loss: 0.063207, val_loss: 0.047706 ---\n",
      "--- epoch: 4504, loss: 0.063205, val_loss: 0.047702 ---\n",
      "--- epoch: 4505, loss: 0.063203, val_loss: 0.047699 ---\n",
      "--- epoch: 4506, loss: 0.063200, val_loss: 0.047696 ---\n",
      "--- epoch: 4507, loss: 0.063198, val_loss: 0.047693 ---\n",
      "--- epoch: 4508, loss: 0.063195, val_loss: 0.047689 ---\n",
      "--- epoch: 4509, loss: 0.063193, val_loss: 0.047686 ---\n",
      "--- epoch: 4510, loss: 0.063190, val_loss: 0.047683 ---\n",
      "--- epoch: 4511, loss: 0.063188, val_loss: 0.047679 ---\n",
      "--- epoch: 4512, loss: 0.063185, val_loss: 0.047676 ---\n",
      "--- epoch: 4513, loss: 0.063183, val_loss: 0.047673 ---\n",
      "--- epoch: 4514, loss: 0.063181, val_loss: 0.047670 ---\n",
      "--- epoch: 4515, loss: 0.063178, val_loss: 0.047666 ---\n",
      "--- epoch: 4516, loss: 0.063176, val_loss: 0.047663 ---\n",
      "--- epoch: 4517, loss: 0.063173, val_loss: 0.047660 ---\n",
      "--- epoch: 4518, loss: 0.063171, val_loss: 0.047656 ---\n",
      "--- epoch: 4519, loss: 0.063168, val_loss: 0.047653 ---\n",
      "--- epoch: 4520, loss: 0.063166, val_loss: 0.047650 ---\n",
      "--- epoch: 4521, loss: 0.063164, val_loss: 0.047646 ---\n",
      "--- epoch: 4522, loss: 0.063161, val_loss: 0.047643 ---\n",
      "--- epoch: 4523, loss: 0.063159, val_loss: 0.047640 ---\n",
      "--- epoch: 4524, loss: 0.063156, val_loss: 0.047637 ---\n",
      "--- epoch: 4525, loss: 0.063154, val_loss: 0.047633 ---\n",
      "--- epoch: 4526, loss: 0.063151, val_loss: 0.047630 ---\n",
      "--- epoch: 4527, loss: 0.063149, val_loss: 0.047627 ---\n",
      "--- epoch: 4528, loss: 0.063147, val_loss: 0.047624 ---\n",
      "--- epoch: 4529, loss: 0.063144, val_loss: 0.047620 ---\n",
      "--- epoch: 4530, loss: 0.063142, val_loss: 0.047617 ---\n",
      "--- epoch: 4531, loss: 0.063139, val_loss: 0.047614 ---\n",
      "--- epoch: 4532, loss: 0.063137, val_loss: 0.047610 ---\n",
      "--- epoch: 4533, loss: 0.063134, val_loss: 0.047607 ---\n",
      "--- epoch: 4534, loss: 0.063132, val_loss: 0.047604 ---\n",
      "--- epoch: 4535, loss: 0.063130, val_loss: 0.047601 ---\n",
      "--- epoch: 4536, loss: 0.063127, val_loss: 0.047597 ---\n",
      "--- epoch: 4537, loss: 0.063125, val_loss: 0.047594 ---\n",
      "--- epoch: 4538, loss: 0.063122, val_loss: 0.047591 ---\n",
      "--- epoch: 4539, loss: 0.063120, val_loss: 0.047588 ---\n",
      "--- epoch: 4540, loss: 0.063117, val_loss: 0.047584 ---\n",
      "--- epoch: 4541, loss: 0.063115, val_loss: 0.047581 ---\n",
      "--- epoch: 4542, loss: 0.063113, val_loss: 0.047578 ---\n",
      "--- epoch: 4543, loss: 0.063110, val_loss: 0.047575 ---\n",
      "--- epoch: 4544, loss: 0.063108, val_loss: 0.047571 ---\n",
      "--- epoch: 4545, loss: 0.063105, val_loss: 0.047568 ---\n",
      "--- epoch: 4546, loss: 0.063103, val_loss: 0.047565 ---\n",
      "--- epoch: 4547, loss: 0.063101, val_loss: 0.047562 ---\n",
      "--- epoch: 4548, loss: 0.063098, val_loss: 0.047558 ---\n",
      "--- epoch: 4549, loss: 0.063096, val_loss: 0.047555 ---\n",
      "--- epoch: 4550, loss: 0.063094, val_loss: 0.047552 ---\n",
      "--- epoch: 4551, loss: 0.063091, val_loss: 0.047549 ---\n",
      "--- epoch: 4552, loss: 0.063089, val_loss: 0.047545 ---\n",
      "--- epoch: 4553, loss: 0.063086, val_loss: 0.047542 ---\n",
      "--- epoch: 4554, loss: 0.063084, val_loss: 0.047539 ---\n",
      "--- epoch: 4555, loss: 0.063082, val_loss: 0.047536 ---\n",
      "--- epoch: 4556, loss: 0.063079, val_loss: 0.047532 ---\n",
      "--- epoch: 4557, loss: 0.063077, val_loss: 0.047529 ---\n",
      "--- epoch: 4558, loss: 0.063074, val_loss: 0.047526 ---\n",
      "--- epoch: 4559, loss: 0.063072, val_loss: 0.047523 ---\n",
      "--- epoch: 4560, loss: 0.063070, val_loss: 0.047520 ---\n",
      "--- epoch: 4561, loss: 0.063067, val_loss: 0.047516 ---\n",
      "--- epoch: 4562, loss: 0.063065, val_loss: 0.047513 ---\n",
      "--- epoch: 4563, loss: 0.063062, val_loss: 0.047510 ---\n",
      "--- epoch: 4564, loss: 0.063060, val_loss: 0.047507 ---\n",
      "--- epoch: 4565, loss: 0.063058, val_loss: 0.047503 ---\n",
      "--- epoch: 4566, loss: 0.063055, val_loss: 0.047500 ---\n",
      "--- epoch: 4567, loss: 0.063053, val_loss: 0.047497 ---\n",
      "--- epoch: 4568, loss: 0.063051, val_loss: 0.047494 ---\n",
      "--- epoch: 4569, loss: 0.063048, val_loss: 0.047490 ---\n",
      "--- epoch: 4570, loss: 0.063046, val_loss: 0.047487 ---\n",
      "--- epoch: 4571, loss: 0.063043, val_loss: 0.047484 ---\n",
      "--- epoch: 4572, loss: 0.063041, val_loss: 0.047481 ---\n",
      "--- epoch: 4573, loss: 0.063039, val_loss: 0.047478 ---\n",
      "--- epoch: 4574, loss: 0.063036, val_loss: 0.047474 ---\n",
      "--- epoch: 4575, loss: 0.063034, val_loss: 0.047471 ---\n",
      "--- epoch: 4576, loss: 0.063031, val_loss: 0.047468 ---\n",
      "--- epoch: 4577, loss: 0.063029, val_loss: 0.047465 ---\n",
      "--- epoch: 4578, loss: 0.063027, val_loss: 0.047461 ---\n",
      "--- epoch: 4579, loss: 0.063024, val_loss: 0.047458 ---\n",
      "--- epoch: 4580, loss: 0.063022, val_loss: 0.047455 ---\n",
      "--- epoch: 4581, loss: 0.063020, val_loss: 0.047452 ---\n",
      "--- epoch: 4582, loss: 0.063017, val_loss: 0.047449 ---\n",
      "--- epoch: 4583, loss: 0.063015, val_loss: 0.047445 ---\n",
      "--- epoch: 4584, loss: 0.063012, val_loss: 0.047442 ---\n",
      "--- epoch: 4585, loss: 0.063010, val_loss: 0.047439 ---\n",
      "--- epoch: 4586, loss: 0.063008, val_loss: 0.047436 ---\n",
      "--- epoch: 4587, loss: 0.063005, val_loss: 0.047432 ---\n",
      "--- epoch: 4588, loss: 0.063003, val_loss: 0.047429 ---\n",
      "--- epoch: 4589, loss: 0.063001, val_loss: 0.047426 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 4590, loss: 0.062998, val_loss: 0.047423 ---\n",
      "--- epoch: 4591, loss: 0.062996, val_loss: 0.047420 ---\n",
      "--- epoch: 4592, loss: 0.062993, val_loss: 0.047416 ---\n",
      "--- epoch: 4593, loss: 0.062991, val_loss: 0.047413 ---\n",
      "--- epoch: 4594, loss: 0.062989, val_loss: 0.047410 ---\n",
      "--- epoch: 4595, loss: 0.062986, val_loss: 0.047407 ---\n",
      "--- epoch: 4596, loss: 0.062984, val_loss: 0.047404 ---\n",
      "--- epoch: 4597, loss: 0.062982, val_loss: 0.047400 ---\n",
      "--- epoch: 4598, loss: 0.062979, val_loss: 0.047397 ---\n",
      "--- epoch: 4599, loss: 0.062977, val_loss: 0.047394 ---\n",
      "--- epoch: 4600, loss: 0.062975, val_loss: 0.047391 ---\n",
      "--- epoch: 4601, loss: 0.062972, val_loss: 0.047388 ---\n",
      "--- epoch: 4602, loss: 0.062970, val_loss: 0.047385 ---\n",
      "--- epoch: 4603, loss: 0.062968, val_loss: 0.047381 ---\n",
      "--- epoch: 4604, loss: 0.062965, val_loss: 0.047378 ---\n",
      "--- epoch: 4605, loss: 0.062963, val_loss: 0.047375 ---\n",
      "--- epoch: 4606, loss: 0.062961, val_loss: 0.047372 ---\n",
      "--- epoch: 4607, loss: 0.062958, val_loss: 0.047369 ---\n",
      "--- epoch: 4608, loss: 0.062956, val_loss: 0.047365 ---\n",
      "--- epoch: 4609, loss: 0.062953, val_loss: 0.047362 ---\n",
      "--- epoch: 4610, loss: 0.062951, val_loss: 0.047359 ---\n",
      "--- epoch: 4611, loss: 0.062949, val_loss: 0.047356 ---\n",
      "--- epoch: 4612, loss: 0.062946, val_loss: 0.047353 ---\n",
      "--- epoch: 4613, loss: 0.062944, val_loss: 0.047350 ---\n",
      "--- epoch: 4614, loss: 0.062942, val_loss: 0.047346 ---\n",
      "--- epoch: 4615, loss: 0.062939, val_loss: 0.047343 ---\n",
      "--- epoch: 4616, loss: 0.062937, val_loss: 0.047340 ---\n",
      "--- epoch: 4617, loss: 0.062935, val_loss: 0.047337 ---\n",
      "--- epoch: 4618, loss: 0.062932, val_loss: 0.047334 ---\n",
      "--- epoch: 4619, loss: 0.062930, val_loss: 0.047330 ---\n",
      "--- epoch: 4620, loss: 0.062928, val_loss: 0.047327 ---\n",
      "--- epoch: 4621, loss: 0.062925, val_loss: 0.047324 ---\n",
      "--- epoch: 4622, loss: 0.062923, val_loss: 0.047321 ---\n",
      "--- epoch: 4623, loss: 0.062921, val_loss: 0.047318 ---\n",
      "--- epoch: 4624, loss: 0.062918, val_loss: 0.047315 ---\n",
      "--- epoch: 4625, loss: 0.062916, val_loss: 0.047311 ---\n",
      "--- epoch: 4626, loss: 0.062914, val_loss: 0.047308 ---\n",
      "--- epoch: 4627, loss: 0.062911, val_loss: 0.047305 ---\n",
      "--- epoch: 4628, loss: 0.062909, val_loss: 0.047302 ---\n",
      "--- epoch: 4629, loss: 0.062907, val_loss: 0.047299 ---\n",
      "--- epoch: 4630, loss: 0.062904, val_loss: 0.047296 ---\n",
      "--- epoch: 4631, loss: 0.062902, val_loss: 0.047292 ---\n",
      "--- epoch: 4632, loss: 0.062900, val_loss: 0.047289 ---\n",
      "--- epoch: 4633, loss: 0.062897, val_loss: 0.047286 ---\n",
      "--- epoch: 4634, loss: 0.062895, val_loss: 0.047283 ---\n",
      "--- epoch: 4635, loss: 0.062893, val_loss: 0.047280 ---\n",
      "--- epoch: 4636, loss: 0.062890, val_loss: 0.047277 ---\n",
      "--- epoch: 4637, loss: 0.062888, val_loss: 0.047274 ---\n",
      "--- epoch: 4638, loss: 0.062886, val_loss: 0.047270 ---\n",
      "--- epoch: 4639, loss: 0.062883, val_loss: 0.047267 ---\n",
      "--- epoch: 4640, loss: 0.062881, val_loss: 0.047264 ---\n",
      "--- epoch: 4641, loss: 0.062879, val_loss: 0.047261 ---\n",
      "--- epoch: 4642, loss: 0.062876, val_loss: 0.047258 ---\n",
      "--- epoch: 4643, loss: 0.062874, val_loss: 0.047255 ---\n",
      "--- epoch: 4644, loss: 0.062872, val_loss: 0.047251 ---\n",
      "--- epoch: 4645, loss: 0.062869, val_loss: 0.047248 ---\n",
      "--- epoch: 4646, loss: 0.062867, val_loss: 0.047245 ---\n",
      "--- epoch: 4647, loss: 0.062865, val_loss: 0.047242 ---\n",
      "--- epoch: 4648, loss: 0.062863, val_loss: 0.047239 ---\n",
      "--- epoch: 4649, loss: 0.062860, val_loss: 0.047236 ---\n",
      "--- epoch: 4650, loss: 0.062858, val_loss: 0.047233 ---\n",
      "--- epoch: 4651, loss: 0.062856, val_loss: 0.047229 ---\n",
      "--- epoch: 4652, loss: 0.062853, val_loss: 0.047226 ---\n",
      "--- epoch: 4653, loss: 0.062851, val_loss: 0.047223 ---\n",
      "--- epoch: 4654, loss: 0.062849, val_loss: 0.047220 ---\n",
      "--- epoch: 4655, loss: 0.062846, val_loss: 0.047217 ---\n",
      "--- epoch: 4656, loss: 0.062844, val_loss: 0.047214 ---\n",
      "--- epoch: 4657, loss: 0.062842, val_loss: 0.047211 ---\n",
      "--- epoch: 4658, loss: 0.062839, val_loss: 0.047208 ---\n",
      "--- epoch: 4659, loss: 0.062837, val_loss: 0.047204 ---\n",
      "--- epoch: 4660, loss: 0.062835, val_loss: 0.047201 ---\n",
      "--- epoch: 4661, loss: 0.062833, val_loss: 0.047198 ---\n",
      "--- epoch: 4662, loss: 0.062830, val_loss: 0.047195 ---\n",
      "--- epoch: 4663, loss: 0.062828, val_loss: 0.047192 ---\n",
      "--- epoch: 4664, loss: 0.062826, val_loss: 0.047189 ---\n",
      "--- epoch: 4665, loss: 0.062823, val_loss: 0.047186 ---\n",
      "--- epoch: 4666, loss: 0.062821, val_loss: 0.047183 ---\n",
      "--- epoch: 4667, loss: 0.062819, val_loss: 0.047179 ---\n",
      "--- epoch: 4668, loss: 0.062816, val_loss: 0.047176 ---\n",
      "--- epoch: 4669, loss: 0.062814, val_loss: 0.047173 ---\n",
      "--- epoch: 4670, loss: 0.062812, val_loss: 0.047170 ---\n",
      "--- epoch: 4671, loss: 0.062810, val_loss: 0.047167 ---\n",
      "--- epoch: 4672, loss: 0.062807, val_loss: 0.047164 ---\n",
      "--- epoch: 4673, loss: 0.062805, val_loss: 0.047161 ---\n",
      "--- epoch: 4674, loss: 0.062803, val_loss: 0.047158 ---\n",
      "--- epoch: 4675, loss: 0.062800, val_loss: 0.047155 ---\n",
      "--- epoch: 4676, loss: 0.062798, val_loss: 0.047151 ---\n",
      "--- epoch: 4677, loss: 0.062796, val_loss: 0.047148 ---\n",
      "--- epoch: 4678, loss: 0.062794, val_loss: 0.047145 ---\n",
      "--- epoch: 4679, loss: 0.062791, val_loss: 0.047142 ---\n",
      "--- epoch: 4680, loss: 0.062789, val_loss: 0.047139 ---\n",
      "--- epoch: 4681, loss: 0.062787, val_loss: 0.047136 ---\n",
      "--- epoch: 4682, loss: 0.062784, val_loss: 0.047133 ---\n",
      "--- epoch: 4683, loss: 0.062782, val_loss: 0.047130 ---\n",
      "--- epoch: 4684, loss: 0.062780, val_loss: 0.047127 ---\n",
      "--- epoch: 4685, loss: 0.062778, val_loss: 0.047124 ---\n",
      "--- epoch: 4686, loss: 0.062775, val_loss: 0.047120 ---\n",
      "--- epoch: 4687, loss: 0.062773, val_loss: 0.047117 ---\n",
      "--- epoch: 4688, loss: 0.062771, val_loss: 0.047114 ---\n",
      "--- epoch: 4689, loss: 0.062769, val_loss: 0.047111 ---\n",
      "--- epoch: 4690, loss: 0.062766, val_loss: 0.047108 ---\n",
      "--- epoch: 4691, loss: 0.062764, val_loss: 0.047105 ---\n",
      "--- epoch: 4692, loss: 0.062762, val_loss: 0.047102 ---\n",
      "--- epoch: 4693, loss: 0.062759, val_loss: 0.047099 ---\n",
      "--- epoch: 4694, loss: 0.062757, val_loss: 0.047096 ---\n",
      "--- epoch: 4695, loss: 0.062755, val_loss: 0.047093 ---\n",
      "--- epoch: 4696, loss: 0.062753, val_loss: 0.047090 ---\n",
      "--- epoch: 4697, loss: 0.062750, val_loss: 0.047086 ---\n",
      "--- epoch: 4698, loss: 0.062748, val_loss: 0.047083 ---\n",
      "--- epoch: 4699, loss: 0.062746, val_loss: 0.047080 ---\n",
      "--- epoch: 4700, loss: 0.062744, val_loss: 0.047077 ---\n",
      "--- epoch: 4701, loss: 0.062741, val_loss: 0.047074 ---\n",
      "--- epoch: 4702, loss: 0.062739, val_loss: 0.047071 ---\n",
      "--- epoch: 4703, loss: 0.062737, val_loss: 0.047068 ---\n",
      "--- epoch: 4704, loss: 0.062734, val_loss: 0.047065 ---\n",
      "--- epoch: 4705, loss: 0.062732, val_loss: 0.047062 ---\n",
      "--- epoch: 4706, loss: 0.062730, val_loss: 0.047059 ---\n",
      "--- epoch: 4707, loss: 0.062728, val_loss: 0.047056 ---\n",
      "--- epoch: 4708, loss: 0.062725, val_loss: 0.047053 ---\n",
      "--- epoch: 4709, loss: 0.062723, val_loss: 0.047049 ---\n",
      "--- epoch: 4710, loss: 0.062721, val_loss: 0.047046 ---\n",
      "--- epoch: 4711, loss: 0.062719, val_loss: 0.047043 ---\n",
      "--- epoch: 4712, loss: 0.062716, val_loss: 0.047040 ---\n",
      "--- epoch: 4713, loss: 0.062714, val_loss: 0.047037 ---\n",
      "--- epoch: 4714, loss: 0.062712, val_loss: 0.047034 ---\n",
      "--- epoch: 4715, loss: 0.062710, val_loss: 0.047031 ---\n",
      "--- epoch: 4716, loss: 0.062707, val_loss: 0.047028 ---\n",
      "--- epoch: 4717, loss: 0.062705, val_loss: 0.047025 ---\n",
      "--- epoch: 4718, loss: 0.062703, val_loss: 0.047022 ---\n",
      "--- epoch: 4719, loss: 0.062701, val_loss: 0.047019 ---\n",
      "--- epoch: 4720, loss: 0.062698, val_loss: 0.047016 ---\n",
      "--- epoch: 4721, loss: 0.062696, val_loss: 0.047013 ---\n",
      "--- epoch: 4722, loss: 0.062694, val_loss: 0.047010 ---\n",
      "--- epoch: 4723, loss: 0.062692, val_loss: 0.047006 ---\n",
      "--- epoch: 4724, loss: 0.062689, val_loss: 0.047003 ---\n",
      "--- epoch: 4725, loss: 0.062687, val_loss: 0.047000 ---\n",
      "--- epoch: 4726, loss: 0.062685, val_loss: 0.046997 ---\n",
      "--- epoch: 4727, loss: 0.062683, val_loss: 0.046994 ---\n",
      "--- epoch: 4728, loss: 0.062680, val_loss: 0.046991 ---\n",
      "--- epoch: 4729, loss: 0.062678, val_loss: 0.046988 ---\n",
      "--- epoch: 4730, loss: 0.062676, val_loss: 0.046985 ---\n",
      "--- epoch: 4731, loss: 0.062674, val_loss: 0.046982 ---\n",
      "--- epoch: 4732, loss: 0.062671, val_loss: 0.046979 ---\n",
      "--- epoch: 4733, loss: 0.062669, val_loss: 0.046976 ---\n",
      "--- epoch: 4734, loss: 0.062667, val_loss: 0.046973 ---\n",
      "--- epoch: 4735, loss: 0.062665, val_loss: 0.046970 ---\n",
      "--- epoch: 4736, loss: 0.062662, val_loss: 0.046967 ---\n",
      "--- epoch: 4737, loss: 0.062660, val_loss: 0.046964 ---\n",
      "--- epoch: 4738, loss: 0.062658, val_loss: 0.046961 ---\n",
      "--- epoch: 4739, loss: 0.062656, val_loss: 0.046958 ---\n",
      "--- epoch: 4740, loss: 0.062653, val_loss: 0.046955 ---\n",
      "--- epoch: 4741, loss: 0.062651, val_loss: 0.046951 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 4742, loss: 0.062649, val_loss: 0.046948 ---\n",
      "--- epoch: 4743, loss: 0.062647, val_loss: 0.046945 ---\n",
      "--- epoch: 4744, loss: 0.062645, val_loss: 0.046942 ---\n",
      "--- epoch: 4745, loss: 0.062642, val_loss: 0.046939 ---\n",
      "--- epoch: 4746, loss: 0.062640, val_loss: 0.046936 ---\n",
      "--- epoch: 4747, loss: 0.062638, val_loss: 0.046933 ---\n",
      "--- epoch: 4748, loss: 0.062636, val_loss: 0.046930 ---\n",
      "--- epoch: 4749, loss: 0.062633, val_loss: 0.046927 ---\n",
      "--- epoch: 4750, loss: 0.062631, val_loss: 0.046924 ---\n",
      "--- epoch: 4751, loss: 0.062629, val_loss: 0.046921 ---\n",
      "--- epoch: 4752, loss: 0.062627, val_loss: 0.046918 ---\n",
      "--- epoch: 4753, loss: 0.062624, val_loss: 0.046915 ---\n",
      "--- epoch: 4754, loss: 0.062622, val_loss: 0.046912 ---\n",
      "--- epoch: 4755, loss: 0.062620, val_loss: 0.046909 ---\n",
      "--- epoch: 4756, loss: 0.062618, val_loss: 0.046906 ---\n",
      "--- epoch: 4757, loss: 0.062616, val_loss: 0.046903 ---\n",
      "--- epoch: 4758, loss: 0.062613, val_loss: 0.046900 ---\n",
      "--- epoch: 4759, loss: 0.062611, val_loss: 0.046897 ---\n",
      "--- epoch: 4760, loss: 0.062609, val_loss: 0.046894 ---\n",
      "--- epoch: 4761, loss: 0.062607, val_loss: 0.046891 ---\n",
      "--- epoch: 4762, loss: 0.062604, val_loss: 0.046888 ---\n",
      "--- epoch: 4763, loss: 0.062602, val_loss: 0.046885 ---\n",
      "--- epoch: 4764, loss: 0.062600, val_loss: 0.046882 ---\n",
      "--- epoch: 4765, loss: 0.062598, val_loss: 0.046879 ---\n",
      "--- epoch: 4766, loss: 0.062596, val_loss: 0.046876 ---\n",
      "--- epoch: 4767, loss: 0.062593, val_loss: 0.046873 ---\n",
      "--- epoch: 4768, loss: 0.062591, val_loss: 0.046870 ---\n",
      "--- epoch: 4769, loss: 0.062589, val_loss: 0.046867 ---\n",
      "--- epoch: 4770, loss: 0.062587, val_loss: 0.046863 ---\n",
      "--- epoch: 4771, loss: 0.062584, val_loss: 0.046860 ---\n",
      "--- epoch: 4772, loss: 0.062582, val_loss: 0.046857 ---\n",
      "--- epoch: 4773, loss: 0.062580, val_loss: 0.046854 ---\n",
      "--- epoch: 4774, loss: 0.062578, val_loss: 0.046851 ---\n",
      "--- epoch: 4775, loss: 0.062576, val_loss: 0.046848 ---\n",
      "--- epoch: 4776, loss: 0.062573, val_loss: 0.046845 ---\n",
      "--- epoch: 4777, loss: 0.062571, val_loss: 0.046842 ---\n",
      "--- epoch: 4778, loss: 0.062569, val_loss: 0.046839 ---\n",
      "--- epoch: 4779, loss: 0.062567, val_loss: 0.046836 ---\n",
      "--- epoch: 4780, loss: 0.062565, val_loss: 0.046833 ---\n",
      "--- epoch: 4781, loss: 0.062562, val_loss: 0.046830 ---\n",
      "--- epoch: 4782, loss: 0.062560, val_loss: 0.046827 ---\n",
      "--- epoch: 4783, loss: 0.062558, val_loss: 0.046824 ---\n",
      "--- epoch: 4784, loss: 0.062556, val_loss: 0.046821 ---\n",
      "--- epoch: 4785, loss: 0.062554, val_loss: 0.046818 ---\n",
      "--- epoch: 4786, loss: 0.062551, val_loss: 0.046815 ---\n",
      "--- epoch: 4787, loss: 0.062549, val_loss: 0.046812 ---\n",
      "--- epoch: 4788, loss: 0.062547, val_loss: 0.046809 ---\n",
      "--- epoch: 4789, loss: 0.062545, val_loss: 0.046806 ---\n",
      "--- epoch: 4790, loss: 0.062543, val_loss: 0.046803 ---\n",
      "--- epoch: 4791, loss: 0.062540, val_loss: 0.046800 ---\n",
      "--- epoch: 4792, loss: 0.062538, val_loss: 0.046797 ---\n",
      "--- epoch: 4793, loss: 0.062536, val_loss: 0.046794 ---\n",
      "--- epoch: 4794, loss: 0.062534, val_loss: 0.046791 ---\n",
      "--- epoch: 4795, loss: 0.062532, val_loss: 0.046788 ---\n",
      "--- epoch: 4796, loss: 0.062530, val_loss: 0.046785 ---\n",
      "--- epoch: 4797, loss: 0.062527, val_loss: 0.046782 ---\n",
      "--- epoch: 4798, loss: 0.062525, val_loss: 0.046779 ---\n",
      "--- epoch: 4799, loss: 0.062523, val_loss: 0.046777 ---\n",
      "--- epoch: 4800, loss: 0.062521, val_loss: 0.046774 ---\n",
      "--- epoch: 4801, loss: 0.062519, val_loss: 0.046771 ---\n",
      "--- epoch: 4802, loss: 0.062516, val_loss: 0.046768 ---\n",
      "--- epoch: 4803, loss: 0.062514, val_loss: 0.046765 ---\n",
      "--- epoch: 4804, loss: 0.062512, val_loss: 0.046762 ---\n",
      "--- epoch: 4805, loss: 0.062510, val_loss: 0.046759 ---\n",
      "--- epoch: 4806, loss: 0.062508, val_loss: 0.046756 ---\n",
      "--- epoch: 4807, loss: 0.062506, val_loss: 0.046753 ---\n",
      "--- epoch: 4808, loss: 0.062503, val_loss: 0.046750 ---\n",
      "--- epoch: 4809, loss: 0.062501, val_loss: 0.046747 ---\n",
      "--- epoch: 4810, loss: 0.062499, val_loss: 0.046744 ---\n",
      "--- epoch: 4811, loss: 0.062497, val_loss: 0.046741 ---\n",
      "--- epoch: 4812, loss: 0.062495, val_loss: 0.046738 ---\n",
      "--- epoch: 4813, loss: 0.062493, val_loss: 0.046735 ---\n",
      "--- epoch: 4814, loss: 0.062490, val_loss: 0.046732 ---\n",
      "--- epoch: 4815, loss: 0.062488, val_loss: 0.046729 ---\n",
      "--- epoch: 4816, loss: 0.062486, val_loss: 0.046726 ---\n",
      "--- epoch: 4817, loss: 0.062484, val_loss: 0.046723 ---\n",
      "--- epoch: 4818, loss: 0.062482, val_loss: 0.046720 ---\n",
      "--- epoch: 4819, loss: 0.062479, val_loss: 0.046717 ---\n",
      "--- epoch: 4820, loss: 0.062477, val_loss: 0.046714 ---\n",
      "--- epoch: 4821, loss: 0.062475, val_loss: 0.046711 ---\n",
      "--- epoch: 4822, loss: 0.062473, val_loss: 0.046708 ---\n",
      "--- epoch: 4823, loss: 0.062471, val_loss: 0.046705 ---\n",
      "--- epoch: 4824, loss: 0.062469, val_loss: 0.046702 ---\n",
      "--- epoch: 4825, loss: 0.062467, val_loss: 0.046699 ---\n",
      "--- epoch: 4826, loss: 0.062464, val_loss: 0.046696 ---\n",
      "--- epoch: 4827, loss: 0.062462, val_loss: 0.046694 ---\n",
      "--- epoch: 4828, loss: 0.062460, val_loss: 0.046691 ---\n",
      "--- epoch: 4829, loss: 0.062458, val_loss: 0.046688 ---\n",
      "--- epoch: 4830, loss: 0.062456, val_loss: 0.046685 ---\n",
      "--- epoch: 4831, loss: 0.062454, val_loss: 0.046682 ---\n",
      "--- epoch: 4832, loss: 0.062451, val_loss: 0.046679 ---\n",
      "--- epoch: 4833, loss: 0.062449, val_loss: 0.046676 ---\n",
      "--- epoch: 4834, loss: 0.062447, val_loss: 0.046673 ---\n",
      "--- epoch: 4835, loss: 0.062445, val_loss: 0.046670 ---\n",
      "--- epoch: 4836, loss: 0.062443, val_loss: 0.046667 ---\n",
      "--- epoch: 4837, loss: 0.062441, val_loss: 0.046664 ---\n",
      "--- epoch: 4838, loss: 0.062439, val_loss: 0.046661 ---\n",
      "--- epoch: 4839, loss: 0.062436, val_loss: 0.046658 ---\n",
      "--- epoch: 4840, loss: 0.062434, val_loss: 0.046655 ---\n",
      "--- epoch: 4841, loss: 0.062432, val_loss: 0.046652 ---\n",
      "--- epoch: 4842, loss: 0.062430, val_loss: 0.046649 ---\n",
      "--- epoch: 4843, loss: 0.062428, val_loss: 0.046646 ---\n",
      "--- epoch: 4844, loss: 0.062426, val_loss: 0.046644 ---\n",
      "--- epoch: 4845, loss: 0.062423, val_loss: 0.046641 ---\n",
      "--- epoch: 4846, loss: 0.062421, val_loss: 0.046638 ---\n",
      "--- epoch: 4847, loss: 0.062419, val_loss: 0.046635 ---\n",
      "--- epoch: 4848, loss: 0.062417, val_loss: 0.046632 ---\n",
      "--- epoch: 4849, loss: 0.062415, val_loss: 0.046629 ---\n",
      "--- epoch: 4850, loss: 0.062413, val_loss: 0.046626 ---\n",
      "--- epoch: 4851, loss: 0.062411, val_loss: 0.046623 ---\n",
      "--- epoch: 4852, loss: 0.062408, val_loss: 0.046620 ---\n",
      "--- epoch: 4853, loss: 0.062406, val_loss: 0.046617 ---\n",
      "--- epoch: 4854, loss: 0.062404, val_loss: 0.046614 ---\n",
      "--- epoch: 4855, loss: 0.062402, val_loss: 0.046611 ---\n",
      "--- epoch: 4856, loss: 0.062400, val_loss: 0.046608 ---\n",
      "--- epoch: 4857, loss: 0.062398, val_loss: 0.046605 ---\n",
      "--- epoch: 4858, loss: 0.062396, val_loss: 0.046603 ---\n",
      "--- epoch: 4859, loss: 0.062393, val_loss: 0.046600 ---\n",
      "--- epoch: 4860, loss: 0.062391, val_loss: 0.046597 ---\n",
      "--- epoch: 4861, loss: 0.062389, val_loss: 0.046594 ---\n",
      "--- epoch: 4862, loss: 0.062387, val_loss: 0.046591 ---\n",
      "--- epoch: 4863, loss: 0.062385, val_loss: 0.046588 ---\n",
      "--- epoch: 4864, loss: 0.062383, val_loss: 0.046585 ---\n",
      "--- epoch: 4865, loss: 0.062381, val_loss: 0.046582 ---\n",
      "--- epoch: 4866, loss: 0.062379, val_loss: 0.046579 ---\n",
      "--- epoch: 4867, loss: 0.062376, val_loss: 0.046576 ---\n",
      "--- epoch: 4868, loss: 0.062374, val_loss: 0.046573 ---\n",
      "--- epoch: 4869, loss: 0.062372, val_loss: 0.046570 ---\n",
      "--- epoch: 4870, loss: 0.062370, val_loss: 0.046568 ---\n",
      "--- epoch: 4871, loss: 0.062368, val_loss: 0.046565 ---\n",
      "--- epoch: 4872, loss: 0.062366, val_loss: 0.046562 ---\n",
      "--- epoch: 4873, loss: 0.062364, val_loss: 0.046559 ---\n",
      "--- epoch: 4874, loss: 0.062362, val_loss: 0.046556 ---\n",
      "--- epoch: 4875, loss: 0.062359, val_loss: 0.046553 ---\n",
      "--- epoch: 4876, loss: 0.062357, val_loss: 0.046550 ---\n",
      "--- epoch: 4877, loss: 0.062355, val_loss: 0.046547 ---\n",
      "--- epoch: 4878, loss: 0.062353, val_loss: 0.046544 ---\n",
      "--- epoch: 4879, loss: 0.062351, val_loss: 0.046541 ---\n",
      "--- epoch: 4880, loss: 0.062349, val_loss: 0.046538 ---\n",
      "--- epoch: 4881, loss: 0.062347, val_loss: 0.046536 ---\n",
      "--- epoch: 4882, loss: 0.062345, val_loss: 0.046533 ---\n",
      "--- epoch: 4883, loss: 0.062342, val_loss: 0.046530 ---\n",
      "--- epoch: 4884, loss: 0.062340, val_loss: 0.046527 ---\n",
      "--- epoch: 4885, loss: 0.062338, val_loss: 0.046524 ---\n",
      "--- epoch: 4886, loss: 0.062336, val_loss: 0.046521 ---\n",
      "--- epoch: 4887, loss: 0.062334, val_loss: 0.046518 ---\n",
      "--- epoch: 4888, loss: 0.062332, val_loss: 0.046515 ---\n",
      "--- epoch: 4889, loss: 0.062330, val_loss: 0.046512 ---\n",
      "--- epoch: 4890, loss: 0.062328, val_loss: 0.046509 ---\n",
      "--- epoch: 4891, loss: 0.062326, val_loss: 0.046507 ---\n",
      "--- epoch: 4892, loss: 0.062323, val_loss: 0.046504 ---\n",
      "--- epoch: 4893, loss: 0.062321, val_loss: 0.046501 ---\n",
      "--- epoch: 4894, loss: 0.062319, val_loss: 0.046498 ---\n",
      "--- epoch: 4895, loss: 0.062317, val_loss: 0.046495 ---\n",
      "--- epoch: 4896, loss: 0.062315, val_loss: 0.046492 ---\n",
      "--- epoch: 4897, loss: 0.062313, val_loss: 0.046489 ---\n",
      "--- epoch: 4898, loss: 0.062311, val_loss: 0.046486 ---\n",
      "--- epoch: 4899, loss: 0.062309, val_loss: 0.046483 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- epoch: 4900, loss: 0.062307, val_loss: 0.046480 ---\n",
      "--- epoch: 4901, loss: 0.062304, val_loss: 0.046478 ---\n",
      "--- epoch: 4902, loss: 0.062302, val_loss: 0.046475 ---\n",
      "--- epoch: 4903, loss: 0.062300, val_loss: 0.046472 ---\n",
      "--- epoch: 4904, loss: 0.062298, val_loss: 0.046469 ---\n",
      "--- epoch: 4905, loss: 0.062296, val_loss: 0.046466 ---\n",
      "--- epoch: 4906, loss: 0.062294, val_loss: 0.046463 ---\n",
      "--- epoch: 4907, loss: 0.062292, val_loss: 0.046460 ---\n",
      "--- epoch: 4908, loss: 0.062290, val_loss: 0.046457 ---\n",
      "--- epoch: 4909, loss: 0.062288, val_loss: 0.046454 ---\n",
      "--- epoch: 4910, loss: 0.062285, val_loss: 0.046452 ---\n",
      "--- epoch: 4911, loss: 0.062283, val_loss: 0.046449 ---\n",
      "--- epoch: 4912, loss: 0.062281, val_loss: 0.046446 ---\n",
      "--- epoch: 4913, loss: 0.062279, val_loss: 0.046443 ---\n",
      "--- epoch: 4914, loss: 0.062277, val_loss: 0.046440 ---\n",
      "--- epoch: 4915, loss: 0.062275, val_loss: 0.046437 ---\n",
      "--- epoch: 4916, loss: 0.062273, val_loss: 0.046434 ---\n",
      "--- epoch: 4917, loss: 0.062271, val_loss: 0.046431 ---\n",
      "--- epoch: 4918, loss: 0.062269, val_loss: 0.046429 ---\n",
      "--- epoch: 4919, loss: 0.062267, val_loss: 0.046426 ---\n",
      "--- epoch: 4920, loss: 0.062264, val_loss: 0.046423 ---\n",
      "--- epoch: 4921, loss: 0.062262, val_loss: 0.046420 ---\n",
      "--- epoch: 4922, loss: 0.062260, val_loss: 0.046417 ---\n",
      "--- epoch: 4923, loss: 0.062258, val_loss: 0.046414 ---\n",
      "--- epoch: 4924, loss: 0.062256, val_loss: 0.046411 ---\n",
      "--- epoch: 4925, loss: 0.062254, val_loss: 0.046408 ---\n",
      "--- epoch: 4926, loss: 0.062252, val_loss: 0.046406 ---\n",
      "--- epoch: 4927, loss: 0.062250, val_loss: 0.046403 ---\n",
      "--- epoch: 4928, loss: 0.062248, val_loss: 0.046400 ---\n",
      "--- epoch: 4929, loss: 0.062246, val_loss: 0.046397 ---\n",
      "--- epoch: 4930, loss: 0.062244, val_loss: 0.046394 ---\n",
      "--- epoch: 4931, loss: 0.062242, val_loss: 0.046391 ---\n",
      "--- epoch: 4932, loss: 0.062239, val_loss: 0.046388 ---\n",
      "--- epoch: 4933, loss: 0.062237, val_loss: 0.046386 ---\n",
      "--- epoch: 4934, loss: 0.062235, val_loss: 0.046383 ---\n",
      "--- epoch: 4935, loss: 0.062233, val_loss: 0.046380 ---\n",
      "--- epoch: 4936, loss: 0.062231, val_loss: 0.046377 ---\n",
      "--- epoch: 4937, loss: 0.062229, val_loss: 0.046374 ---\n",
      "--- epoch: 4938, loss: 0.062227, val_loss: 0.046371 ---\n",
      "--- epoch: 4939, loss: 0.062225, val_loss: 0.046369 ---\n",
      "--- epoch: 4940, loss: 0.062223, val_loss: 0.046366 ---\n",
      "--- epoch: 4941, loss: 0.062221, val_loss: 0.046363 ---\n",
      "--- epoch: 4942, loss: 0.062219, val_loss: 0.046360 ---\n",
      "--- epoch: 4943, loss: 0.062217, val_loss: 0.046357 ---\n",
      "--- epoch: 4944, loss: 0.062215, val_loss: 0.046354 ---\n",
      "--- epoch: 4945, loss: 0.062212, val_loss: 0.046351 ---\n",
      "--- epoch: 4946, loss: 0.062210, val_loss: 0.046349 ---\n",
      "--- epoch: 4947, loss: 0.062208, val_loss: 0.046346 ---\n",
      "--- epoch: 4948, loss: 0.062206, val_loss: 0.046343 ---\n",
      "--- epoch: 4949, loss: 0.062204, val_loss: 0.046340 ---\n",
      "--- epoch: 4950, loss: 0.062202, val_loss: 0.046337 ---\n",
      "--- epoch: 4951, loss: 0.062200, val_loss: 0.046334 ---\n",
      "--- epoch: 4952, loss: 0.062198, val_loss: 0.046332 ---\n",
      "--- epoch: 4953, loss: 0.062196, val_loss: 0.046329 ---\n",
      "--- epoch: 4954, loss: 0.062194, val_loss: 0.046326 ---\n",
      "--- epoch: 4955, loss: 0.062192, val_loss: 0.046323 ---\n",
      "--- epoch: 4956, loss: 0.062190, val_loss: 0.046320 ---\n",
      "--- epoch: 4957, loss: 0.062188, val_loss: 0.046317 ---\n",
      "--- epoch: 4958, loss: 0.062186, val_loss: 0.046315 ---\n",
      "--- epoch: 4959, loss: 0.062184, val_loss: 0.046312 ---\n",
      "--- epoch: 4960, loss: 0.062182, val_loss: 0.046309 ---\n",
      "--- epoch: 4961, loss: 0.062179, val_loss: 0.046306 ---\n",
      "--- epoch: 4962, loss: 0.062177, val_loss: 0.046303 ---\n",
      "--- epoch: 4963, loss: 0.062175, val_loss: 0.046300 ---\n",
      "--- epoch: 4964, loss: 0.062173, val_loss: 0.046298 ---\n",
      "--- epoch: 4965, loss: 0.062171, val_loss: 0.046295 ---\n",
      "--- epoch: 4966, loss: 0.062169, val_loss: 0.046292 ---\n",
      "--- epoch: 4967, loss: 0.062167, val_loss: 0.046289 ---\n",
      "--- epoch: 4968, loss: 0.062165, val_loss: 0.046286 ---\n",
      "--- epoch: 4969, loss: 0.062163, val_loss: 0.046284 ---\n",
      "--- epoch: 4970, loss: 0.062161, val_loss: 0.046281 ---\n",
      "--- epoch: 4971, loss: 0.062159, val_loss: 0.046278 ---\n",
      "--- epoch: 4972, loss: 0.062157, val_loss: 0.046275 ---\n",
      "--- epoch: 4973, loss: 0.062155, val_loss: 0.046272 ---\n",
      "--- epoch: 4974, loss: 0.062153, val_loss: 0.046269 ---\n",
      "--- epoch: 4975, loss: 0.062151, val_loss: 0.046267 ---\n",
      "--- epoch: 4976, loss: 0.062149, val_loss: 0.046264 ---\n",
      "--- epoch: 4977, loss: 0.062147, val_loss: 0.046261 ---\n",
      "--- epoch: 4978, loss: 0.062145, val_loss: 0.046258 ---\n",
      "--- epoch: 4979, loss: 0.062142, val_loss: 0.046255 ---\n",
      "--- epoch: 4980, loss: 0.062140, val_loss: 0.046253 ---\n",
      "--- epoch: 4981, loss: 0.062138, val_loss: 0.046250 ---\n",
      "--- epoch: 4982, loss: 0.062136, val_loss: 0.046247 ---\n",
      "--- epoch: 4983, loss: 0.062134, val_loss: 0.046244 ---\n",
      "--- epoch: 4984, loss: 0.062132, val_loss: 0.046241 ---\n",
      "--- epoch: 4985, loss: 0.062130, val_loss: 0.046238 ---\n",
      "--- epoch: 4986, loss: 0.062128, val_loss: 0.046236 ---\n",
      "--- epoch: 4987, loss: 0.062126, val_loss: 0.046233 ---\n",
      "--- epoch: 4988, loss: 0.062124, val_loss: 0.046230 ---\n",
      "--- epoch: 4989, loss: 0.062122, val_loss: 0.046227 ---\n",
      "--- epoch: 4990, loss: 0.062120, val_loss: 0.046224 ---\n",
      "--- epoch: 4991, loss: 0.062118, val_loss: 0.046222 ---\n",
      "--- epoch: 4992, loss: 0.062116, val_loss: 0.046219 ---\n",
      "--- epoch: 4993, loss: 0.062114, val_loss: 0.046216 ---\n",
      "--- epoch: 4994, loss: 0.062112, val_loss: 0.046213 ---\n",
      "--- epoch: 4995, loss: 0.062110, val_loss: 0.046210 ---\n",
      "--- epoch: 4996, loss: 0.062108, val_loss: 0.046208 ---\n",
      "--- epoch: 4997, loss: 0.062106, val_loss: 0.046205 ---\n",
      "--- epoch: 4998, loss: 0.062104, val_loss: 0.046202 ---\n",
      "--- epoch: 4999, loss: 0.062102, val_loss: 0.046199 ---\n",
      "--- epoch: 5000, loss: 0.062100, val_loss: 0.046196 ---\n"
     ]
    }
   ],
   "source": [
    "mini_batch = 100\n",
    "epoch = 5000\n",
    "history_loss = []\n",
    "history_val_loss = []\n",
    "for i in range(epoch):\n",
    "    iter_num = int(sample_num//mini_batch)\n",
    "    avg_loss = 0.\n",
    "    for j in range(iter_num):\n",
    "        _, L = sess.run([fit, loss], feed_dict={\n",
    "            x : x_train[j*mini_batch : (j+1)*mini_batch],\n",
    "            y : y_train[j*mini_batch : (j+1)*mini_batch]\n",
    "        })\n",
    "        avg_loss += L\n",
    "    avg_loss = avg_loss/float(iter_num)\n",
    "    history_loss.append(avg_loss)\n",
    "    val_loss = sess.run(loss, feed_dict={x : x_val, y : y_val})\n",
    "    history_val_loss.append(val_loss)\n",
    "    print('--- epoch: %d, loss: %f, val_loss: %f ---'%(i+1, avg_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.88086009]\n",
      " [ 1.70247006]] 1.5767\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(w), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.61669706e-04]\n",
      " [  9.97737408e-01]\n",
      " [  9.50518787e-01]\n",
      " [  9.72907066e-01]\n",
      " [  9.98648226e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = sess.run(y_pred, feed_dict={x : x_val})\n",
    "print(y_hat[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.993333\n"
     ]
    }
   ],
   "source": [
    "y_h = y_hat>0.5\n",
    "y_t = y_val>0.5\n",
    "res = (y_h==y_t)\n",
    "res = res.reshape([-1])\n",
    "acc = len(np.where(res==True)[0])/len(y_val)\n",
    "print('accuracy: %f'%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa23fa3ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa23fa3be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# epoch-loss curve\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(history_loss, color='b', label=\"Training loss\")\n",
    "ax.plot(history_val_loss, color='r', label=\"validation loss\",axes =ax)\n",
    "legend = ax.legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fa26d3a7f0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa26d496d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the result of w and b\n",
    "weight = -(-2.880)/ 1.702\n",
    "bias = -1.5767 / 1.702\n",
    "x1 = -1.5\n",
    "x2 = 2.5\n",
    "y1 = weight*x1 + bias\n",
    "y2 = weight*x2 + bias\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title('on total')\n",
    "plt.plot(data[0:1000, 0], data[0:1000, 1], '.b')\n",
    "plt.plot(data[1000:, 0], data[1000:, 1], '>r')\n",
    "plt.plot([x1, x2], [y1, y2], 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
